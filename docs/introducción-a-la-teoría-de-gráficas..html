<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 13 Introducción a la Teoría de Gráficas. | Deep Learning</title>
  <meta name="description" content="Capítulo 13 Introducción a la Teoría de Gráficas. | Deep Learning" />
  <meta name="generator" content="bookdown 0.46 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 13 Introducción a la Teoría de Gráficas. | Deep Learning" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Capítulo 13 Introducción a la Teoría de Gráficas. | Deep Learning" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 13 Introducción a la Teoría de Gráficas. | Deep Learning" />
  
  <meta name="twitter:description" content="Capítulo 13 Introducción a la Teoría de Gráficas. | Deep Learning" />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="miscellanea-intro-to-graph-neural-networks.html"/>
<link rel="next" href="graph-neural-network.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><img src="img/aif-logo.png" width="280"></a></li|
|:-:|  
<center>Curso de Redes Neuronales Artificiales</center>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>BIENVENIDA</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#objetivo"><i class="fa fa-check"></i>Objetivo</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#alcances-del-programa"><i class="fa fa-check"></i>Alcances del Programa</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#temario"><i class="fa fa-check"></i>Temario:</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#c%C3%B3digo"><i class="fa fa-check"></i>Código</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#duraci%C3%B3n-y-evaluaci%C3%B3n-del-programa"><i class="fa fa-check"></i>Duración y evaluación del programa</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#recursos-y-din%C3%A1mica"><i class="fa fa-check"></i>Recursos y dinámica</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#agenda"><i class="fa fa-check"></i>Agenda</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#software"><i class="fa fa-check"></i>Software</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#bibliograf%C3%ADa"><i class="fa fa-check"></i>Bibliografía</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introducción-a-deep-learning.html"><a href="introducción-a-deep-learning.html"><i class="fa fa-check"></i><b>1</b> Introducción a Deep Learning</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introducción-a-deep-learning.html"><a href="introducción-a-deep-learning.html#introducci%C3%B3n-al-aprendizaje-autom%C3%A1tico"><i class="fa fa-check"></i><b>1.1</b> Introducción al aprendizaje automático</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="introducción-a-deep-learning.html"><a href="introducción-a-deep-learning.html#motivaci%C3%B3n-los-paradigmas-del-conocimiento"><i class="fa fa-check"></i><b>1.1.1</b> Motivación: Los paradigmas del conocimiento</a></li>
<li class="chapter" data-level="1.1.2" data-path="introducción-a-deep-learning.html"><a href="introducción-a-deep-learning.html#machine-learning-supervisado"><i class="fa fa-check"></i><b>1.1.2</b> Machine learning supervisado</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="introducción-a-deep-learning.html"><a href="introducción-a-deep-learning.html#por-qu%C3%A9-deep-learning"><i class="fa fa-check"></i><b>1.2</b> ¿Por qué Deep Learning?</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="introducción-a-deep-learning.html"><a href="introducción-a-deep-learning.html#dimensi%C3%B3n-vc"><i class="fa fa-check"></i><b>1.2.1</b> Dimensión VC</a></li>
<li class="chapter" data-level="1.2.2" data-path="introducción-a-deep-learning.html"><a href="introducción-a-deep-learning.html#el-truco-del-kernel-svm"><i class="fa fa-check"></i><b>1.2.2</b> El truco del Kernel (SVM)</a></li>
<li class="chapter" data-level="1.2.3" data-path="introducción-a-deep-learning.html"><a href="introducción-a-deep-learning.html#ingenier%C3%ADa-de-caracteristicas"><i class="fa fa-check"></i><b>1.2.3</b> Ingeniería de caracteristicas</a></li>
<li class="chapter" data-level="1.2.4" data-path="introducción-a-deep-learning.html"><a href="introducción-a-deep-learning.html#beneficios-del-deep-learning"><i class="fa fa-check"></i><b>1.2.4</b> Beneficios del deep learning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="preliminares.html"><a href="preliminares.html"><i class="fa fa-check"></i><b>2</b> Preliminares</a>
<ul>
<li class="chapter" data-level="2.1" data-path="preliminares.html"><a href="preliminares.html#algebra-lineal"><i class="fa fa-check"></i><b>2.1</b> Algebra Lineal</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="preliminares.html"><a href="preliminares.html#introducci%C3%B3n"><i class="fa fa-check"></i><b>2.1.1</b> Introducción</a></li>
<li class="chapter" data-level="2.1.2" data-path="preliminares.html"><a href="preliminares.html#motivaci%C3%B3n"><i class="fa fa-check"></i><b>2.1.2</b> Motivación</a></li>
<li class="chapter" data-level="2.1.3" data-path="preliminares.html"><a href="preliminares.html#escalares"><i class="fa fa-check"></i><b>2.1.3</b> Escalares</a></li>
<li class="chapter" data-level="2.1.4" data-path="preliminares.html"><a href="preliminares.html#vectores-1"><i class="fa fa-check"></i><b>2.1.4</b> Vectores</a></li>
<li class="chapter" data-level="2.1.5" data-path="preliminares.html"><a href="preliminares.html#matrices-1"><i class="fa fa-check"></i><b>2.1.5</b> Matrices</a></li>
<li class="chapter" data-level="2.1.6" data-path="preliminares.html"><a href="preliminares.html#tensores"><i class="fa fa-check"></i><b>2.1.6</b> Tensores</a></li>
<li class="chapter" data-level="2.1.7" data-path="preliminares.html"><a href="preliminares.html#reducciones-sobre-tensores"><i class="fa fa-check"></i><b>2.1.7</b> Reducciones sobre tensores</a></li>
<li class="chapter" data-level="2.1.8" data-path="preliminares.html"><a href="preliminares.html#producto-punto"><i class="fa fa-check"></i><b>2.1.8</b> Producto punto</a></li>
<li class="chapter" data-level="2.1.9" data-path="preliminares.html"><a href="preliminares.html#producto-entre-matrices-y-vectores"><i class="fa fa-check"></i><b>2.1.9</b> Producto entre matrices y vectores</a></li>
<li class="chapter" data-level="2.1.10" data-path="preliminares.html"><a href="preliminares.html#multiplicaci%C3%B3n-matricial"><i class="fa fa-check"></i><b>2.1.10</b> Multiplicación matricial</a></li>
<li class="chapter" data-level="2.1.11" data-path="preliminares.html"><a href="preliminares.html#normas"><i class="fa fa-check"></i><b>2.1.11</b> Normas</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="preliminares.html"><a href="preliminares.html#c%C3%A1lculo-diferencial"><i class="fa fa-check"></i><b>2.2</b> Cálculo Diferencial</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="preliminares.html"><a href="preliminares.html#introducci%C3%B3n-1"><i class="fa fa-check"></i><b>2.2.1</b> Introducción</a></li>
<li class="chapter" data-level="2.2.2" data-path="preliminares.html"><a href="preliminares.html#motivaci%C3%B3n-1"><i class="fa fa-check"></i><b>2.2.2</b> Motivación</a></li>
<li class="chapter" data-level="2.2.3" data-path="preliminares.html"><a href="preliminares.html#derivadas-y-diferenciaci%C3%B3n"><i class="fa fa-check"></i><b>2.2.3</b> Derivadas y diferenciación</a></li>
<li class="chapter" data-level="2.2.4" data-path="preliminares.html"><a href="preliminares.html#regla-de-la-cadena"><i class="fa fa-check"></i><b>2.2.4</b> Regla de la cadena</a></li>
<li class="chapter" data-level="2.2.5" data-path="preliminares.html"><a href="preliminares.html#interpretaci%C3%B3n-geom%C3%A9trica-de-la-derivada"><i class="fa fa-check"></i><b>2.2.5</b> Interpretación geométrica de la derivada</a></li>
<li class="chapter" data-level="2.2.6" data-path="preliminares.html"><a href="preliminares.html#teorema-fundamental-del-c%C3%A1lculo"><i class="fa fa-check"></i><b>2.2.6</b> Teorema fundamental del cálculo</a></li>
<li class="chapter" data-level="2.2.7" data-path="preliminares.html"><a href="preliminares.html#autodiferenciaci%C3%B3n"><i class="fa fa-check"></i><b>2.2.7</b> Autodiferenciación</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html"><i class="fa fa-check"></i><b>3</b> Redes neuronales Lineales para Regresión</a>
<ul>
<li class="chapter" data-level="3.1" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#introducci%C3%B3n-2"><i class="fa fa-check"></i><b>3.1</b> Introducción</a></li>
<li class="chapter" data-level="3.2" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#regresiones-lineales-simples"><i class="fa fa-check"></i><b>3.2</b> Regresiones lineales simples</a></li>
<li class="chapter" data-level="3.3" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#funci%C3%B3n-de-p%C3%A9rdida-y-funci%C3%B3n-de-costo"><i class="fa fa-check"></i><b>3.3</b> Función de pérdida y función de costo</a></li>
<li class="chapter" data-level="3.4" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#supuestos-en-la-regresi%C3%B3n-lineal"><i class="fa fa-check"></i><b>3.4</b> Supuestos en la regresión lineal</a></li>
<li class="chapter" data-level="3.5" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#regresi%C3%B3n-lineal-m%C3%BAltiple"><i class="fa fa-check"></i><b>3.5</b> Regresión Lineal Múltiple</a></li>
<li class="chapter" data-level="3.6" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#estimaci%C3%B3n-de-los-par%C3%A1metros"><i class="fa fa-check"></i><b>3.6</b> Estimación de los parámetros</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#derivaci%C3%B3n-paso-a-paso"><i class="fa fa-check"></i><b>3.6.1</b> Derivación paso a paso</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#bondad-de-ajuste"><i class="fa fa-check"></i><b>3.7</b> Bondad de ajuste</a></li>
<li class="chapter" data-level="3.8" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#supuestos-del-modelo-lineal-m%C3%BAltiple"><i class="fa fa-check"></i><b>3.8</b> Supuestos del modelo lineal múltiple</a></li>
<li class="chapter" data-level="3.9" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#regularizaci%C3%B3n-en-la-regresi%C3%B3n-lineal"><i class="fa fa-check"></i><b>3.9</b> Regularización en la Regresión Lineal</a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#ridge-regression"><i class="fa fa-check"></i><b>3.9.1</b> Ridge Regression</a></li>
<li class="chapter" data-level="3.9.2" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#lasso-regression"><i class="fa fa-check"></i><b>3.9.2</b> Lasso Regression</a></li>
<li class="chapter" data-level="3.9.3" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#elastic-net-regression"><i class="fa fa-check"></i><b>3.9.3</b> Elastic Net Regression</a></li>
<li class="chapter" data-level="3.9.4" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#comparaci%C3%B3n-de-m%C3%A9todos"><i class="fa fa-check"></i><b>3.9.4</b> Comparación de métodos</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#consideraciones"><i class="fa fa-check"></i><b>3.10</b> Consideraciones</a></li>
<li class="chapter" data-level="3.11" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#sesgo-y-varianza"><i class="fa fa-check"></i><b>3.11</b> Sesgo y Varianza</a>
<ul>
<li class="chapter" data-level="3.11.1" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#sesgo"><i class="fa fa-check"></i><b>3.11.1</b> Sesgo</a></li>
<li class="chapter" data-level="3.11.2" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#varianza"><i class="fa fa-check"></i><b>3.11.2</b> Varianza</a></li>
<li class="chapter" data-level="3.11.3" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#compromiso-sesgovarianza"><i class="fa fa-check"></i><b>3.11.3</b> Compromiso sesgo–varianza</a></li>
<li class="chapter" data-level="3.11.4" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#en-regresi%C3%B3n-lineal"><i class="fa fa-check"></i><b>3.11.4</b> En regresión lineal</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#conclusi%C3%B3n-de-la-secci%C3%B3n"><i class="fa fa-check"></i><b>3.12</b> Conclusión de la sección</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="redes-neuronales-lineales-para-clasificación.html"><a href="redes-neuronales-lineales-para-clasificación.html"><i class="fa fa-check"></i><b>4</b> Redes neuronales Lineales para Clasificación</a>
<ul>
<li class="chapter" data-level="4.1" data-path="redes-neuronales-lineales-para-clasificación.html"><a href="redes-neuronales-lineales-para-clasificación.html#modelos-lineales-generalizados"><i class="fa fa-check"></i><b>4.1</b> Modelos Lineales Generalizados</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="redes-neuronales-lineales-para-clasificación.html"><a href="redes-neuronales-lineales-para-clasificación.html#historia-1"><i class="fa fa-check"></i><b>4.1.1</b> Historia</a></li>
<li class="chapter" data-level="4.1.2" data-path="redes-neuronales-lineales-para-clasificación.html"><a href="redes-neuronales-lineales-para-clasificación.html#definici%C3%B3n"><i class="fa fa-check"></i><b>4.1.2</b> Definición</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="redes-neuronales-lineales-para-clasificación.html"><a href="redes-neuronales-lineales-para-clasificación.html#regresi%C3%B3n-log%C3%ADstica-para-clasificaci%C3%B3n"><i class="fa fa-check"></i><b>4.2</b> Regresión Logística para Clasificación</a></li>
<li class="chapter" data-level="4.3" data-path="redes-neuronales-lineales-para-clasificación.html"><a href="redes-neuronales-lineales-para-clasificación.html#redes-neuronales"><i class="fa fa-check"></i><b>4.3</b> Redes neuronales</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="redes-neuronales-lineales-para-clasificación.html"><a href="redes-neuronales-lineales-para-clasificación.html#historia-2"><i class="fa fa-check"></i><b>4.3.1</b> Historia</a></li>
<li class="chapter" data-level="4.3.2" data-path="redes-neuronales-lineales-para-clasificación.html"><a href="redes-neuronales-lineales-para-clasificación.html#definici%C3%B3n-1"><i class="fa fa-check"></i><b>4.3.2</b> Definición</a></li>
<li class="chapter" data-level="4.3.3" data-path="redes-neuronales-lineales-para-clasificación.html"><a href="redes-neuronales-lineales-para-clasificación.html#neurona"><i class="fa fa-check"></i><b>4.3.3</b> Neurona</a></li>
<li class="chapter" data-level="4.3.4" data-path="redes-neuronales-lineales-para-clasificación.html"><a href="redes-neuronales-lineales-para-clasificación.html#redes-neuronales-1"><i class="fa fa-check"></i><b>4.3.4</b> Redes Neuronales</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="redes-neuronales-lineales-para-clasificación.html"><a href="redes-neuronales-lineales-para-clasificación.html#notas-adicionales"><i class="fa fa-check"></i>Notas adicionales</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html"><i class="fa fa-check"></i><b>5</b> Perceptrón Multicapa</a>
<ul>
<li class="chapter" data-level="5.1" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#perceptrones-multicapa"><i class="fa fa-check"></i><b>5.1</b> Perceptrones multicapa</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#capas-ocultas"><i class="fa fa-check"></i><b>5.1.1</b> Capas ocultas</a></li>
<li class="chapter" data-level="5.1.2" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#funciones-de-activaci%C3%B3n"><i class="fa fa-check"></i><b>5.1.2</b> Funciones de activación</a></li>
<li class="chapter" data-level="5.1.3" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#discusi%C3%B3n"><i class="fa fa-check"></i><b>5.1.3</b> Discusión</a></li>
<li class="chapter" data-level="5.1.4" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#ejercicios"><i class="fa fa-check"></i><b>5.1.4</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#implementaci%C3%B3n-de-perceptrones-multicapa"><i class="fa fa-check"></i><b>5.2</b> Implementación de Perceptrones Multicapa</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#implementaci%C3%B3n-desde-cero"><i class="fa fa-check"></i><b>5.2.1</b> Implementación desde Cero</a></li>
<li class="chapter" data-level="5.2.2" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#implementaci%C3%B3n"><i class="fa fa-check"></i><b>5.2.2</b> Implementación</a></li>
<li class="chapter" data-level="5.2.3" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#ejercicios-1"><i class="fa fa-check"></i><b>5.2.3</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#forward-propagation-backward-propagation"><i class="fa fa-check"></i><b>5.3</b> Forward Propagation, Backward Propagation</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#forward-propagation"><i class="fa fa-check"></i><b>5.3.1</b> Forward Propagation</a></li>
<li class="chapter" data-level="5.3.2" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#backpropagation"><i class="fa fa-check"></i><b>5.3.2</b> Backpropagation</a></li>
<li class="chapter" data-level="5.3.3" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#resumen-6"><i class="fa fa-check"></i><b>5.3.3</b> Resumen</a></li>
<li class="chapter" data-level="5.3.4" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#ejercicios-2"><i class="fa fa-check"></i><b>5.3.4</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#estabilidad-num%C3%A9rica-e-inicializaci%C3%B3n"><i class="fa fa-check"></i><b>5.4</b> Estabilidad Numérica e Inicialización</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#explotaci%C3%B3n-y-desvanecimiento-de-gradientes"><i class="fa fa-check"></i><b>5.4.1</b> Explotación y Desvanecimiento de Gradientes</a></li>
<li class="chapter" data-level="5.4.2" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#inicializaci%C3%B3n-param%C3%A9trica"><i class="fa fa-check"></i><b>5.4.2</b> Inicialización paramétrica</a></li>
<li class="chapter" data-level="5.4.3" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#ejercicios-3"><i class="fa fa-check"></i><b>5.4.3</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#generalizaci%C3%B3n-en-deep-learning"><i class="fa fa-check"></i><b>5.5</b> Generalización en Deep Learning</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#sobreajuste-y-regularizaci%C3%B3n"><i class="fa fa-check"></i><b>5.5.1</b> Sobreajuste y Regularización</a></li>
<li class="chapter" data-level="5.5.2" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#inspiraci%C3%B3n-de-los-no-param%C3%A9tricos"><i class="fa fa-check"></i><b>5.5.2</b> Inspiración de los no paramétricos</a></li>
<li class="chapter" data-level="5.5.3" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#early-stopping"><i class="fa fa-check"></i><b>5.5.3</b> Early Stopping</a></li>
<li class="chapter" data-level="5.5.4" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#m%C3%A9todos-cl%C3%A1sicos-de-regularizaci%C3%B3n-para-redes-profundas"><i class="fa fa-check"></i><b>5.5.4</b> Métodos clásicos de regularización para redes profundas</a></li>
<li class="chapter" data-level="5.5.5" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#ejercicios-4"><i class="fa fa-check"></i><b>5.5.5</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#dropout"><i class="fa fa-check"></i><b>5.6</b> Dropout</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#dropout-en-la-pr%C3%A1ctica"><i class="fa fa-check"></i><b>5.6.1</b> Dropout en la práctica</a></li>
<li class="chapter" data-level="5.6.2" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#implementaci%C3%B3n-desde-cero-1"><i class="fa fa-check"></i><b>5.6.2</b> Implementación desde cero</a></li>
<li class="chapter" data-level="5.6.3" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#definici%C3%B3n-del-modelo"><i class="fa fa-check"></i><b>5.6.3</b> Definición del modelo</a></li>
<li class="chapter" data-level="5.6.4" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#entrenamiento-2"><i class="fa fa-check"></i><b>5.6.4</b> Entrenamiento</a></li>
<li class="chapter" data-level="5.6.5" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#implementaci%C3%B3n-concisa"><i class="fa fa-check"></i><b>5.6.5</b> Implementación concisa</a></li>
<li class="chapter" data-level="5.6.6" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#resumen-7"><i class="fa fa-check"></i><b>5.6.6</b> Resumen</a></li>
<li class="chapter" data-level="5.6.7" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#ejercicios-5"><i class="fa fa-check"></i><b>5.6.7</b> Ejercicios</a></li>
<li class="chapter" data-level="5.6.8" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#dropout-en-la-pr%C3%A1ctica-1"><i class="fa fa-check"></i><b>5.6.8</b> Dropout en la práctica</a></li>
<li class="chapter" data-level="5.6.9" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#implementaci%C3%B3n-desde-cero-2"><i class="fa fa-check"></i><b>5.6.9</b> Implementación desde cero</a></li>
<li class="chapter" data-level="5.6.10" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#definici%C3%B3n-del-modelo-1"><i class="fa fa-check"></i><b>5.6.10</b> Definición del modelo</a></li>
<li class="chapter" data-level="5.6.11" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#entrenamiento-3"><i class="fa fa-check"></i><b>5.6.11</b> Entrenamiento</a></li>
<li class="chapter" data-level="5.6.12" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#implementaci%C3%B3n-concisa-1"><i class="fa fa-check"></i><b>5.6.12</b> Implementación concisa</a></li>
<li class="chapter" data-level="5.6.13" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#resumen-8"><i class="fa fa-check"></i><b>5.6.13</b> Resumen</a></li>
<li class="chapter" data-level="5.6.14" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#ejercicios-6"><i class="fa fa-check"></i><b>5.6.14</b> Ejercicios</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="gpus.html"><a href="gpus.html"><i class="fa fa-check"></i><b>6</b> GPUs</a>
<ul>
<li class="chapter" data-level="6.1" data-path="gpus.html"><a href="gpus.html#paralelismo-y-concurrencia"><i class="fa fa-check"></i><b>6.1</b> Paralelismo y concurrencia</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="gpus.html"><a href="gpus.html#reflexi%C3%B3n-concurrencia-y-paralelismo"><i class="fa fa-check"></i><b>6.1.1</b> Reflexión: Concurrencia y Paralelismo</a></li>
<li class="chapter" data-level="6.1.2" data-path="gpus.html"><a href="gpus.html#relaci%C3%B3n-entre-concurrencia-y-paralelismo"><i class="fa fa-check"></i><b>6.1.2</b> Relación entre concurrencia y paralelismo</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="gpus.html"><a href="gpus.html#complejidad-computacional"><i class="fa fa-check"></i><b>6.2</b> Complejidad Computacional</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="gpus.html"><a href="gpus.html#analizando-la-complejidad-computacional-en-el-problema-de-ordenamiento-de-n%C3%BAmeros"><i class="fa fa-check"></i><b>6.2.1</b> Analizando la complejidad computacional en el problema de ordenamiento de números</a></li>
<li class="chapter" data-level="6.2.2" data-path="gpus.html"><a href="gpus.html#notaci%C3%B3n-big-o"><i class="fa fa-check"></i><b>6.2.2</b> Notación Big O</a></li>
<li class="chapter" data-level="6.2.3" data-path="gpus.html"><a href="gpus.html#bubble-sort-vs-merge-sort."><i class="fa fa-check"></i><b>6.2.3</b> Bubble sort vs Merge sort.</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="gpus.html"><a href="gpus.html#el-papel-del-hardware"><i class="fa fa-check"></i><b>6.3</b> El papel del hardware</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="gpus.html"><a href="gpus.html#implementaci%C3%B3n-de-multiplicaci%C3%B3n-de-matrices-en-distintas-arquitecturas"><i class="fa fa-check"></i><b>6.3.1</b> Implementación de multiplicación de matrices en distintas arquitecturas</a></li>
<li class="chapter" data-level="6.3.2" data-path="gpus.html"><a href="gpus.html#es-viable-acelerar-cualquier-algoritmo-en-gpu-tpu"><i class="fa fa-check"></i><b>6.3.2</b> ¿Es viable acelerar cualquier algoritmo en GPU / TPU?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="redes-neuronales-convolucionales.html"><a href="redes-neuronales-convolucionales.html"><i class="fa fa-check"></i><b>7</b> Redes Neuronales Convolucionales</a></li>
<li class="chapter" data-level="8" data-path="redes-neuronales-convolucionales-modernas.html"><a href="redes-neuronales-convolucionales-modernas.html"><i class="fa fa-check"></i><b>8</b> Redes Neuronales Convolucionales Modernas</a></li>
<li class="chapter" data-level="9" data-path="redes-neuronales-recurrentes.html"><a href="redes-neuronales-recurrentes.html"><i class="fa fa-check"></i><b>9</b> Redes Neuronales Recurrentes</a></li>
<li class="chapter" data-level="10" data-path="redes-neuronales-recurrentes-modernas.html"><a href="redes-neuronales-recurrentes-modernas.html"><i class="fa fa-check"></i><b>10</b> Redes Neuronales Recurrentes Modernas</a></li>
<li class="chapter" data-level="11" data-path="mecanismos-de-atención-y-transformers.html"><a href="mecanismos-de-atención-y-transformers.html"><i class="fa fa-check"></i><b>11</b> Mecanismos de Atención y Transformers</a></li>
<li class="part"><span><b>Parte 3: Escalabilidad, Eficiencia y Aplicaciones</b></span></li>
<li class="chapter" data-level="12" data-path="algoritmos-de-optimización.html"><a href="algoritmos-de-optimización.html"><i class="fa fa-check"></i><b>12</b> Algoritmos de Optimización</a></li>
<li class="chapter" data-level="" data-path="miscellanea-intro-to-graph-neural-networks.html"><a href="miscellanea-intro-to-graph-neural-networks.html"><i class="fa fa-check"></i>Miscellanea: Intro to Graph Neural Networks</a></li>
<li class="chapter" data-level="13" data-path="introducción-a-la-teoría-de-gráficas..html"><a href="introducción-a-la-teoría-de-gráficas..html"><i class="fa fa-check"></i><b>13</b> Introducción a la Teoría de Gráficas.</a>
<ul>
<li class="chapter" data-level="13.1" data-path="introducción-a-la-teoría-de-gráficas..html"><a href="introducción-a-la-teoría-de-gráficas..html#qu%C3%A9-es-una-gr%C3%A1fica"><i class="fa fa-check"></i><b>13.1</b> ¿Qué es una gráfica?</a></li>
<li class="chapter" data-level="13.2" data-path="introducción-a-la-teoría-de-gráficas..html"><a href="introducción-a-la-teoría-de-gráficas..html#problemas-cl%C3%A1sicos-de-teor%C3%ADa-de-gr%C3%A1ficas-selecci%C3%B3n"><i class="fa fa-check"></i><b>13.2</b> Problemas clásicos de teoría de gráficas (selección)</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="introducción-a-la-teoría-de-gráficas..html"><a href="introducción-a-la-teoría-de-gráficas..html#caminos-y-conectividad"><i class="fa fa-check"></i><b>13.2.1</b> Caminos y conectividad</a></li>
<li class="chapter" data-level="13.2.2" data-path="introducción-a-la-teoría-de-gráficas..html"><a href="introducción-a-la-teoría-de-gráficas..html#detecci%C3%B3n-de-comunidades"><i class="fa fa-check"></i><b>13.2.2</b> Detección de comunidades</a></li>
<li class="chapter" data-level="13.2.3" data-path="introducción-a-la-teoría-de-gráficas..html"><a href="introducción-a-la-teoría-de-gráficas..html#centralidad-e-influencia"><i class="fa fa-check"></i><b>13.2.3</b> Centralidad e influencia</a></li>
<li class="chapter" data-level="13.2.4" data-path="introducción-a-la-teoría-de-gráficas..html"><a href="introducción-a-la-teoría-de-gráficas..html#emparejamiento-y-asignaci%C3%B3n"><i class="fa fa-check"></i><b>13.2.4</b> Emparejamiento y asignación</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="introducción-a-la-teoría-de-gráficas..html"><a href="introducción-a-la-teoría-de-gráficas..html#ecosistema-de-herramientas-para-el-trabajo-con-grafos"><i class="fa fa-check"></i><b>13.3</b> Ecosistema de Herramientas para el Trabajo con Grafos</a></li>
<li class="chapter" data-level="13.4" data-path="introducción-a-la-teoría-de-gráficas..html"><a href="introducción-a-la-teoría-de-gráficas..html#por-qu%C3%A9-combinar-graficas-y-deep-learning"><i class="fa fa-check"></i><b>13.4</b> ¿Por qué combinar Graficas y Deep Learning?</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="introducción-a-la-teoría-de-gráficas..html"><a href="introducción-a-la-teoría-de-gráficas..html#a.-multilayer-percepton-en-las-features-tabulares-de-cora"><i class="fa fa-check"></i><b>13.4.1</b> A. Multilayer Percepton en las features tabulares de Cora</a></li>
<li class="chapter" data-level="13.4.2" data-path="introducción-a-la-teoría-de-gráficas..html"><a href="introducción-a-la-teoría-de-gráficas..html#b.-modelo-basado-en-una-capa-lineal-que-se-multiplica-por-la-matriz-de-adyacencia."><i class="fa fa-check"></i><b>13.4.2</b> B. Modelo basado en una capa lineal que se multiplica por la matriz de adyacencia.</a></li>
<li class="chapter" data-level="13.4.3" data-path="introducción-a-la-teoría-de-gráficas..html"><a href="introducción-a-la-teoría-de-gráficas..html#qu%C3%A9-esta-haciendo-la-red"><i class="fa fa-check"></i><b>13.4.3</b> ¿Qué esta haciendo la red?</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="introducción-a-la-teoría-de-gráficas..html"><a href="introducción-a-la-teoría-de-gráficas..html#tipos-de-problemas-de-gnn"><i class="fa fa-check"></i><b>13.5</b> Tipos de problemas de GNN</a></li>
<li class="chapter" data-level="13.6" data-path="introducción-a-la-teoría-de-gráficas..html"><a href="introducción-a-la-teoría-de-gráficas..html#existe-un-teorema-de-aproximaci%C3%B3n-univeral-tau-para-gnns"><i class="fa fa-check"></i><b>13.6</b> ¿Existe un Teorema de Aproximación Univeral (TAU) para GNN’s?</a></li>
<li class="chapter" data-level="13.7" data-path="introducción-a-la-teoría-de-gráficas..html"><a href="introducción-a-la-teoría-de-gráficas..html#enfoques-de-aprendizaje-transductivo-e-inductivo"><i class="fa fa-check"></i><b>13.7</b> Enfoques de aprendizaje transductivo e inductivo</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="graph-neural-network.html"><a href="graph-neural-network.html"><i class="fa fa-check"></i><b>14</b> Graph Neural Network</a>
<ul>
<li class="chapter" data-level="14.1" data-path="graph-neural-network.html"><a href="graph-neural-network.html#pytorch-geometric-y-graph-neural-networks"><i class="fa fa-check"></i><b>14.1</b> PyTorch Geometric y Graph Neural Networks</a></li>
<li class="chapter" data-level="14.2" data-path="graph-neural-network.html"><a href="graph-neural-network.html#graph-convolutional-networks-gnn"><i class="fa fa-check"></i><b>14.2</b> Graph Convolutional Networks (GNN)</a></li>
<li class="chapter" data-level="14.3" data-path="graph-neural-network.html"><a href="graph-neural-network.html#c%C3%B3mo-funcionan"><i class="fa fa-check"></i><b>14.3</b> ¿Cómo funcionan?</a></li>
<li class="chapter" data-level="14.4" data-path="graph-neural-network.html"><a href="graph-neural-network.html#implementaci%C3%B3n-en-pytorch-geometric"><i class="fa fa-check"></i><b>14.4</b> Implementación en PyTorch Geometric</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="graph-neural-network.html"><a href="graph-neural-network.html#ejemplo-predicci%C3%B3n-del-volumen-de-tr%C3%A1fico-en-wikipedia-regresi%C3%B3n"><i class="fa fa-check"></i><b>14.4.1</b> Ejemplo: Predicción del volumen de tráfico en Wikipedia (Regresión)</a></li>
<li class="chapter" data-level="14.4.2" data-path="graph-neural-network.html"><a href="graph-neural-network.html#ejemplo-clasificaci%C3%B3n-de-art%C3%ADculos-de-investigaci%C3%B3n-por-categor%C3%ADa"><i class="fa fa-check"></i><b>14.4.2</b> Ejemplo: Clasificación de artículos de investigación por categoría</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="graph-neural-network.html"><a href="graph-neural-network.html#graph-attention-network-gat"><i class="fa fa-check"></i><b>14.5</b> Graph Attention Network (GAT)</a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="graph-neural-network.html"><a href="graph-neural-network.html#c%C3%B3mo-funcionan-1"><i class="fa fa-check"></i><b>14.5.1</b> ¿Cómo funcionan?</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="graph-neural-network.html"><a href="graph-neural-network.html#implementaci%C3%B3n-en-pytorch-geometric-1"><i class="fa fa-check"></i><b>14.6</b> Implementación en PyTorch Geometric</a>
<ul>
<li class="chapter" data-level="14.6.1" data-path="graph-neural-network.html"><a href="graph-neural-network.html#ejemplo-clasificaci%C3%B3n-de-art%C3%ADculos-de-investigaci%C3%B3n-por-categor%C3%ADa-parte-ii"><i class="fa fa-check"></i><b>14.6.1</b> Ejemplo: Clasificación de artículos de investigación por categoría (Parte II)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="embeddings-y-graph-neural-network.html"><a href="embeddings-y-graph-neural-network.html"><i class="fa fa-check"></i><b>15</b> Embeddings y Graph Neural Network</a>
<ul>
<li class="chapter" data-level="15.1" data-path="embeddings-y-graph-neural-network.html"><a href="embeddings-y-graph-neural-network.html#qu%C3%A9-es-un-embedding"><i class="fa fa-check"></i><b>15.1</b> ¿Qué es un embedding?</a></li>
<li class="chapter" data-level="15.2" data-path="embeddings-y-graph-neural-network.html"><a href="embeddings-y-graph-neural-network.html#word2vec"><i class="fa fa-check"></i><b>15.2</b> Word2Vec</a></li>
<li class="chapter" data-level="15.3" data-path="embeddings-y-graph-neural-network.html"><a href="embeddings-y-graph-neural-network.html#node2vec"><i class="fa fa-check"></i><b>15.3</b> Node2Vec</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="embeddings-y-graph-neural-network.html"><a href="embeddings-y-graph-neural-network.html#ejemplo-aplicando-el-modelo-de-skipgrams-a-random-walks"><i class="fa fa-check"></i><b>15.3.1</b> Ejemplo: Aplicando el modelo de SkipGrams a Random Walks</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="embeddings-y-graph-neural-network.html"><a href="embeddings-y-graph-neural-network.html#sageconv"><i class="fa fa-check"></i><b>15.4</b> SageConv</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="embeddings-y-graph-neural-network.html"><a href="embeddings-y-graph-neural-network.html#ejemplo-clasificaci%C3%B3n-de-art%C3%ADculos-de-investigaci%C3%B3n-por-categor%C3%ADa-parte-ii-1"><i class="fa fa-check"></i><b>15.4.1</b> Ejemplo: Clasificación de artículos de investigación por categoría (Parte II)</a></li>
<li class="chapter" data-level="15.4.2" data-path="embeddings-y-graph-neural-network.html"><a href="embeddings-y-graph-neural-network.html#ejemplo-clasificaci%C3%B3n-de-art%C3%ADculos-de-investigaci%C3%B3n-por-categor%C3%ADa-parte-ii-2"><i class="fa fa-check"></i><b>15.4.2</b> Ejemplo: Clasificación de artículos de investigación por categoría (Parte II)</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="./"><img src="img/aif-logo.png" width="280"></a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Deep Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introducción-a-la-teoría-de-gráficas." class="section level1 hasAnchor" number="13">
<h1><span class="header-section-number">Capítulo 13</span> Introducción a la Teoría de Gráficas.<a href="introducción-a-la-teoría-de-gráficas..html#introducci%C3%B3n-a-la-teor%C3%ADa-de-gr%C3%A1ficas." class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="qué-es-una-gráfica" class="section level2 hasAnchor" number="13.1">
<h2><span class="header-section-number">13.1</span> ¿Qué es una gráfica?<a href="introducción-a-la-teoría-de-gráficas..html#qu%C3%A9-es-una-gr%C3%A1fica" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Una gráfica es un objeto matemático que representa un conjunto de objetos y las
relaciones entre ellos. Estos se usan para modelar fenómenos complejos, como la
interacción en redes sociales, redes de comunicaciones, las relaciones entre
citas de documentos, la configuración de compuestos químicos y demás.</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb53-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb53-1" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb53-2"><a href="introducción-a-la-teoría-de-gráficas..html#cb53-2" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb53-3"><a href="introducción-a-la-teoría-de-gráficas..html#cb53-3" tabindex="-1"></a><span class="im">from</span> torch.nn <span class="im">import</span> Linear</span>
<span id="cb53-4"><a href="introducción-a-la-teoría-de-gráficas..html#cb53-4" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb53-5"><a href="introducción-a-la-teoría-de-gráficas..html#cb53-5" tabindex="-1"></a><span class="im">import</span> torch_geometric</span>
<span id="cb53-6"><a href="introducción-a-la-teoría-de-gráficas..html#cb53-6" tabindex="-1"></a><span class="im">from</span> torch_geometric.datasets <span class="im">import</span> Planetoid</span>
<span id="cb53-7"><a href="introducción-a-la-teoría-de-gráficas..html#cb53-7" tabindex="-1"></a><span class="im">from</span> torch_geometric.utils <span class="im">import</span> (</span>
<span id="cb53-8"><a href="introducción-a-la-teoría-de-gráficas..html#cb53-8" tabindex="-1"></a>  to_dense_adj, to_networkx, degree</span>
<span id="cb53-9"><a href="introducción-a-la-teoría-de-gráficas..html#cb53-9" tabindex="-1"></a>)</span>
<span id="cb53-10"><a href="introducción-a-la-teoría-de-gráficas..html#cb53-10" tabindex="-1"></a></span>
<span id="cb53-11"><a href="introducción-a-la-teoría-de-gráficas..html#cb53-11" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb53-12"><a href="introducción-a-la-teoría-de-gráficas..html#cb53-12" tabindex="-1"></a><span class="im">import</span> networkx <span class="im">as</span> nx</span>
<span id="cb53-13"><a href="introducción-a-la-teoría-de-gráficas..html#cb53-13" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb53-14"><a href="introducción-a-la-teoría-de-gráficas..html#cb53-14" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb53-15"><a href="introducción-a-la-teoría-de-gráficas..html#cb53-15" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb53-16"><a href="introducción-a-la-teoría-de-gráficas..html#cb53-16" tabindex="-1"></a></span>
<span id="cb53-17"><a href="introducción-a-la-teoría-de-gráficas..html#cb53-17" tabindex="-1"></a><span class="co"># Load Zachary&#39;s Karate Club graph</span></span>
<span id="cb53-18"><a href="introducción-a-la-teoría-de-gráficas..html#cb53-18" tabindex="-1"></a>G <span class="op">=</span> nx.karate_club_graph()</span>
<span id="cb53-19"><a href="introducción-a-la-teoría-de-gráficas..html#cb53-19" tabindex="-1"></a></span>
<span id="cb53-20"><a href="introducción-a-la-teoría-de-gráficas..html#cb53-20" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Number of nodes: </span><span class="sc">{</span>G<span class="sc">.</span>number_of_nodes()<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<pre><code>## Number of nodes: 34</code></pre>
<div class="sourceCode" id="cb55"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb55-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb55-1" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Number of edges: </span><span class="sc">{</span>G<span class="sc">.</span>number_of_edges()<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<pre><code>## Number of edges: 78</code></pre>
<div class="sourceCode" id="cb57"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb57-1" tabindex="-1"></a><span class="co"># Get the club membership attribute for coloring</span></span>
<span id="cb57-2"><a href="introducción-a-la-teoría-de-gráficas..html#cb57-2" tabindex="-1"></a>club_labels <span class="op">=</span> [G.nodes[i][<span class="st">&#39;club&#39;</span>] <span class="cf">for</span> i <span class="kw">in</span> G.nodes]</span>
<span id="cb57-3"><a href="introducción-a-la-teoría-de-gráficas..html#cb57-3" tabindex="-1"></a></span>
<span id="cb57-4"><a href="introducción-a-la-teoría-de-gráficas..html#cb57-4" tabindex="-1"></a><span class="co"># Color based on club membership (&#39;Mr. Hi&#39; or &#39;Officer&#39;)</span></span>
<span id="cb57-5"><a href="introducción-a-la-teoría-de-gráficas..html#cb57-5" tabindex="-1"></a>color_map <span class="op">=</span> [</span>
<span id="cb57-6"><a href="introducción-a-la-teoría-de-gráficas..html#cb57-6" tabindex="-1"></a>  <span class="st">&#39;#FF5733&#39;</span> <span class="cf">if</span> club <span class="op">==</span> <span class="st">&#39;Mr. Hi&#39;</span> <span class="cf">else</span> <span class="st">&#39;#3371FF&#39;</span> <span class="cf">for</span> club <span class="kw">in</span> club_labels</span>
<span id="cb57-7"><a href="introducción-a-la-teoría-de-gráficas..html#cb57-7" tabindex="-1"></a>  ]</span>
<span id="cb57-8"><a href="introducción-a-la-teoría-de-gráficas..html#cb57-8" tabindex="-1"></a></span>
<span id="cb57-9"><a href="introducción-a-la-teoría-de-gráficas..html#cb57-9" tabindex="-1"></a><span class="co"># Draw the graph</span></span>
<span id="cb57-10"><a href="introducción-a-la-teoría-de-gráficas..html#cb57-10" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb57-11"><a href="introducción-a-la-teoría-de-gráficas..html#cb57-11" tabindex="-1"></a>pos <span class="op">=</span> nx.spring_layout(G) <span class="co"># positions for all nodes</span></span>
<span id="cb57-12"><a href="introducción-a-la-teoría-de-gráficas..html#cb57-12" tabindex="-1"></a>nx.draw_networkx_nodes(G, pos, node_color<span class="op">=</span>color_map)</span>
<span id="cb57-13"><a href="introducción-a-la-teoría-de-gráficas..html#cb57-13" tabindex="-1"></a>nx.draw_networkx_edges(G, pos, alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb57-14"><a href="introducción-a-la-teoría-de-gráficas..html#cb57-14" tabindex="-1"></a>nx.draw_networkx_labels(G, pos, font_color<span class="op">=</span><span class="st">&#39;white&#39;</span>)</span></code></pre></div>
<pre><code>## {0: Text(-0.04719248013020107, -0.24839125943933962, &#39;0&#39;), 1: Text(0.2527061933150169, -0.49853455876626895, &#39;1&#39;), 2: Text(0.18566695314916642, -0.21266682268175097, &#39;2&#39;), 3: Text(-0.008383036646563192, -0.6439993123881046, &#39;3&#39;), 4: Text(-0.5360248191245703, 0.024524280025362565, &#39;4&#39;), 5: Text(-0.5352479067701617, 0.3478180477965669, &#39;5&#39;), 6: Text(-0.38539660372494483, 0.4091755909484533, &#39;6&#39;), 7: Text(0.1861921144042323, -0.642247317123454, &#39;7&#39;), 8: Text(0.2904656263409677, -0.0182088686069621, &#39;8&#39;), 9: Text(0.6962549141862674, 0.38503225480269104, &#39;9&#39;), 10: Text(-0.7509492691755976, 0.06447817148422515, &#39;10&#39;), 11: Text(0.6280781559604274, -0.3883000117951177, &#39;11&#39;), 12: Text(-0.25653071196175875, -1.0, &#39;12&#39;), 13: Text(0.12514863455767072, -0.37006969238228743, &#39;13&#39;), 14: Text(-0.20682621275600446, -0.18837809006539058, &#39;14&#39;), 15: Text(0.38293168470972005, 0.4021947491463121, &#39;15&#39;), 16: Text(-0.505814793320668, 0.8885756854662669, &#39;16&#39;), 17: Text(0.048219906960434315, -0.9587541712942022, &#39;17&#39;), 18: Text(0.7305662673930557, 0.22666495046220123, &#39;18&#39;), 19: Text(0.48593445647478734, -0.47766709292332676, &#39;19&#39;), 20: Text(-0.38515409253901134, -0.21405119036828252, &#39;20&#39;), 21: Text(0.3918472870541829, -0.8416382729148583, &#39;21&#39;), 22: Text(0.3548745515028669, 0.6147570976490807, &#39;22&#39;), 23: Text(-0.09362049308351174, 0.4743109168716645, &#39;23&#39;), 24: Text(-0.1802597339264463, 0.8759848229910039, &#39;24&#39;), 25: Text(-0.3555479449878414, 0.6603804298322751, &#39;25&#39;), 26: Text(-0.5882110543793023, -0.052217857704892665, &#39;26&#39;), 27: Text(0.09624343417563727, 0.5092114605111109, &#39;27&#39;), 28: Text(-0.15261197898794066, 0.008646757903172543, &#39;28&#39;), 29: Text(-0.314306892645962, 0.18978119101271848, &#39;29&#39;), 30: Text(0.4484037616416584, -0.027980555679159046, &#39;30&#39;), 31: Text(-0.1773476911929115, 0.3696333299793844, &#39;31&#39;), 32: Text(0.03578559216621987, 0.15851367128534505, &#39;32&#39;), 33: Text(0.14010618136108588, 0.1734216659655616, &#39;33&#39;)}</code></pre>
<div class="sourceCode" id="cb59"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb59-1" tabindex="-1"></a>plt.title(<span class="st">&quot;Zachary&#39;s Karate Club Network&quot;</span>)</span>
<span id="cb59-2"><a href="introducción-a-la-teoría-de-gráficas..html#cb59-2" tabindex="-1"></a>plt.axis(<span class="st">&#39;off&#39;</span>)</span></code></pre></div>
<pre><code>## (np.float64(-0.9065084005153062), np.float64(0.8861253987327644), np.float64(-1.198300446973958), np.float64(1.086876132440225))</code></pre>
<div class="sourceCode" id="cb61"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb61-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb61-1" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p><img src="deep_learning_course_python_files/figure-html/unnamed-chunk-104-1.png" alt="" width="768" /></p>
<p>Matematicamente se representan como conjuntos de vértices (o nodos)
<span class="math inline">\(V = \{v_1, \ldots, v_n \}\)</span> y del conjunto de las relaciones entre ellas
<span class="math inline">\(E = \{e_{i_1 i_j}, \ldots, e_{i_m i_m} \}\)</span>.</p>
<p><img src="img/21-gnn/sample-graph.png" alt="" width="501" style="display: block; margin: auto;" /></p>
<p>Si bien, el conjunto de aristas define la estructura de la gráfica es comun
generar representaciones alternativas. Entre ellas se encuentran:</p>
<ul>
<li><strong>Matriz de adjyacencias:</strong> <span class="math inline">\(A\in \mathbb{R}^n\)</span>, donde <span class="math inline">\(n\)</span> es el número de vertices
de la gráfica y las entradas de la matriz estan dadas como sigue</li>
</ul>
<p><span class="math display">\[A_{ij} = \begin{cases}
    1,&amp; \text{ existe arista entre } v_i \text{ y }v_j\\
    0,&amp; \text{ en otro caso }
\end{cases}\]</span></p>
<p><img src="img/21-gnn/adjacency_matrix.png" alt="" width="302" style="display: block; margin: auto;" />
Es de notar que en la práctica, dicha matriz suele ser de tipo <em>sparse</em>, dado
que no todos los nodos están conectados.</p>
<ul>
<li><strong>Sparse Coodinate Format (COO):</strong> Es una representacion tensorial de tipo
<em>sparse</em> de las estructura de la gráfica. La idea es solo almacenar los indices
de los nodos que denotan las adyacencias en la gráfica omitiendo aquellos
lugares donde no hay relaciones ente nodos. Véase el siguiente <a href="https://docs.pytorch.org/docs/stable/sparse.html#sparse-coo-tensors">link</a>.</li>
</ul>
<p><img src="img/21-gnn/sparse_coo.png" alt="" width="1157" style="display: block; margin: auto;" /></p>
<ul>
<li>Por otro lado, se puede considerar de forma opcional incluir en el análisis
a características numéricas y categorícas (<em>features</em>) de los vértices de la
gráfica.</li>
</ul>
<p><img src="img/21-gnn/graph-3-objects.png" alt="" width="736" style="display: block; margin: auto;" /></p>
<ul>
<li><strong>Grado de sus vertices:</strong> el grado de un nodo <span class="math inline">\(deg(v_i)\)</span> como a la cantidad de aristas
donde dicho nodo está presente. Este se puede calcular como:</li>
</ul>
<p><span class="math display">\[deg(v_i) = \sum_{i=1}^N A_{ij}\]</span></p>
<div class="sourceCode" id="cb62"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb62-1" tabindex="-1"></a>G <span class="op">=</span> nx.Graph()</span>
<span id="cb62-2"><a href="introducción-a-la-teoría-de-gráficas..html#cb62-2" tabindex="-1"></a>G.add_edges_from([(<span class="st">&#39;A&#39;</span>, <span class="st">&#39;B&#39;</span>), (<span class="st">&#39;A&#39;</span>, <span class="st">&#39;C&#39;</span>), (<span class="st">&#39;B&#39;</span>, <span class="st">&#39;D&#39;</span>),</span>
<span id="cb62-3"><a href="introducción-a-la-teoría-de-gráficas..html#cb62-3" tabindex="-1"></a>(<span class="st">&#39;B&#39;</span>, <span class="st">&#39;E&#39;</span>), (<span class="st">&#39;C&#39;</span>, <span class="st">&#39;F&#39;</span>), (<span class="st">&#39;C&#39;</span>, <span class="st">&#39;G&#39;</span>)])</span>
<span id="cb62-4"><a href="introducción-a-la-teoría-de-gráficas..html#cb62-4" tabindex="-1"></a></span>
<span id="cb62-5"><a href="introducción-a-la-teoría-de-gráficas..html#cb62-5" tabindex="-1"></a><span class="co"># Draw the graph</span></span>
<span id="cb62-6"><a href="introducción-a-la-teoría-de-gráficas..html#cb62-6" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb62-7"><a href="introducción-a-la-teoría-de-gráficas..html#cb62-7" tabindex="-1"></a>pos <span class="op">=</span> nx.spring_layout(G) <span class="co"># positions for all nodes</span></span>
<span id="cb62-8"><a href="introducción-a-la-teoría-de-gráficas..html#cb62-8" tabindex="-1"></a>nx.draw_networkx_nodes(G, pos)</span>
<span id="cb62-9"><a href="introducción-a-la-teoría-de-gráficas..html#cb62-9" tabindex="-1"></a>nx.draw_networkx_edges(G, pos, alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb62-10"><a href="introducción-a-la-teoría-de-gráficas..html#cb62-10" tabindex="-1"></a>nx.draw_networkx_labels(G, pos, font_color<span class="op">=</span><span class="st">&#39;white&#39;</span>)</span></code></pre></div>
<pre><code>## {&#39;A&#39;: Text(0.0014884134129522653, 0.00038927366611223594, &#39;A&#39;), &#39;B&#39;: Text(0.27649108229581354, 0.5351300817099227, &#39;B&#39;), &#39;C&#39;: Text(-0.27656878516697603, -0.5363259769209958, &#39;C&#39;), &#39;D&#39;: Text(0.16389404009945505, 1.0, &#39;D&#39;), &#39;E&#39;: Text(0.7198087698415417, 0.7144950449075653, &#39;E&#39;), &#39;F&#39;: Text(-0.7180668173023278, -0.7138747005754214, &#39;F&#39;), &#39;G&#39;: Text(-0.1670467031804588, -0.9998137227871826, &#39;G&#39;)}</code></pre>
<div class="sourceCode" id="cb64"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb64-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb64-1" tabindex="-1"></a>plt.title(<span class="st">&quot;Samaple Graph&quot;</span>)</span>
<span id="cb64-2"><a href="introducción-a-la-teoría-de-gráficas..html#cb64-2" tabindex="-1"></a>plt.axis(<span class="st">&#39;off&#39;</span>)</span></code></pre></div>
<pre><code>## (np.float64(-0.869043753952434), np.float64(0.870785706491648), np.float64(-1.2097941636798368), np.float64(1.2099804408926542))</code></pre>
<div class="sourceCode" id="cb66"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb66-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb66-1" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p><img src="deep_learning_course_python_files/figure-html/unnamed-chunk-109-1.png" alt="" width="768" /></p>
<div class="sourceCode" id="cb67"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb67-1" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;deg(A) = </span><span class="sc">{</span>G<span class="sc">.</span>degree[<span class="st">&#39;A&#39;</span>]<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<pre><code>## deg(A) = 2</code></pre>
<div class="sourceCode" id="cb69"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb69-1" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;deg(B) = </span><span class="sc">{</span>G<span class="sc">.</span>degree[<span class="st">&#39;B&#39;</span>]<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<pre><code>## deg(B) = 3</code></pre>
</div>
<div id="problemas-clásicos-de-teoría-de-gráficas-selección" class="section level2 hasAnchor" number="13.2">
<h2><span class="header-section-number">13.2</span> Problemas clásicos de teoría de gráficas (selección)<a href="introducción-a-la-teoría-de-gráficas..html#problemas-cl%C3%A1sicos-de-teor%C3%ADa-de-gr%C3%A1ficas-selecci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="caminos-y-conectividad" class="section level3 hasAnchor" number="13.2.1">
<h3><span class="header-section-number">13.2.1</span> Caminos y conectividad<a href="introducción-a-la-teoría-de-gráficas..html#caminos-y-conectividad" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Problema:</strong> determinar si dos nodos están conectados y cómo se propaga la información a través del grafo.<br />
<strong>Aplicaciones:</strong> navegación y mapas, análisis de redes sociales, propagación de epidemias, redes de comunicación.</p>
</div>
<div id="detección-de-comunidades" class="section level3 hasAnchor" number="13.2.2">
<h3><span class="header-section-number">13.2.2</span> Detección de comunidades<a href="introducción-a-la-teoría-de-gráficas..html#detecci%C3%B3n-de-comunidades" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Problema:</strong> identificar grupos de nodos densamente conectados entre sí.<br />
<strong>Aplicaciones:</strong> segmentación de usuarios, análisis de redes sociales, biología de sistemas, recomendación de contenidos.</p>
</div>
<div id="centralidad-e-influencia" class="section level3 hasAnchor" number="13.2.3">
<h3><span class="header-section-number">13.2.3</span> Centralidad e influencia<a href="introducción-a-la-teoría-de-gráficas..html#centralidad-e-influencia" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Problema:</strong> medir la importancia relativa de los nodos dentro de un grafo.<br />
<strong>Aplicaciones:</strong> ranking de páginas web, detección de líderes de opinión, identificación de nodos críticos en infraestructura, epidemiología.</p>
</div>
<div id="emparejamiento-y-asignación" class="section level3 hasAnchor" number="13.2.4">
<h3><span class="header-section-number">13.2.4</span> Emparejamiento y asignación<a href="introducción-a-la-teoría-de-gráficas..html#emparejamiento-y-asignaci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Problema:</strong> asignar nodos entre dos conjuntos respetando restricciones estructurales.<br />
<strong>Aplicaciones:</strong> asignación de tareas, sistemas de recomendación, mercados laborales, publicidad y subastas.</p>
</div>
</div>
<div id="ecosistema-de-herramientas-para-el-trabajo-con-grafos" class="section level2 hasAnchor" number="13.3">
<h2><span class="header-section-number">13.3</span> Ecosistema de Herramientas para el Trabajo con Grafos<a href="introducción-a-la-teoría-de-gráficas..html#ecosistema-de-herramientas-para-el-trabajo-con-grafos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ol style="list-style-type: decimal">
<li>Software para Visualización y Análisis de Grafos</li>
</ol>
<ul>
<li><em>Gephi:</em> Herramienta open source la visualización interactiva y el análisis exploratorio de redes complejas y grandes grafos. <a href="https://gephi.org" class="uri">https://gephi.org</a>. La siguiente imagen fue generada en dicha herramienta</li>
</ul>
<p><img src="img/21-gnn/cite_seer_data.jpg" alt="" style="display: block; margin: auto;" /></p>
<ul>
<li><strong>Bases de datos de Grafos:</strong>
<ul>
<li><em>Neo4j:</em> Sistema de gestión de bases de datos orientada a grafos que incluye el Graph Data Science (GDS) Library para ejecutar algoritmos directamente sobre los datos almacenados.</li>
<li><strong>Memgraph</strong>: Base de datos de grafos con capacidades de Streaming <a href="https://memgraph.com" class="uri">https://memgraph.com</a></li>
<li><em>AWS Neptune</em>: Base de datos serveless, funcioina en la nube de AWS <a href="https://aws.amazon.com/es/neptune/" class="uri">https://aws.amazon.com/es/neptune/</a></li>
</ul></li>
<li><em>Graphviz:</em> Herramienta basada en scripts (lenguaje DOT) que permite la generación automática de diagramas de grafos de manera estructural y jerárquica.</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Librerías de Python para Manipulación y Algoritmos</li>
</ol>
<ul>
<li><em>NetworkX:</em> La librería de creación, manipulación y estudio de estructuras de
red; flexible e implementa algoritmos clásicos. <a href="https://networkx.org/en/" class="uri">https://networkx.org/en/</a></li>
<li><em>Graph:</em> Es un framework de Spark para trabajar con gráficas en ambientes distribuidas (<a href="https://spark.apache.org/graphx/" class="uri">https://spark.apache.org/graphx/</a>)</li>
<li><em>Mercury-graph</em>: Libreria de BBVA para gráficos, disponible en Mercury, cuenta
con algoritmos implementados para Python y Spark. <a href="https://www.bbvaaifactory.com/es/graph-analytics-with-mercury-graph/" class="uri">https://www.bbvaaifactory.com/es/graph-analytics-with-mercury-graph/</a></li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>Librerías de Deep Learning para Grafos (GNN)</li>
</ol>
<ul>
<li><p><em>PyTorch Geometric (PyG):</em> Construida sobre PyTorch. Ofrece implementaciones de última generación para operaciones de convolución y pooling en grafos. <a href="https://pytorch-geometric.readthedocs.io/en/latest/" class="uri">https://pytorch-geometric.readthedocs.io/en/latest/</a></p></li>
<li><p><em>Deep Graph Library (DGL):</em> Una librería optimizada y agnóstica al framework
(compatible con PyTorch, TensorFlow y JAX), diseñada para facilitar la
implementación de modelos GNN a escala industrial. <a href="https://www.dgl.ai" class="uri">https://www.dgl.ai</a></p></li>
</ul>
</div>
<div id="por-qué-combinar-graficas-y-deep-learning" class="section level2 hasAnchor" number="13.4">
<h2><span class="header-section-number">13.4</span> ¿Por qué combinar Graficas y Deep Learning?<a href="introducción-a-la-teoría-de-gráficas..html#por-qu%C3%A9-combinar-graficas-y-deep-learning" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Cuando los datos de un problema, ademas de features numéricas tambien incorporan
estructura, puede resultar util tomarla en consideracion para tareas de ML.</p>
<p>Para ejemplificarlo, vamos a resolver el problema de clasificación de los datos
del <em>Cora</em> de la libreria <em>torch_geometric.datasets</em>.</p>
<p>Este es un conjunto de datos de una red de citas bibliográficas que relaciona
artículos científicos y citas bibliográficas de otros artículos en su texto.
La tabla siguiente hace un resumen</p>
<table>
<colgroup>
<col width="4%" />
<col width="38%" />
<col width="57%" />
</colgroup>
<thead>
<tr class="header">
<th>#</th>
<th>Atributo</th>
<th>Valor</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>Nodos</td>
<td>2,708 (Artículos científicos)</td>
</tr>
<tr class="even">
<td>2</td>
<td>Aristas</td>
<td>10,556 (Citas)</td>
</tr>
<tr class="odd">
<td>3</td>
<td>Características (Features)</td>
<td>1,433 (Vector binario de palabras clave, Bag-of-Words)</td>
</tr>
<tr class="even">
<td>4</td>
<td>Clases</td>
<td>7 categorías de investigación</td>
</tr>
</tbody>
</table>
<p>Las categorias de los artìculos son las siguientes:</p>
<table>
<colgroup>
<col width="10%" />
<col width="22%" />
<col width="67%" />
</colgroup>
<thead>
<tr class="header">
<th>Categoria</th>
<th>Nombre</th>
<th>Descripción</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>Theory</td>
<td>Aspectos teóricos, algoritmos fundamentales y pruebas matemáticas.</td>
</tr>
<tr class="even">
<td>1</td>
<td>Reinforcement Learning</td>
<td>Agentes que aprenden mediante prueba y error para maximizar recompensas.</td>
</tr>
<tr class="odd">
<td>2</td>
<td>Genetic Algorithms</td>
<td>Algoritmos de optimización inspirados en la evolución biológica.</td>
</tr>
<tr class="even">
<td>3</td>
<td>Neural Networks</td>
<td>Modelos basados en capas de neuronas artificiales y Deep Learning.</td>
</tr>
<tr class="odd">
<td>4</td>
<td>Probabilistic Methods</td>
<td>Modelos que gestionan la incertidumbre (Redes Bayesianas, etc.).</td>
</tr>
<tr class="even">
<td>5</td>
<td>Case Based</td>
<td>Sistemas de razonamiento basados en casos y analogías previas.</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb71"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb71-1" tabindex="-1"></a>dataset <span class="op">=</span> Planetoid(root<span class="op">=</span><span class="st">&#39;./tmp/cora&#39;</span>, name<span class="op">=</span><span class="st">&#39;cora&#39;</span>)</span>
<span id="cb71-2"><a href="introducción-a-la-teoría-de-gráficas..html#cb71-2" tabindex="-1"></a>data <span class="op">=</span> dataset[<span class="dv">0</span>]</span></code></pre></div>
<div class="sourceCode" id="cb72"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb72-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb72-1" tabindex="-1"></a><span class="kw">class</span> GraphUtils:</span>
<span id="cb72-2"><a href="introducción-a-la-teoría-de-gráficas..html#cb72-2" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb72-3"><a href="introducción-a-la-teoría-de-gráficas..html#cb72-3" tabindex="-1"></a>    <span class="kw">def</span> create_adjacency_matrix(data):</span>
<span id="cb72-4"><a href="introducción-a-la-teoría-de-gráficas..html#cb72-4" tabindex="-1"></a>        <span class="co"># Crea matriz de adyacencia</span></span>
<span id="cb72-5"><a href="introducción-a-la-teoría-de-gráficas..html#cb72-5" tabindex="-1"></a>        adjacency <span class="op">=</span> to_dense_adj(data.edge_index)[<span class="dv">0</span>]</span>
<span id="cb72-6"><a href="introducción-a-la-teoría-de-gráficas..html#cb72-6" tabindex="-1"></a>        <span class="co"># Agrega una diagonal de unos (auto-referencia a nodos)</span></span>
<span id="cb72-7"><a href="introducción-a-la-teoría-de-gráficas..html#cb72-7" tabindex="-1"></a>        adjacency <span class="op">=</span> adjacency <span class="op">+</span> torch.eye(<span class="bu">len</span>(adjacency))</span>
<span id="cb72-8"><a href="introducción-a-la-teoría-de-gráficas..html#cb72-8" tabindex="-1"></a>        <span class="cf">return</span> adjacency</span>
<span id="cb72-9"><a href="introducción-a-la-teoría-de-gráficas..html#cb72-9" tabindex="-1"></a></span>
<span id="cb72-10"><a href="introducción-a-la-teoría-de-gráficas..html#cb72-10" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb72-11"><a href="introducción-a-la-teoría-de-gráficas..html#cb72-11" tabindex="-1"></a>    <span class="kw">def</span> convert_to_networkx(graph, n_sample<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb72-12"><a href="introducción-a-la-teoría-de-gráficas..html#cb72-12" tabindex="-1"></a>        g <span class="op">=</span> to_networkx(graph, node_attrs<span class="op">=</span>[<span class="st">&quot;x&quot;</span>])</span>
<span id="cb72-13"><a href="introducción-a-la-teoría-de-gráficas..html#cb72-13" tabindex="-1"></a>        y <span class="op">=</span> graph.y.numpy()</span>
<span id="cb72-14"><a href="introducción-a-la-teoría-de-gráficas..html#cb72-14" tabindex="-1"></a>    </span>
<span id="cb72-15"><a href="introducción-a-la-teoría-de-gráficas..html#cb72-15" tabindex="-1"></a>        <span class="cf">if</span> n_sample <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb72-16"><a href="introducción-a-la-teoría-de-gráficas..html#cb72-16" tabindex="-1"></a>            sampled_nodes  <span class="op">=</span> random.sample(<span class="bu">list</span>(g.nodes), n_sample)</span>
<span id="cb72-17"><a href="introducción-a-la-teoría-de-gráficas..html#cb72-17" tabindex="-1"></a>            g <span class="op">=</span> g.subgraph(sampled_nodes)</span>
<span id="cb72-18"><a href="introducción-a-la-teoría-de-gráficas..html#cb72-18" tabindex="-1"></a>            y <span class="op">=</span> y[sampled_nodes]</span>
<span id="cb72-19"><a href="introducción-a-la-teoría-de-gráficas..html#cb72-19" tabindex="-1"></a>    </span>
<span id="cb72-20"><a href="introducción-a-la-teoría-de-gráficas..html#cb72-20" tabindex="-1"></a>        <span class="cf">return</span> g, y</span>
<span id="cb72-21"><a href="introducción-a-la-teoría-de-gráficas..html#cb72-21" tabindex="-1"></a>    </span>
<span id="cb72-22"><a href="introducción-a-la-teoría-de-gráficas..html#cb72-22" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb72-23"><a href="introducción-a-la-teoría-de-gráficas..html#cb72-23" tabindex="-1"></a>    <span class="kw">def</span> plot_graph(g, y):</span>
<span id="cb72-24"><a href="introducción-a-la-teoría-de-gráficas..html#cb72-24" tabindex="-1"></a>        plt.figure(figsize<span class="op">=</span>(<span class="dv">9</span>, <span class="dv">7</span>))</span>
<span id="cb72-25"><a href="introducción-a-la-teoría-de-gráficas..html#cb72-25" tabindex="-1"></a>        nx.draw_spring(g, node_size<span class="op">=</span><span class="dv">30</span>, arrows<span class="op">=</span><span class="va">False</span>, node_color<span class="op">=</span>y)</span>
<span id="cb72-26"><a href="introducción-a-la-teoría-de-gráficas..html#cb72-26" tabindex="-1"></a>        plt.show() </span></code></pre></div>
<p>Esta es una representación de una muestra de 1,000 artículos en el conjunto Cora.</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb73-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb73-1" tabindex="-1"></a>g, y <span class="op">=</span> GraphUtils.convert_to_networkx(data, n_sample<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb73-2"><a href="introducción-a-la-teoría-de-gráficas..html#cb73-2" tabindex="-1"></a>GraphUtils.plot_graph(g, y)  </span></code></pre></div>
<p><img src="deep_learning_course_python_files/figure-html/unnamed-chunk-114-1.png" alt="" width="864" />
En complemento, ahora veremos el arreglo tabular de datos donde cada reglón es un
artículo, los features son el Bag of Words del corpus del artículo con las
palabras de toda la colección y la categoría a la que pertenece dicho artículo.</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb74-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb74-1" tabindex="-1"></a>cora_features <span class="op">=</span> pd.DataFrame(dataset.x.numpy(),columns<span class="op">=</span>[<span class="st">&quot;word&quot;</span><span class="op">+</span><span class="bu">str</span>(i) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1433</span>)])</span>
<span id="cb74-2"><a href="introducción-a-la-teoría-de-gráficas..html#cb74-2" tabindex="-1"></a>cora_features[<span class="st">&quot;category&quot;</span>] <span class="op">=</span> data.y</span>
<span id="cb74-3"><a href="introducción-a-la-teoría-de-gráficas..html#cb74-3" tabindex="-1"></a></span>
<span id="cb74-4"><a href="introducción-a-la-teoría-de-gráficas..html#cb74-4" tabindex="-1"></a>cora_features[cora_features.columns[<span class="op">-</span><span class="dv">5</span>:]].head(<span class="dv">20</span>)</span></code></pre></div>
<pre><code>##     word1429  word1430  word1431  word1432  category
## 0        0.0       0.0       0.0       0.0         3
## 1        0.0       0.0       0.0       0.0         4
## 2        0.0       0.0       0.0       0.0         4
## 3        0.0       0.0       0.0       0.0         0
## 4        0.0       0.0       0.0       0.0         3
## 5        0.0       0.0       0.0       0.0         2
## 6        0.0       0.0       0.0       0.0         0
## 7        0.0       0.0       0.0       0.0         3
## 8        0.0       0.0       0.0       0.0         3
## 9        0.0       0.0       0.0       0.0         2
## 10       0.0       0.0       0.0       0.0         0
## 11       0.0       0.0       0.0       0.0         0
## 12       0.0       0.0       0.0       0.0         4
## 13       0.0       0.0       0.0       0.0         3
## 14       0.0       0.0       0.0       0.0         3
## 15       0.0       0.0       0.0       0.0         3
## 16       0.0       0.0       0.0       0.0         2
## 17       0.0       0.0       0.0       1.0         3
## 18       0.0       0.0       0.0       0.0         1
## 19       0.0       0.0       0.0       0.0         3</code></pre>
<p>Para la comparativa consistirá en los siguientes:</p>
<ol style="list-style-type: upper-alpha">
<li><p>Un modelo de tipo Multilayer Percepton con dos capas que usa las features
numéricas para predecir la categoría a la que corresponde cada artículos</p></li>
<li><p>Un modelo que combina capaz, que conectan los datos las features
numèricas a una capa lineal y despúes multiplican la salida por la matriz de
adyacencias para involucrar la estrucura de la red.</p></li>
</ol>
<div id="a.-multilayer-percepton-en-las-features-tabulares-de-cora" class="section level3 hasAnchor" number="13.4.1">
<h3><span class="header-section-number">13.4.1</span> A. Multilayer Percepton en las features tabulares de Cora<a href="introducción-a-la-teoría-de-gráficas..html#a.-multilayer-percepton-en-las-features-tabulares-de-cora" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb76"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb76-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-1" tabindex="-1"></a><span class="co"># Define MLP model</span></span>
<span id="cb76-2"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-2" tabindex="-1"></a><span class="kw">class</span> MLP(torch.nn.Module):</span>
<span id="cb76-3"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-3" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dim_in, dim_h, dim_out):</span>
<span id="cb76-4"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-4" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb76-5"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-5" tabindex="-1"></a>        <span class="va">self</span>.linear1 <span class="op">=</span> Linear(dim_in, dim_h)</span>
<span id="cb76-6"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-6" tabindex="-1"></a>        <span class="va">self</span>.linear2 <span class="op">=</span> Linear(dim_h, dim_out)</span>
<span id="cb76-7"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-7" tabindex="-1"></a></span>
<span id="cb76-8"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-8" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb76-9"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-9" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.linear1(x)</span>
<span id="cb76-10"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-10" tabindex="-1"></a>        x <span class="op">=</span> torch.relu(x)</span>
<span id="cb76-11"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-11" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.linear2(x)</span>
<span id="cb76-12"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-12" tabindex="-1"></a>        <span class="cf">return</span> F.log_softmax(x, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb76-13"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-13" tabindex="-1"></a></span>
<span id="cb76-14"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-14" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, data, epochs, learning_rate<span class="op">=</span><span class="fl">0.01</span>, weight_decay<span class="op">=</span><span class="fl">5e-4</span>):</span>
<span id="cb76-15"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-15" tabindex="-1"></a>        criterion <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb76-16"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-16" tabindex="-1"></a>        optimizer <span class="op">=</span> torch.optim.Adam(<span class="va">self</span>.parameters(), lr<span class="op">=</span>learning_rate, weight_decay<span class="op">=</span>weight_decay)</span>
<span id="cb76-17"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-17" tabindex="-1"></a></span>
<span id="cb76-18"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-18" tabindex="-1"></a>        <span class="va">self</span>.train()</span>
<span id="cb76-19"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-19" tabindex="-1"></a>        <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs<span class="op">+</span><span class="dv">1</span>):</span>
<span id="cb76-20"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-20" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb76-21"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-21" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>(data.x)</span>
<span id="cb76-22"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-22" tabindex="-1"></a>            loss <span class="op">=</span> criterion(out[data.train_mask], data.y[data.train_mask])</span>
<span id="cb76-23"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-23" tabindex="-1"></a>            acc <span class="op">=</span> <span class="va">self</span>.accuracy(out[data.train_mask].argmax(dim<span class="op">=</span><span class="dv">1</span>), data.y[data.train_mask])</span>
<span id="cb76-24"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-24" tabindex="-1"></a>            loss.backward()</span>
<span id="cb76-25"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-25" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb76-26"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-26" tabindex="-1"></a></span>
<span id="cb76-27"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-27" tabindex="-1"></a>            <span class="cf">if</span> epoch <span class="op">%</span> <span class="dv">20</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb76-28"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-28" tabindex="-1"></a>                val_loss <span class="op">=</span> criterion(out[data.val_mask], data.y[data.val_mask])</span>
<span id="cb76-29"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-29" tabindex="-1"></a>                val_acc <span class="op">=</span> <span class="va">self</span>.accuracy(out[data.val_mask].argmax(dim<span class="op">=</span><span class="dv">1</span>), data.y[data.val_mask])</span>
<span id="cb76-30"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-30" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f&#39;Epoch </span><span class="sc">{</span>epoch<span class="sc">:&gt;3}</span><span class="ss"> | Train Loss: </span><span class="sc">{</span>loss<span class="sc">:.3f}</span><span class="ss"> | Train Acc:&#39;</span></span>
<span id="cb76-31"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-31" tabindex="-1"></a>                      <span class="ss">f&#39; </span><span class="sc">{</span>acc<span class="op">*</span><span class="dv">100</span><span class="sc">:&gt;5.2f}</span><span class="ss">% | Val Loss: </span><span class="sc">{</span>val_loss<span class="sc">:.2f}</span><span class="ss"> | &#39;</span></span>
<span id="cb76-32"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-32" tabindex="-1"></a>                      <span class="ss">f&#39;Val Acc: </span><span class="sc">{</span>val_acc<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%&#39;</span>)</span>
<span id="cb76-33"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-33" tabindex="-1"></a></span>
<span id="cb76-34"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-34" tabindex="-1"></a>    <span class="at">@torch.no_grad</span>()</span>
<span id="cb76-35"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-35" tabindex="-1"></a>    <span class="kw">def</span> test(<span class="va">self</span>, data):</span>
<span id="cb76-36"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-36" tabindex="-1"></a>        <span class="va">self</span>.<span class="bu">eval</span>()</span>
<span id="cb76-37"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-37" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>(data.x)</span>
<span id="cb76-38"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-38" tabindex="-1"></a>        acc <span class="op">=</span> <span class="va">self</span>.accuracy(out.argmax(dim<span class="op">=</span><span class="dv">1</span>)[data.test_mask], data.y[data.test_mask])</span>
<span id="cb76-39"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-39" tabindex="-1"></a>        <span class="cf">return</span> acc</span>
<span id="cb76-40"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-40" tabindex="-1"></a></span>
<span id="cb76-41"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-41" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb76-42"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-42" tabindex="-1"></a>    <span class="kw">def</span> accuracy(y_pred, y_true):</span>
<span id="cb76-43"><a href="introducción-a-la-teoría-de-gráficas..html#cb76-43" tabindex="-1"></a>        <span class="cf">return</span> torch.<span class="bu">sum</span>(y_pred <span class="op">==</span> y_true).item() <span class="op">/</span> <span class="bu">len</span>(y_true)</span></code></pre></div>
</div>
<div id="b.-modelo-basado-en-una-capa-lineal-que-se-multiplica-por-la-matriz-de-adyacencia." class="section level3 hasAnchor" number="13.4.2">
<h3><span class="header-section-number">13.4.2</span> B. Modelo basado en una capa lineal que se multiplica por la matriz de adyacencia.<a href="introducción-a-la-teoría-de-gráficas..html#b.-modelo-basado-en-una-capa-lineal-que-se-multiplica-por-la-matriz-de-adyacencia." class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb77"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb77-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb77-1" tabindex="-1"></a><span class="kw">class</span> GNNLayer(torch.nn.Module):</span>
<span id="cb77-2"><a href="introducción-a-la-teoría-de-gráficas..html#cb77-2" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dim_in, dim_out):</span>
<span id="cb77-3"><a href="introducción-a-la-teoría-de-gráficas..html#cb77-3" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb77-4"><a href="introducción-a-la-teoría-de-gráficas..html#cb77-4" tabindex="-1"></a>        <span class="va">self</span>.linear <span class="op">=</span> Linear(dim_in, dim_out, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb77-5"><a href="introducción-a-la-teoría-de-gráficas..html#cb77-5" tabindex="-1"></a></span>
<span id="cb77-6"><a href="introducción-a-la-teoría-de-gráficas..html#cb77-6" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, adjacency):</span>
<span id="cb77-7"><a href="introducción-a-la-teoría-de-gráficas..html#cb77-7" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.linear(x)</span>
<span id="cb77-8"><a href="introducción-a-la-teoría-de-gráficas..html#cb77-8" tabindex="-1"></a>        x <span class="op">=</span> torch.sparse.mm(adjacency, x)</span>
<span id="cb77-9"><a href="introducción-a-la-teoría-de-gráficas..html#cb77-9" tabindex="-1"></a>        <span class="cf">return</span> x</span></code></pre></div>
<div class="sourceCode" id="cb78"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb78-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-1" tabindex="-1"></a><span class="kw">class</span> GNN(torch.nn.Module):</span>
<span id="cb78-2"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-2" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dim_in, dim_h, dim_out):</span>
<span id="cb78-3"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-3" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb78-4"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-4" tabindex="-1"></a>        <span class="va">self</span>.gnn1 <span class="op">=</span> GNNLayer(dim_in, dim_h)</span>
<span id="cb78-5"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-5" tabindex="-1"></a>        <span class="va">self</span>.gnn2 <span class="op">=</span> GNNLayer(dim_h, dim_out)</span>
<span id="cb78-6"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-6" tabindex="-1"></a></span>
<span id="cb78-7"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-7" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, adjacency):</span>
<span id="cb78-8"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-8" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.gnn1(x, adjacency)</span>
<span id="cb78-9"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-9" tabindex="-1"></a>        h <span class="op">=</span> torch.relu(h)</span>
<span id="cb78-10"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-10" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.gnn2(h, adjacency)</span>
<span id="cb78-11"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-11" tabindex="-1"></a>        <span class="cf">return</span> F.log_softmax(h, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb78-12"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-12" tabindex="-1"></a></span>
<span id="cb78-13"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-13" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, data, adjacency, epochs, learning_rate<span class="op">=</span><span class="fl">0.01</span>, weight_decay<span class="op">=</span><span class="fl">5e-4</span>):</span>
<span id="cb78-14"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-14" tabindex="-1"></a>        criterion <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb78-15"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-15" tabindex="-1"></a>        optimizer <span class="op">=</span> torch.optim.Adam(<span class="va">self</span>.parameters(), lr<span class="op">=</span>learning_rate, weight_decay<span class="op">=</span>weight_decay)</span>
<span id="cb78-16"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-16" tabindex="-1"></a></span>
<span id="cb78-17"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-17" tabindex="-1"></a>        <span class="va">self</span>.train()</span>
<span id="cb78-18"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-18" tabindex="-1"></a>        <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs<span class="op">+</span><span class="dv">1</span>):</span>
<span id="cb78-19"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-19" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb78-20"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-20" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>(data.x, adjacency)</span>
<span id="cb78-21"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-21" tabindex="-1"></a>            loss <span class="op">=</span> criterion(out[data.train_mask], data.y[data.train_mask])</span>
<span id="cb78-22"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-22" tabindex="-1"></a>            acc <span class="op">=</span> MLP.accuracy(out[data.train_mask].argmax(dim<span class="op">=</span><span class="dv">1</span>), data.y[data.train_mask])</span>
<span id="cb78-23"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-23" tabindex="-1"></a>            loss.backward()</span>
<span id="cb78-24"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-24" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb78-25"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-25" tabindex="-1"></a></span>
<span id="cb78-26"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-26" tabindex="-1"></a>            <span class="cf">if</span> epoch <span class="op">%</span> <span class="dv">20</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb78-27"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-27" tabindex="-1"></a>                val_loss <span class="op">=</span> criterion(out[data.val_mask], data.y[data.val_mask])</span>
<span id="cb78-28"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-28" tabindex="-1"></a>                val_acc <span class="op">=</span> MLP.accuracy(out[data.val_mask].argmax(dim<span class="op">=</span><span class="dv">1</span>), data.y[data.val_mask])</span>
<span id="cb78-29"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-29" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f&#39;Epoch </span><span class="sc">{</span>epoch<span class="sc">:&gt;3}</span><span class="ss"> | Train Loss: </span><span class="sc">{</span>loss<span class="sc">:.3f}</span><span class="ss"> | Train Acc:&#39;</span></span>
<span id="cb78-30"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-30" tabindex="-1"></a>                      <span class="ss">f&#39; </span><span class="sc">{</span>acc<span class="op">*</span><span class="dv">100</span><span class="sc">:&gt;5.2f}</span><span class="ss">% | Val Loss: </span><span class="sc">{</span>val_loss<span class="sc">:.2f}</span><span class="ss"> | &#39;</span></span>
<span id="cb78-31"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-31" tabindex="-1"></a>                      <span class="ss">f&#39;Val Acc: </span><span class="sc">{</span>val_acc<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%&#39;</span>)</span>
<span id="cb78-32"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-32" tabindex="-1"></a></span>
<span id="cb78-33"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-33" tabindex="-1"></a>    <span class="at">@torch.no_grad</span>()</span>
<span id="cb78-34"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-34" tabindex="-1"></a>    <span class="kw">def</span> test(<span class="va">self</span>, data, adjacency):</span>
<span id="cb78-35"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-35" tabindex="-1"></a>        <span class="va">self</span>.<span class="bu">eval</span>()</span>
<span id="cb78-36"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-36" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>(data.x, adjacency)</span>
<span id="cb78-37"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-37" tabindex="-1"></a>        acc <span class="op">=</span> MLP.accuracy(out.argmax(dim<span class="op">=</span><span class="dv">1</span>)[data.test_mask], data.y[data.test_mask])</span>
<span id="cb78-38"><a href="introducción-a-la-teoría-de-gráficas..html#cb78-38" tabindex="-1"></a>        <span class="cf">return</span> acc</span></code></pre></div>
<p>Ahora entrenamos ambos modelos:</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb79-1" tabindex="-1"></a>mlp <span class="op">=</span> MLP(dataset.num_features, <span class="dv">16</span>, dataset.num_classes)</span>
<span id="cb79-2"><a href="introducción-a-la-teoría-de-gráficas..html#cb79-2" tabindex="-1"></a><span class="bu">print</span>(mlp)</span></code></pre></div>
<pre><code>## MLP(
##   (linear1): Linear(in_features=1433, out_features=16, bias=True)
##   (linear2): Linear(in_features=16, out_features=7, bias=True)
## )</code></pre>
<div class="sourceCode" id="cb81"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb81-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb81-1" tabindex="-1"></a>mlp.fit(data, epochs<span class="op">=</span><span class="dv">100</span>)</span></code></pre></div>
<pre><code>## Epoch   0 | Train Loss: 1.959 | Train Acc: 10.71% | Val Loss: 2.03 | Val Acc: 9.60%
## Epoch  20 | Train Loss: 0.098 | Train Acc: 100.00% | Val Loss: 1.34 | Val Acc: 54.40%
## Epoch  40 | Train Loss: 0.013 | Train Acc: 100.00% | Val Loss: 1.42 | Val Acc: 54.20%
## Epoch  60 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 1.38 | Val Acc: 53.40%
## Epoch  80 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 1.32 | Val Acc: 54.60%
## Epoch 100 | Train Loss: 0.009 | Train Acc: 100.00% | Val Loss: 1.30 | Val Acc: 55.20%</code></pre>
<div class="sourceCode" id="cb83"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb83-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb83-1" tabindex="-1"></a>acc_mlp <span class="op">=</span> mlp.test(data)</span>
<span id="cb83-2"><a href="introducción-a-la-teoría-de-gráficas..html#cb83-2" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;</span><span class="ch">\n</span><span class="ss">MLP test accuracy: </span><span class="sc">{</span>acc_mlp<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%&#39;</span>)</span></code></pre></div>
<pre><code>## 
## MLP test accuracy: 55.60%</code></pre>
<div class="sourceCode" id="cb85"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb85-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb85-1" tabindex="-1"></a>adjacency <span class="op">=</span> GraphUtils.create_adjacency_matrix(data)</span>
<span id="cb85-2"><a href="introducción-a-la-teoría-de-gráficas..html#cb85-2" tabindex="-1"></a>gnn <span class="op">=</span> GNN(dataset.num_features, <span class="dv">16</span>, dataset.num_classes)</span>
<span id="cb85-3"><a href="introducción-a-la-teoría-de-gráficas..html#cb85-3" tabindex="-1"></a><span class="bu">print</span>(gnn)</span></code></pre></div>
<pre><code>## GNN(
##   (gnn1): GNNLayer(
##     (linear): Linear(in_features=1433, out_features=16, bias=False)
##   )
##   (gnn2): GNNLayer(
##     (linear): Linear(in_features=16, out_features=7, bias=False)
##   )
## )</code></pre>
<div class="sourceCode" id="cb87"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb87-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb87-1" tabindex="-1"></a>gnn.fit(data, adjacency, epochs<span class="op">=</span><span class="dv">100</span>)</span></code></pre></div>
<pre><code>## Epoch   0 | Train Loss: 1.940 | Train Acc: 18.57% | Val Loss: 1.95 | Val Acc: 16.40%
## Epoch  20 | Train Loss: 0.074 | Train Acc: 100.00% | Val Loss: 1.55 | Val Acc: 75.20%
## Epoch  40 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 2.26 | Val Acc: 73.80%
## Epoch  60 | Train Loss: 0.002 | Train Acc: 100.00% | Val Loss: 2.39 | Val Acc: 74.40%
## Epoch  80 | Train Loss: 0.001 | Train Acc: 100.00% | Val Loss: 2.35 | Val Acc: 74.60%
## Epoch 100 | Train Loss: 0.001 | Train Acc: 100.00% | Val Loss: 2.30 | Val Acc: 74.60%</code></pre>
<div class="sourceCode" id="cb89"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb89-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb89-1" tabindex="-1"></a>acc_gnn <span class="op">=</span> gnn.test(data, adjacency)</span>
<span id="cb89-2"><a href="introducción-a-la-teoría-de-gráficas..html#cb89-2" tabindex="-1"></a></span>
<span id="cb89-3"><a href="introducción-a-la-teoría-de-gráficas..html#cb89-3" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;</span><span class="ch">\n</span><span class="ss">GNN test accuracy: </span><span class="sc">{</span>acc_gnn<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%&#39;</span>)</span></code></pre></div>
<pre><code>## 
## GNN test accuracy: 76.60%</code></pre>
<div class="sourceCode" id="cb91"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb91-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb91-1" tabindex="-1"></a>pd.DataFrame(</span>
<span id="cb91-2"><a href="introducción-a-la-teoría-de-gráficas..html#cb91-2" tabindex="-1"></a>  {</span>
<span id="cb91-3"><a href="introducción-a-la-teoría-de-gráficas..html#cb91-3" tabindex="-1"></a>    <span class="st">&quot;modelo&quot;</span>: [<span class="st">&quot;MLP&quot;</span>, <span class="st">&quot;GNN&quot;</span>],</span>
<span id="cb91-4"><a href="introducción-a-la-teoría-de-gráficas..html#cb91-4" tabindex="-1"></a>    <span class="st">&quot;accuracy&quot;</span>: [acc_mlp<span class="op">*</span><span class="dv">100</span>, acc_gnn<span class="op">*</span><span class="dv">100</span>]</span>
<span id="cb91-5"><a href="introducción-a-la-teoría-de-gráficas..html#cb91-5" tabindex="-1"></a>  }</span>
<span id="cb91-6"><a href="introducción-a-la-teoría-de-gráficas..html#cb91-6" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>##   modelo  accuracy
## 0    MLP      55.6
## 1    GNN      76.6</code></pre>
<p>En este ejemplo, el factor que marco la diferencia de la accion de la matriz
de transaciones sobre los pesos de la red, pues intutivamente sirve para
comunicar la estructura de relaciones de los nodos en el proceso de aprendizaje.</p>
<p>Dicho modelo es una implementación <em>dummy</em> de una familia conocida como
<strong>Graph Convolutional Networks</strong> que abordaremos más adelante.</p>
</div>
<div id="qué-esta-haciendo-la-red" class="section level3 hasAnchor" number="13.4.3">
<h3><span class="header-section-number">13.4.3</span> ¿Qué esta haciendo la red?<a href="introducción-a-la-teoría-de-gráficas..html#qu%C3%A9-esta-haciendo-la-red" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En este caso usaremos los datos del Karate Club presentes en PyTorch Geoemtric.</p>
<p>Entrenaremos nuevamente una red con la misma idea previa, que las features
numéricas sean multiplicadas por la matriz de adyancencia</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb93-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb93-1" tabindex="-1"></a><span class="im">from</span> torch_geometric.datasets <span class="im">import</span> KarateClub</span>
<span id="cb93-2"><a href="introducción-a-la-teoría-de-gráficas..html#cb93-2" tabindex="-1"></a></span>
<span id="cb93-3"><a href="introducción-a-la-teoría-de-gráficas..html#cb93-3" tabindex="-1"></a><span class="co"># Import dataset from PyTorch Geometric</span></span>
<span id="cb93-4"><a href="introducción-a-la-teoría-de-gráficas..html#cb93-4" tabindex="-1"></a>dataset <span class="op">=</span> KarateClub()</span>
<span id="cb93-5"><a href="introducción-a-la-teoría-de-gráficas..html#cb93-5" tabindex="-1"></a>data <span class="op">=</span> dataset[<span class="dv">0</span>]</span></code></pre></div>
<p>Podemos acceder a la información de la gráfica:</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb94-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb94-1" tabindex="-1"></a><span class="co"># Print information</span></span>
<span id="cb94-2"><a href="introducción-a-la-teoría-de-gráficas..html#cb94-2" tabindex="-1"></a><span class="bu">print</span>(dataset)</span></code></pre></div>
<pre><code>## KarateClub()</code></pre>
<div class="sourceCode" id="cb96"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb96-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb96-1" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;------------&#39;</span>)</span></code></pre></div>
<pre><code>## ------------</code></pre>
<div class="sourceCode" id="cb98"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb98-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb98-1" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Number of graphs: </span><span class="sc">{</span><span class="bu">len</span>(dataset)<span class="sc">}</span><span class="ss">&#39;</span>)</span></code></pre></div>
<pre><code>## Number of graphs: 1</code></pre>
<div class="sourceCode" id="cb100"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb100-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb100-1" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Number of features: </span><span class="sc">{</span>dataset<span class="sc">.</span>num_features<span class="sc">}</span><span class="ss">&#39;</span>)</span></code></pre></div>
<pre><code>## Number of features: 34</code></pre>
<div class="sourceCode" id="cb102"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb102-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb102-1" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Number of classes: </span><span class="sc">{</span>dataset<span class="sc">.</span>num_classes<span class="sc">}</span><span class="ss">&#39;</span>)</span></code></pre></div>
<pre><code>## Number of classes: 4</code></pre>
<p>En este caso las features numéricas son solo encoding de los nodos con el indice
que se han numerado:</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb104-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb104-1" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;x = </span><span class="sc">{</span>data<span class="sc">.</span>x<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">&#39;</span>)</span></code></pre></div>
<pre><code>## x = torch.Size([34, 34])</code></pre>
<div class="sourceCode" id="cb106"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb106-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb106-1" tabindex="-1"></a><span class="bu">print</span>(data.x)</span></code></pre></div>
<pre><code>## tensor([[1., 0., 0.,  ..., 0., 0., 0.],
##         [0., 1., 0.,  ..., 0., 0., 0.],
##         [0., 0., 1.,  ..., 0., 0., 0.],
##         ...,
##         [0., 0., 0.,  ..., 1., 0., 0.],
##         [0., 0., 0.,  ..., 0., 1., 0.],
##         [0., 0., 0.,  ..., 0., 0., 1.]])</code></pre>
<div class="sourceCode" id="cb108"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb108-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb108-1" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;edge_index = </span><span class="sc">{</span>data<span class="sc">.</span>edge_index<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">&#39;</span>)</span></code></pre></div>
<pre><code>## edge_index = torch.Size([2, 156])</code></pre>
<div class="sourceCode" id="cb110"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb110-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb110-1" tabindex="-1"></a>pd.DataFrame(data.x, columns<span class="op">=</span>[<span class="st">&quot;x&quot;</span><span class="op">+</span><span class="bu">str</span>(i<span class="op">+</span><span class="dv">1</span>) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(data.x.shape[<span class="dv">0</span>])]).head()</span></code></pre></div>
<pre><code>##     x1   x2   x3   x4   x5   x6   x7   x8   x9  x10  x11  x12  x13  ...  x22  x23  x24  x25  x26  x27  x28  x29  x30  x31  x32  x33  x34
## 0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
## 1  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
## 2  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
## 3  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
## 4  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
## 
## [5 rows x 34 columns]</code></pre>
<div class="sourceCode" id="cb112"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb112-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb112-1" tabindex="-1"></a><span class="im">from</span> torch_geometric.utils <span class="im">import</span> to_networkx</span>
<span id="cb112-2"><a href="introducción-a-la-teoría-de-gráficas..html#cb112-2" tabindex="-1"></a></span>
<span id="cb112-3"><a href="introducción-a-la-teoría-de-gráficas..html#cb112-3" tabindex="-1"></a>G <span class="op">=</span> to_networkx(data, to_undirected<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb112-4"><a href="introducción-a-la-teoría-de-gráficas..html#cb112-4" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">12</span>))</span>
<span id="cb112-5"><a href="introducción-a-la-teoría-de-gráficas..html#cb112-5" tabindex="-1"></a>plt.axis(<span class="st">&#39;off&#39;</span>)</span></code></pre></div>
<pre><code>## (np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(1.0))</code></pre>
<div class="sourceCode" id="cb114"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb114-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb114-1" tabindex="-1"></a>nx.draw_networkx(G,</span>
<span id="cb114-2"><a href="introducción-a-la-teoría-de-gráficas..html#cb114-2" tabindex="-1"></a>                pos<span class="op">=</span>nx.spring_layout(G, seed<span class="op">=</span><span class="dv">0</span>),</span>
<span id="cb114-3"><a href="introducción-a-la-teoría-de-gráficas..html#cb114-3" tabindex="-1"></a>                with_labels<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb114-4"><a href="introducción-a-la-teoría-de-gráficas..html#cb114-4" tabindex="-1"></a>                node_size<span class="op">=</span><span class="dv">400</span>,</span>
<span id="cb114-5"><a href="introducción-a-la-teoría-de-gráficas..html#cb114-5" tabindex="-1"></a>                node_color<span class="op">=</span>data.y,</span>
<span id="cb114-6"><a href="introducción-a-la-teoría-de-gráficas..html#cb114-6" tabindex="-1"></a>                cmap<span class="op">=</span><span class="st">&quot;hsv&quot;</span>,</span>
<span id="cb114-7"><a href="introducción-a-la-teoría-de-gráficas..html#cb114-7" tabindex="-1"></a>                vmin<span class="op">=-</span><span class="dv">2</span>,</span>
<span id="cb114-8"><a href="introducción-a-la-teoría-de-gráficas..html#cb114-8" tabindex="-1"></a>                vmax<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb114-9"><a href="introducción-a-la-teoría-de-gráficas..html#cb114-9" tabindex="-1"></a>                width<span class="op">=</span><span class="fl">0.8</span>,</span>
<span id="cb114-10"><a href="introducción-a-la-teoría-de-gráficas..html#cb114-10" tabindex="-1"></a>                edge_color<span class="op">=</span><span class="st">&quot;grey&quot;</span>,</span>
<span id="cb114-11"><a href="introducción-a-la-teoría-de-gráficas..html#cb114-11" tabindex="-1"></a>                font_size<span class="op">=</span><span class="dv">14</span></span>
<span id="cb114-12"><a href="introducción-a-la-teoría-de-gráficas..html#cb114-12" tabindex="-1"></a>                )</span>
<span id="cb114-13"><a href="introducción-a-la-teoría-de-gráficas..html#cb114-13" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p><img src="deep_learning_course_python_files/figure-html/unnamed-chunk-125-3.png" alt="" width="1152" /></p>
<div class="sourceCode" id="cb115"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb115-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb115-1" tabindex="-1"></a><span class="im">from</span> torch.nn <span class="im">import</span> Linear</span>
<span id="cb115-2"><a href="introducción-a-la-teoría-de-gráficas..html#cb115-2" tabindex="-1"></a><span class="im">from</span> torch_geometric.nn <span class="im">import</span> GCNConv</span>
<span id="cb115-3"><a href="introducción-a-la-teoría-de-gráficas..html#cb115-3" tabindex="-1"></a></span>
<span id="cb115-4"><a href="introducción-a-la-teoría-de-gráficas..html#cb115-4" tabindex="-1"></a><span class="kw">class</span> GCN(torch.nn.Module):</span>
<span id="cb115-5"><a href="introducción-a-la-teoría-de-gráficas..html#cb115-5" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb115-6"><a href="introducción-a-la-teoría-de-gráficas..html#cb115-6" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb115-7"><a href="introducción-a-la-teoría-de-gráficas..html#cb115-7" tabindex="-1"></a>        <span class="va">self</span>.gcn <span class="op">=</span> GCNConv(dataset.num_features, <span class="dv">3</span>)</span>
<span id="cb115-8"><a href="introducción-a-la-teoría-de-gráficas..html#cb115-8" tabindex="-1"></a>        <span class="va">self</span>.out <span class="op">=</span> Linear(<span class="dv">3</span>, dataset.num_classes)</span>
<span id="cb115-9"><a href="introducción-a-la-teoría-de-gráficas..html#cb115-9" tabindex="-1"></a></span>
<span id="cb115-10"><a href="introducción-a-la-teoría-de-gráficas..html#cb115-10" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, edge_index):</span>
<span id="cb115-11"><a href="introducción-a-la-teoría-de-gráficas..html#cb115-11" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.gcn(x, edge_index).relu()</span>
<span id="cb115-12"><a href="introducción-a-la-teoría-de-gráficas..html#cb115-12" tabindex="-1"></a>        z <span class="op">=</span> <span class="va">self</span>.out(h)</span>
<span id="cb115-13"><a href="introducción-a-la-teoría-de-gráficas..html#cb115-13" tabindex="-1"></a>        <span class="cf">return</span> h, z</span>
<span id="cb115-14"><a href="introducción-a-la-teoría-de-gráficas..html#cb115-14" tabindex="-1"></a></span>
<span id="cb115-15"><a href="introducción-a-la-teoría-de-gráficas..html#cb115-15" tabindex="-1"></a>model <span class="op">=</span> GCN()</span>
<span id="cb115-16"><a href="introducción-a-la-teoría-de-gráficas..html#cb115-16" tabindex="-1"></a><span class="bu">print</span>(model)</span></code></pre></div>
<pre><code>## GCN(
##   (gcn): GCNConv(34, 3)
##   (out): Linear(in_features=3, out_features=4, bias=True)
## )</code></pre>
<div class="sourceCode" id="cb117"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb117-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-1" tabindex="-1"></a>criterion <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb117-2"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-2" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.02</span>)</span>
<span id="cb117-3"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-3" tabindex="-1"></a></span>
<span id="cb117-4"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-4" tabindex="-1"></a><span class="co"># Calculate accuracy</span></span>
<span id="cb117-5"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-5" tabindex="-1"></a><span class="kw">def</span> accuracy(pred_y, y):</span>
<span id="cb117-6"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-6" tabindex="-1"></a>    <span class="cf">return</span> (pred_y <span class="op">==</span> y).<span class="bu">sum</span>() <span class="op">/</span> <span class="bu">len</span>(y)</span>
<span id="cb117-7"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-7" tabindex="-1"></a></span>
<span id="cb117-8"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-8" tabindex="-1"></a><span class="co"># Data for animations</span></span>
<span id="cb117-9"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-9" tabindex="-1"></a>embeddings <span class="op">=</span> []</span>
<span id="cb117-10"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-10" tabindex="-1"></a>losses <span class="op">=</span> []</span>
<span id="cb117-11"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-11" tabindex="-1"></a>accuracies <span class="op">=</span> []</span>
<span id="cb117-12"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-12" tabindex="-1"></a>outputs <span class="op">=</span> []</span>
<span id="cb117-13"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-13" tabindex="-1"></a></span>
<span id="cb117-14"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-14" tabindex="-1"></a><span class="co"># Training loop</span></span>
<span id="cb117-15"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-15" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">201</span>):</span>
<span id="cb117-16"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-16" tabindex="-1"></a>    <span class="co"># Clear gradients</span></span>
<span id="cb117-17"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-17" tabindex="-1"></a>    optimizer.zero_grad()</span>
<span id="cb117-18"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-18" tabindex="-1"></a></span>
<span id="cb117-19"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-19" tabindex="-1"></a>    <span class="co"># Forward pass</span></span>
<span id="cb117-20"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-20" tabindex="-1"></a>    h, z <span class="op">=</span> model(data.x, data.edge_index)</span>
<span id="cb117-21"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-21" tabindex="-1"></a></span>
<span id="cb117-22"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-22" tabindex="-1"></a>    <span class="co"># Calculate loss function</span></span>
<span id="cb117-23"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-23" tabindex="-1"></a>    loss <span class="op">=</span> criterion(z, data.y)</span>
<span id="cb117-24"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-24" tabindex="-1"></a></span>
<span id="cb117-25"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-25" tabindex="-1"></a>    <span class="co"># Calculate accuracy</span></span>
<span id="cb117-26"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-26" tabindex="-1"></a>    acc <span class="op">=</span> accuracy(z.argmax(dim<span class="op">=</span><span class="dv">1</span>), data.y)</span>
<span id="cb117-27"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-27" tabindex="-1"></a></span>
<span id="cb117-28"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-28" tabindex="-1"></a>    <span class="co"># Compute gradients</span></span>
<span id="cb117-29"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-29" tabindex="-1"></a>    loss.backward()</span>
<span id="cb117-30"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-30" tabindex="-1"></a></span>
<span id="cb117-31"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-31" tabindex="-1"></a>    <span class="co"># Tune parameters</span></span>
<span id="cb117-32"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-32" tabindex="-1"></a>    optimizer.step()</span>
<span id="cb117-33"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-33" tabindex="-1"></a></span>
<span id="cb117-34"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-34" tabindex="-1"></a>    <span class="co"># Store data for animations</span></span>
<span id="cb117-35"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-35" tabindex="-1"></a>    embeddings.append(h)</span>
<span id="cb117-36"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-36" tabindex="-1"></a>    losses.append(loss)</span>
<span id="cb117-37"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-37" tabindex="-1"></a>    accuracies.append(acc)</span>
<span id="cb117-38"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-38" tabindex="-1"></a>    outputs.append(z.argmax(dim<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb117-39"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-39" tabindex="-1"></a></span>
<span id="cb117-40"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-40" tabindex="-1"></a>    <span class="co"># Print metrics every 10 epochs</span></span>
<span id="cb117-41"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-41" tabindex="-1"></a>    <span class="cf">if</span> epoch <span class="op">%</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb117-42"><a href="introducción-a-la-teoría-de-gráficas..html#cb117-42" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&#39;Epoch </span><span class="sc">{</span>epoch<span class="sc">:&gt;3}</span><span class="ss"> | Loss: </span><span class="sc">{</span>loss<span class="sc">:.2f}</span><span class="ss"> | Acc: </span><span class="sc">{</span>acc<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%&#39;</span>)</span></code></pre></div>
<pre><code>## Epoch   0 | Loss: 1.32 | Acc: 35.29%
## Epoch  10 | Loss: 1.17 | Acc: 70.59%
## Epoch  20 | Loss: 0.99 | Acc: 70.59%
## Epoch  30 | Loss: 0.78 | Acc: 85.29%
## Epoch  40 | Loss: 0.55 | Acc: 91.18%
## Epoch  50 | Loss: 0.34 | Acc: 100.00%
## Epoch  60 | Loss: 0.19 | Acc: 100.00%
## Epoch  70 | Loss: 0.11 | Acc: 100.00%
## Epoch  80 | Loss: 0.07 | Acc: 100.00%
## Epoch  90 | Loss: 0.04 | Acc: 100.00%
## Epoch 100 | Loss: 0.03 | Acc: 100.00%
## Epoch 110 | Loss: 0.02 | Acc: 100.00%
## Epoch 120 | Loss: 0.02 | Acc: 100.00%
## Epoch 130 | Loss: 0.02 | Acc: 100.00%
## Epoch 140 | Loss: 0.01 | Acc: 100.00%
## Epoch 150 | Loss: 0.01 | Acc: 100.00%
## Epoch 160 | Loss: 0.01 | Acc: 100.00%
## Epoch 170 | Loss: 0.01 | Acc: 100.00%
## Epoch 180 | Loss: 0.01 | Acc: 100.00%
## Epoch 190 | Loss: 0.01 | Acc: 100.00%
## Epoch 200 | Loss: 0.01 | Acc: 100.00%</code></pre>
<div class="sourceCode" id="cb119"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb119-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb119-1" tabindex="-1"></a>plt.rcParams[<span class="st">&quot;animation.bitrate&quot;</span>] <span class="op">=</span> <span class="dv">3000</span></span>
<span id="cb119-2"><a href="introducción-a-la-teoría-de-gráficas..html#cb119-2" tabindex="-1"></a></span>
<span id="cb119-3"><a href="introducción-a-la-teoría-de-gráficas..html#cb119-3" tabindex="-1"></a><span class="kw">def</span> draw_predicted_graph(i):</span>
<span id="cb119-4"><a href="introducción-a-la-teoría-de-gráficas..html#cb119-4" tabindex="-1"></a>    G <span class="op">=</span> to_networkx(data, to_undirected<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb119-5"><a href="introducción-a-la-teoría-de-gráficas..html#cb119-5" tabindex="-1"></a>    fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">12</span>))</span>
<span id="cb119-6"><a href="introducción-a-la-teoría-de-gráficas..html#cb119-6" tabindex="-1"></a>    plt.axis(<span class="st">&#39;off&#39;</span>)</span>
<span id="cb119-7"><a href="introducción-a-la-teoría-de-gráficas..html#cb119-7" tabindex="-1"></a>    nx.draw_networkx(G,</span>
<span id="cb119-8"><a href="introducción-a-la-teoría-de-gráficas..html#cb119-8" tabindex="-1"></a>                    pos<span class="op">=</span>nx.spring_layout(G, seed<span class="op">=</span><span class="dv">0</span>),</span>
<span id="cb119-9"><a href="introducción-a-la-teoría-de-gráficas..html#cb119-9" tabindex="-1"></a>                    with_labels<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb119-10"><a href="introducción-a-la-teoría-de-gráficas..html#cb119-10" tabindex="-1"></a>                    node_size<span class="op">=</span><span class="dv">300</span>,</span>
<span id="cb119-11"><a href="introducción-a-la-teoría-de-gráficas..html#cb119-11" tabindex="-1"></a>                    node_color<span class="op">=</span>outputs[i].numpy(),</span>
<span id="cb119-12"><a href="introducción-a-la-teoría-de-gráficas..html#cb119-12" tabindex="-1"></a>                    cmap<span class="op">=</span><span class="st">&quot;hsv&quot;</span>,</span>
<span id="cb119-13"><a href="introducción-a-la-teoría-de-gráficas..html#cb119-13" tabindex="-1"></a>                    vmin<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb119-14"><a href="introducción-a-la-teoría-de-gráficas..html#cb119-14" tabindex="-1"></a>                    vmax<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb119-15"><a href="introducción-a-la-teoría-de-gráficas..html#cb119-15" tabindex="-1"></a>                    width<span class="op">=</span><span class="fl">0.8</span>,</span>
<span id="cb119-16"><a href="introducción-a-la-teoría-de-gráficas..html#cb119-16" tabindex="-1"></a>                    edge_color<span class="op">=</span><span class="st">&quot;grey&quot;</span>,</span>
<span id="cb119-17"><a href="introducción-a-la-teoría-de-gráficas..html#cb119-17" tabindex="-1"></a>                    font_size<span class="op">=</span><span class="dv">14</span></span>
<span id="cb119-18"><a href="introducción-a-la-teoría-de-gráficas..html#cb119-18" tabindex="-1"></a>                    )</span>
<span id="cb119-19"><a href="introducción-a-la-teoría-de-gráficas..html#cb119-19" tabindex="-1"></a>    plt.title(</span>
<span id="cb119-20"><a href="introducción-a-la-teoría-de-gráficas..html#cb119-20" tabindex="-1"></a>      <span class="ss">f&#39;Epoch </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> | Loss: </span><span class="sc">{</span>losses[i]<span class="sc">:.2f}</span><span class="ss"> | Acc: </span><span class="sc">{</span>accuracies[i]<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%&#39;</span>,</span>
<span id="cb119-21"><a href="introducción-a-la-teoría-de-gráficas..html#cb119-21" tabindex="-1"></a>      fontsize<span class="op">=</span><span class="dv">18</span>, pad<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb119-22"><a href="introducción-a-la-teoría-de-gráficas..html#cb119-22" tabindex="-1"></a>    plt.show()</span></code></pre></div>
<div class="sourceCode" id="cb120"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb120-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb120-1" tabindex="-1"></a>draw_predicted_graph(<span class="dv">1</span>)</span></code></pre></div>
<p><img src="deep_learning_course_python_files/figure-html/unnamed-chunk-129-5.png" alt="" width="1152" /></p>
<div class="sourceCode" id="cb121"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb121-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb121-1" tabindex="-1"></a>draw_predicted_graph(<span class="dv">5</span>)</span></code></pre></div>
<p><img src="deep_learning_course_python_files/figure-html/unnamed-chunk-130-7.png" alt="" width="1152" /></p>
<div class="sourceCode" id="cb122"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb122-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb122-1" tabindex="-1"></a>draw_predicted_graph(<span class="dv">9</span>)</span></code></pre></div>
<p><img src="deep_learning_course_python_files/figure-html/unnamed-chunk-131-9.png" alt="" width="1152" /></p>
<div class="sourceCode" id="cb123"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb123-1"><a href="introducción-a-la-teoría-de-gráficas..html#cb123-1" tabindex="-1"></a>draw_predicted_graph(<span class="dv">100</span>)</span></code></pre></div>
<p><img src="deep_learning_course_python_files/figure-html/unnamed-chunk-132-11.png" alt="" width="1152" /></p>
<p>En las imágenes se aprecia como poco a poco, los pesos se van ajustando, a través
de la información de la matriz de adyancias, para predecir las etiquetas de los nodos.</p>
</div>
</div>
<div id="tipos-de-problemas-de-gnn" class="section level2 hasAnchor" number="13.5">
<h2><span class="header-section-number">13.5</span> Tipos de problemas de GNN<a href="introducción-a-la-teoría-de-gráficas..html#tipos-de-problemas-de-gnn" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El aprendizaje automático en grafos se presenta en diversas modalidades:</p>
<ul>
<li><p><strong>Aprendizaje Supervisado/Semi-supervisado:</strong></p>
<ul>
<li><em>Clasificación de Nodos (o Aristas):</em> Nodos etiquetados → etiquetar otros nodos.
<ul>
<li>Ejemplos: Marketing (orientado/segmentaciones), predicción de interfaces proteicas.</li>
</ul></li>
<li><em>Clasificación de Grafos:</em> Grafos etiquetados → etiquetar nuevo grafo.
<ul>
<li>Ejemplos: Clasificación de moléculas, predicción de la eficacia de fármacos.</li>
</ul></li>
</ul></li>
</ul>
<p><img src="img/21-gnn/gnn_node_classification.png" alt="" width="1000" style="display: block; margin: auto;" /></p>
<ul>
<li><strong>Aprendizaje No Supervisado (y Semi-supervisado)</strong>
<ul>
<li>Ejemplos:
<ul>
<li>Detección de Comunidades: Un grafo → agrupar nodos</li>
<li>Análisis de redes sociales.</li>
</ul></li>
</ul></li>
</ul>
<p><img src="img/21-gnn/gnn_node_clustering.png" alt="" width="1000" style="display: block; margin: auto;" /></p>
<ul>
<li><em>Link prediction (o Vínculos): Un grafo → ¿posible nueva arista?</em>
<ul>
<li>Ejemplos: Sistemas de recomendación. Cabe mencionar que Uber usa modelos
de este este estilo para hacer recomendaciones de comida <a href="https://www.uber.com/en-MX/blog/uber-eats-graph-learning/" class="uri">https://www.uber.com/en-MX/blog/uber-eats-graph-learning/</a></li>
</ul></li>
</ul>
<p><img src="img/21-gnn/gnn_link_prediction.png" alt="" width="1000" style="display: block; margin: auto;" /></p>
<ul>
<li><strong>Otros tareas:</strong>
<ul>
<li>Predicción (de nodo, de arista) en grafos dinámicos (simulación de sistemas físicos),</li>
<li>Generación de gráficas (diseño de fármacos)</li>
<li>Predicción de Tráfico: Google Maps hace estimaciones de condiciones de tráfico empleando Graph Nuera Networks <a href="https://deepmind.google/blog/traffic-prediction-with-advanced-graph-neural-networks/" class="uri">https://deepmind.google/blog/traffic-prediction-with-advanced-graph-neural-networks/</a></li>
</ul></li>
</ul>
<p><img src="img/21-gnn/gnn_graph_classification.png" alt="" width="1000" style="display: block; margin: auto;" /></p>
</div>
<div id="existe-un-teorema-de-aproximación-univeral-tau-para-gnns" class="section level2 hasAnchor" number="13.6">
<h2><span class="header-section-number">13.6</span> ¿Existe un Teorema de Aproximación Univeral (TAU) para GNN’s?<a href="introducción-a-la-teoría-de-gráficas..html#existe-un-teorema-de-aproximaci%C3%B3n-univeral-tau-para-gnns" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><p>Muchas pruebas del existentes del TAU para GNN son extensiones de del Teorema de Stone-Weierstrass,</p></li>
<li><p>Un tema a resolver en problema a resolver es si dos gráficas son isomórficas.</p>
<ul>
<li>Weisfeiler y Leman idearon una heurística que trata de determinar si dos
gráficas son isomórficas entre si.</li>
<li>Los resultados algoritmos son invariantes ante permutaciones de etiquetado
de las gráficas</li>
<li>En la práctica, es muy dificil encontrar gráficas isomórficas entre si.</li>
</ul></li>
<li><p>Algunos resultados prueban la universalidad bajo ciertas condiciones:</p>
<ul>
<li>Maron et al. On the Universality of Invariant Networks (2019)
<em>“G-invariant networks are universal if high-order tensors are allowed (..)”</em></li>
<li>Universal Invariant and Equivariant Graph Neural Network (2019) <em>“GNNs are universal approximators in probability for node classification &amp; regression tasks, as they can approximate any measurable function that satisfies
the 1–WL equivalence on nodes”</em></li>
</ul></li>
</ul>
</div>
<div id="enfoques-de-aprendizaje-transductivo-e-inductivo" class="section level2 hasAnchor" number="13.7">
<h2><span class="header-section-number">13.7</span> Enfoques de aprendizaje transductivo e inductivo<a href="introducción-a-la-teoría-de-gráficas..html#enfoques-de-aprendizaje-transductivo-e-inductivo" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Aprendizaje Transductivo:</strong> En este paradigma, el modelo se entrena
considerando todo el grafo disponible, es decir, con todos los nodos y sus
relaciones (aristas) presentes durante la fase de entrenamiento, incluso aquellos
cuya informacion no se utiliza directamente para el cálculo de la función de pérdida.</p>
<p><strong>Nota:</strong> Bajo dicho enfoque, un modelo aprende representaciones
(embeddings) dependientes de la estructura completa del grafo, por lo que <strong>no
puede generalizar a nodos o subgrafos no observados durante el entrenamiento</strong>.</p>
<p><strong>Aprendizaje Inductivo:</strong> reservan conjuntos de datos de entrenamiento y prueba
separados. El proceso de aprendizaje ingesta los datos de entrenamiento y, a
continuación, el modelo aprendido se prueba utilizando los datos de prueba, que
no ha observado antes en ninguna capacidad.</p>
<p><img src="img/21-gnn/transductive-inductive.png" alt="" width="425" style="display: block; margin: auto;" /></p>

<!-- ::: watermark -->
<!-- <img src="img/aif-logo.png" width="400"/> -->
<!-- ::: -->
</div>
</div>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script>

$('.pipehover_incremental tr').hover(function() {
  $(this).removeClass()
  $(this).prevAll().removeClass()
  $(this).nextAll().removeClass()
  $(this).addClass('hover');
  $(this).prevAll().addClass('hover');
  $(this).closest('div').next().find('img').attr("src", $(this).attr("link"));
});


$('.pipehover_select_one_row tr').hover(function() {
  $(this).removeClass()
  $(this).prevAll().removeClass()
  $(this).nextAll().removeClass()
  $(this).addClass('hover');
  $(this).closest('div').next().find('img').attr("src", $(this).attr("link"));
});

</script>
            </section>

          </div>
        </div>
      </div>
<a href="miscellanea-intro-to-graph-neural-networks.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="graph-neural-network.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["deep_learning_course_python.pdf"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
