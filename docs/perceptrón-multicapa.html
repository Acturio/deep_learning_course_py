<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 4 Perceptrón Multicapa | Deep Learning</title>
  <meta name="description" content="Capítulo 4 Perceptrón Multicapa | Deep Learning" />
  <meta name="generator" content="bookdown 0.46 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 4 Perceptrón Multicapa | Deep Learning" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Capítulo 4 Perceptrón Multicapa | Deep Learning" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 4 Perceptrón Multicapa | Deep Learning" />
  
  <meta name="twitter:description" content="Capítulo 4 Perceptrón Multicapa | Deep Learning" />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="redes-neuronales-lineales-para-clasificación.html"/>
<link rel="next" href="guía-del-constructor.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><img src="img/aif-logo.png" width="280"></a></li|
|:-:|  
<center>Curso de Redes Neuronales Artificiales</center>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>BIENVENIDA</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#objetivo"><i class="fa fa-check"></i>Objetivo</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#alcances-del-programa"><i class="fa fa-check"></i>Alcances del Programa</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#temario"><i class="fa fa-check"></i>Temario:</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#c%C3%B3digo"><i class="fa fa-check"></i>Código</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#duraci%C3%B3n-y-evaluaci%C3%B3n-del-programa"><i class="fa fa-check"></i>Duración y evaluación del programa</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#recursos-y-din%C3%A1mica"><i class="fa fa-check"></i>Recursos y dinámica</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#agenda"><i class="fa fa-check"></i>Agenda</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#software"><i class="fa fa-check"></i>Software</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#bibliograf%C3%ADa"><i class="fa fa-check"></i>Bibliografía</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path=""><a href="#part-parte-1-bases-y-preeliminares"><i class="fa fa-check"></i>(PART*) Parte 1: Bases y Preeliminares</a>
<ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#introducci%C3%B3n-al-aprendizaje-autom%C3%A1tico"><i class="fa fa-check"></i><b>0.1</b> Introducción al aprendizaje automático</a>
<ul>
<li class="chapter" data-level="0.1.1" data-path="index.html"><a href="index.html#motivaci%C3%B3n-los-paradigmas-del-conocimiento"><i class="fa fa-check"></i><b>0.1.1</b> Motivación: Los paradigmas del conocimiento</a></li>
<li class="chapter" data-level="0.1.2" data-path="index.html"><a href="index.html#machine-learning-supervisado"><i class="fa fa-check"></i><b>0.1.2</b> Machine learning supervisado</a></li>
</ul></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#por-qu%C3%A9-deep-learning"><i class="fa fa-check"></i><b>0.2</b> ¿Por qué Deep Learning?</a>
<ul>
<li class="chapter" data-level="0.2.1" data-path="index.html"><a href="index.html#dimensi%C3%B3n-vc"><i class="fa fa-check"></i><b>0.2.1</b> Dimensión VC</a></li>
<li class="chapter" data-level="0.2.2" data-path="index.html"><a href="index.html#el-truco-del-kernel-svm"><i class="fa fa-check"></i><b>0.2.2</b> El truco del Kernel (SVM)</a></li>
<li class="chapter" data-level="0.2.3" data-path="index.html"><a href="index.html#ingenier%C3%ADa-de-caracteristicas"><i class="fa fa-check"></i><b>0.2.3</b> Ingeniería de caracteristicas</a></li>
<li class="chapter" data-level="0.2.4" data-path="index.html"><a href="index.html#beneficios-del-deep-learning"><i class="fa fa-check"></i><b>0.2.4</b> Beneficios del deep learning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="preliminares.html"><a href="preliminares.html"><i class="fa fa-check"></i><b>1</b> Preliminares</a>
<ul>
<li class="chapter" data-level="1.1" data-path="preliminares.html"><a href="preliminares.html#algebra-lineal"><i class="fa fa-check"></i><b>1.1</b> Algebra Lineal</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="preliminares.html"><a href="preliminares.html#introducci%C3%B3n"><i class="fa fa-check"></i><b>1.1.1</b> Introducción</a></li>
<li class="chapter" data-level="1.1.2" data-path="preliminares.html"><a href="preliminares.html#motivaci%C3%B3n"><i class="fa fa-check"></i><b>1.1.2</b> Motivación</a></li>
<li class="chapter" data-level="1.1.3" data-path="preliminares.html"><a href="preliminares.html#escalares"><i class="fa fa-check"></i><b>1.1.3</b> Escalares</a></li>
<li class="chapter" data-level="1.1.4" data-path="preliminares.html"><a href="preliminares.html#vectores-1"><i class="fa fa-check"></i><b>1.1.4</b> Vectores</a></li>
<li class="chapter" data-level="1.1.5" data-path="preliminares.html"><a href="preliminares.html#matrices-1"><i class="fa fa-check"></i><b>1.1.5</b> Matrices</a></li>
<li class="chapter" data-level="1.1.6" data-path="preliminares.html"><a href="preliminares.html#tensores"><i class="fa fa-check"></i><b>1.1.6</b> Tensores</a></li>
<li class="chapter" data-level="1.1.7" data-path="preliminares.html"><a href="preliminares.html#reducciones-sobre-tensores"><i class="fa fa-check"></i><b>1.1.7</b> Reducciones sobre tensores</a></li>
<li class="chapter" data-level="1.1.8" data-path="preliminares.html"><a href="preliminares.html#producto-punto"><i class="fa fa-check"></i><b>1.1.8</b> Producto punto</a></li>
<li class="chapter" data-level="1.1.9" data-path="preliminares.html"><a href="preliminares.html#producto-entre-matrices-y-vectores"><i class="fa fa-check"></i><b>1.1.9</b> Producto entre matrices y vectores</a></li>
<li class="chapter" data-level="1.1.10" data-path="preliminares.html"><a href="preliminares.html#multiplicaci%C3%B3n-matricial"><i class="fa fa-check"></i><b>1.1.10</b> Multiplicación matricial</a></li>
<li class="chapter" data-level="1.1.11" data-path="preliminares.html"><a href="preliminares.html#normas"><i class="fa fa-check"></i><b>1.1.11</b> Normas</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="preliminares.html"><a href="preliminares.html#c%C3%A1lculo-diferencial"><i class="fa fa-check"></i><b>1.2</b> Cálculo Diferencial</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="preliminares.html"><a href="preliminares.html#introducci%C3%B3n-1"><i class="fa fa-check"></i><b>1.2.1</b> Introducción</a></li>
<li class="chapter" data-level="1.2.2" data-path="preliminares.html"><a href="preliminares.html#motivaci%C3%B3n-1"><i class="fa fa-check"></i><b>1.2.2</b> Motivación</a></li>
<li class="chapter" data-level="1.2.3" data-path="preliminares.html"><a href="preliminares.html#derivadas-y-diferenciaci%C3%B3n"><i class="fa fa-check"></i><b>1.2.3</b> Derivadas y diferenciación</a></li>
<li class="chapter" data-level="1.2.4" data-path="preliminares.html"><a href="preliminares.html#regla-de-la-cadena"><i class="fa fa-check"></i><b>1.2.4</b> Regla de la cadena</a></li>
<li class="chapter" data-level="1.2.5" data-path="preliminares.html"><a href="preliminares.html#interpretaci%C3%B3n-geom%C3%A9trica-de-la-derivada"><i class="fa fa-check"></i><b>1.2.5</b> Interpretación geométrica de la derivada</a></li>
<li class="chapter" data-level="1.2.6" data-path="preliminares.html"><a href="preliminares.html#teorema-fundamental-del-c%C3%A1lculo"><i class="fa fa-check"></i><b>1.2.6</b> Teorema fundamental del cálculo</a></li>
<li class="chapter" data-level="1.2.7" data-path="preliminares.html"><a href="preliminares.html#autodiferenciaci%C3%B3n"><i class="fa fa-check"></i><b>1.2.7</b> Autodiferenciación</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html"><i class="fa fa-check"></i><b>2</b> Redes neuronales Lineales para Regresión</a>
<ul>
<li class="chapter" data-level="2.1" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#introducci%C3%B3n-2"><i class="fa fa-check"></i><b>2.1</b> Introducción</a></li>
<li class="chapter" data-level="2.2" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#regresiones-lineales-simples"><i class="fa fa-check"></i><b>2.2</b> Regresiones lineales simples</a></li>
<li class="chapter" data-level="2.3" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#funci%C3%B3n-de-p%C3%A9rdida-y-funci%C3%B3n-de-costo"><i class="fa fa-check"></i><b>2.3</b> Función de pérdida y función de costo</a></li>
<li class="chapter" data-level="2.4" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#supuestos-en-la-regresi%C3%B3n-lineal"><i class="fa fa-check"></i><b>2.4</b> Supuestos en la regresión lineal</a></li>
<li class="chapter" data-level="2.5" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#regresi%C3%B3n-lineal-m%C3%BAltiple"><i class="fa fa-check"></i><b>2.5</b> Regresión Lineal Múltiple</a></li>
<li class="chapter" data-level="2.6" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#estimaci%C3%B3n-de-los-par%C3%A1metros"><i class="fa fa-check"></i><b>2.6</b> Estimación de los parámetros</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#derivaci%C3%B3n-paso-a-paso"><i class="fa fa-check"></i><b>2.6.1</b> Derivación paso a paso</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#bondad-de-ajuste"><i class="fa fa-check"></i><b>2.7</b> Bondad de ajuste</a></li>
<li class="chapter" data-level="2.8" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#supuestos-del-modelo-lineal-m%C3%BAltiple"><i class="fa fa-check"></i><b>2.8</b> Supuestos del modelo lineal múltiple</a></li>
<li class="chapter" data-level="2.9" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#regularizaci%C3%B3n-en-la-regresi%C3%B3n-lineal"><i class="fa fa-check"></i><b>2.9</b> Regularización en la Regresión Lineal</a>
<ul>
<li class="chapter" data-level="2.9.1" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#ridge-regression"><i class="fa fa-check"></i><b>2.9.1</b> Ridge Regression</a></li>
<li class="chapter" data-level="2.9.2" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#lasso-regression"><i class="fa fa-check"></i><b>2.9.2</b> Lasso Regression</a></li>
<li class="chapter" data-level="2.9.3" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#elastic-net-regression"><i class="fa fa-check"></i><b>2.9.3</b> Elastic Net Regression</a></li>
<li class="chapter" data-level="2.9.4" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#comparaci%C3%B3n-de-m%C3%A9todos"><i class="fa fa-check"></i><b>2.9.4</b> Comparación de métodos</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#consideraciones"><i class="fa fa-check"></i><b>2.10</b> Consideraciones</a></li>
<li class="chapter" data-level="2.11" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#sesgo-y-varianza"><i class="fa fa-check"></i><b>2.11</b> Sesgo y Varianza</a>
<ul>
<li class="chapter" data-level="2.11.1" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#sesgo"><i class="fa fa-check"></i><b>2.11.1</b> Sesgo</a></li>
<li class="chapter" data-level="2.11.2" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#varianza"><i class="fa fa-check"></i><b>2.11.2</b> Varianza</a></li>
<li class="chapter" data-level="2.11.3" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#compromiso-sesgovarianza"><i class="fa fa-check"></i><b>2.11.3</b> Compromiso sesgo–varianza</a></li>
<li class="chapter" data-level="2.11.4" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#en-regresi%C3%B3n-lineal"><i class="fa fa-check"></i><b>2.11.4</b> En regresión lineal</a></li>
</ul></li>
<li class="chapter" data-level="2.12" data-path="redes-neuronales-lineales-para-regresión.html"><a href="redes-neuronales-lineales-para-regresión.html#conclusi%C3%B3n-de-la-secci%C3%B3n"><i class="fa fa-check"></i><b>2.12</b> Conclusión de la sección</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="redes-neuronales-lineales-para-clasificación.html"><a href="redes-neuronales-lineales-para-clasificación.html"><i class="fa fa-check"></i><b>3</b> Redes neuronales Lineales para Clasificación</a>
<ul>
<li class="chapter" data-level="3.1" data-path="redes-neuronales-lineales-para-clasificación.html"><a href="redes-neuronales-lineales-para-clasificación.html#modelos-lineales-generalizados"><i class="fa fa-check"></i><b>3.1</b> Modelos Lineales Generalizados</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="redes-neuronales-lineales-para-clasificación.html"><a href="redes-neuronales-lineales-para-clasificación.html#historia-1"><i class="fa fa-check"></i><b>3.1.1</b> Historia</a></li>
<li class="chapter" data-level="3.1.2" data-path="redes-neuronales-lineales-para-clasificación.html"><a href="redes-neuronales-lineales-para-clasificación.html#definici%C3%B3n"><i class="fa fa-check"></i><b>3.1.2</b> Definición</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="redes-neuronales-lineales-para-clasificación.html"><a href="redes-neuronales-lineales-para-clasificación.html#regresi%C3%B3n-log%C3%ADstica-para-clasificaci%C3%B3n"><i class="fa fa-check"></i><b>3.2</b> Regresión Logística para Clasificación</a></li>
<li class="chapter" data-level="3.3" data-path="redes-neuronales-lineales-para-clasificación.html"><a href="redes-neuronales-lineales-para-clasificación.html#redes-neuronales"><i class="fa fa-check"></i><b>3.3</b> Redes neuronales</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="redes-neuronales-lineales-para-clasificación.html"><a href="redes-neuronales-lineales-para-clasificación.html#historia-2"><i class="fa fa-check"></i><b>3.3.1</b> Historia</a></li>
<li class="chapter" data-level="3.3.2" data-path="redes-neuronales-lineales-para-clasificación.html"><a href="redes-neuronales-lineales-para-clasificación.html#definici%C3%B3n-1"><i class="fa fa-check"></i><b>3.3.2</b> Definición</a></li>
<li class="chapter" data-level="3.3.3" data-path="redes-neuronales-lineales-para-clasificación.html"><a href="redes-neuronales-lineales-para-clasificación.html#neurona"><i class="fa fa-check"></i><b>3.3.3</b> Neurona</a></li>
<li class="chapter" data-level="3.3.4" data-path="redes-neuronales-lineales-para-clasificación.html"><a href="redes-neuronales-lineales-para-clasificación.html#redes-neuronales-1"><i class="fa fa-check"></i><b>3.3.4</b> Redes Neuronales</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="redes-neuronales-lineales-para-clasificación.html"><a href="redes-neuronales-lineales-para-clasificación.html#notas-adicionales"><i class="fa fa-check"></i>Notas adicionales</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html"><i class="fa fa-check"></i><b>4</b> Perceptrón Multicapa</a>
<ul>
<li class="chapter" data-level="4.1" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#perceptrones-multicapa"><i class="fa fa-check"></i><b>4.1</b> Perceptrones multicapa</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#capas-ocultas"><i class="fa fa-check"></i><b>4.1.1</b> Capas ocultas</a></li>
<li class="chapter" data-level="4.1.2" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#funciones-de-activaci%C3%B3n"><i class="fa fa-check"></i><b>4.1.2</b> Funciones de activación</a></li>
<li class="chapter" data-level="4.1.3" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#discusi%C3%B3n"><i class="fa fa-check"></i><b>4.1.3</b> Discusión</a></li>
<li class="chapter" data-level="4.1.4" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#ejercicios"><i class="fa fa-check"></i><b>4.1.4</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#implementaci%C3%B3n-de-perceptrones-multicapa"><i class="fa fa-check"></i><b>4.2</b> Implementación de Perceptrones Multicapa</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#implementaci%C3%B3n-desde-cero"><i class="fa fa-check"></i><b>4.2.1</b> Implementación desde Cero</a></li>
<li class="chapter" data-level="4.2.2" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#implementaci%C3%B3n"><i class="fa fa-check"></i><b>4.2.2</b> Implementación</a></li>
<li class="chapter" data-level="4.2.3" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#ejercicios-1"><i class="fa fa-check"></i><b>4.2.3</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#forward-propagation-backward-propagation"><i class="fa fa-check"></i><b>4.3</b> Forward Propagation, Backward Propagation</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#forward-propagation"><i class="fa fa-check"></i><b>4.3.1</b> Forward Propagation</a></li>
<li class="chapter" data-level="4.3.2" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#backpropagation"><i class="fa fa-check"></i><b>4.3.2</b> Backpropagation</a></li>
<li class="chapter" data-level="4.3.3" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#resumen-6"><i class="fa fa-check"></i><b>4.3.3</b> Resumen</a></li>
<li class="chapter" data-level="4.3.4" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#ejercicios-2"><i class="fa fa-check"></i><b>4.3.4</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#estabilidad-num%C3%A9rica-e-inicializaci%C3%B3n"><i class="fa fa-check"></i><b>4.4</b> Estabilidad Numérica e Inicialización</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#explotaci%C3%B3n-y-desvanecimiento-de-gradientes"><i class="fa fa-check"></i><b>4.4.1</b> Explotación y Desvanecimiento de Gradientes</a></li>
<li class="chapter" data-level="4.4.2" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#inicializaci%C3%B3n-param%C3%A9trica"><i class="fa fa-check"></i><b>4.4.2</b> Inicialización paramétrica</a></li>
<li class="chapter" data-level="4.4.3" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#ejercicios-3"><i class="fa fa-check"></i><b>4.4.3</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#generalizaci%C3%B3n-en-deep-learning"><i class="fa fa-check"></i><b>4.5</b> Generalización en Deep Learning</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#sobreajuste-y-regularizaci%C3%B3n"><i class="fa fa-check"></i><b>4.5.1</b> Sobreajuste y Regularización</a></li>
<li class="chapter" data-level="4.5.2" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#inspiraci%C3%B3n-de-los-no-param%C3%A9tricos"><i class="fa fa-check"></i><b>4.5.2</b> Inspiración de los no paramétricos</a></li>
<li class="chapter" data-level="4.5.3" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#early-stopping"><i class="fa fa-check"></i><b>4.5.3</b> Early Stopping</a></li>
<li class="chapter" data-level="4.5.4" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#m%C3%A9todos-cl%C3%A1sicos-de-regularizaci%C3%B3n-para-redes-profundas"><i class="fa fa-check"></i><b>4.5.4</b> Métodos clásicos de regularización para redes profundas</a></li>
<li class="chapter" data-level="4.5.5" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#ejercicios-4"><i class="fa fa-check"></i><b>4.5.5</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#dropout"><i class="fa fa-check"></i><b>4.6</b> Dropout</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#dropout-en-la-pr%C3%A1ctica"><i class="fa fa-check"></i><b>4.6.1</b> Dropout en la práctica</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="perceptrón-multicapa.html"><a href="perceptrón-multicapa.html#ejemplo"><i class="fa fa-check"></i><b>4.7</b> Ejemplo</a></li>
</ul></li>
<li class="part"><span><b>Parte 2: Técnicas Modernas de Deep Learning</b></span></li>
<li class="chapter" data-level="5" data-path="guía-del-constructor.html"><a href="guía-del-constructor.html"><i class="fa fa-check"></i><b>5</b> Guía del Constructor</a></li>
<li class="chapter" data-level="6" data-path="redes-neuronales-convolucionales.html"><a href="redes-neuronales-convolucionales.html"><i class="fa fa-check"></i><b>6</b> Redes Neuronales Convolucionales</a></li>
<li class="chapter" data-level="7" data-path="redes-neuronales-convolucionales-modernas.html"><a href="redes-neuronales-convolucionales-modernas.html"><i class="fa fa-check"></i><b>7</b> Redes Neuronales Convolucionales Modernas</a></li>
<li class="chapter" data-level="8" data-path="redes-neuronales-recurrentes.html"><a href="redes-neuronales-recurrentes.html"><i class="fa fa-check"></i><b>8</b> Redes Neuronales Recurrentes</a></li>
<li class="chapter" data-level="9" data-path="redes-neuronales-recurrentes-modernas.html"><a href="redes-neuronales-recurrentes-modernas.html"><i class="fa fa-check"></i><b>9</b> Redes Neuronales Recurrentes Modernas</a></li>
<li class="chapter" data-level="10" data-path="mecanismos-de-atención-y-transformers.html"><a href="mecanismos-de-atención-y-transformers.html"><i class="fa fa-check"></i><b>10</b> Mecanismos de Atención y Transformers</a></li>
<li class="part"><span><b>Parte 3: Escalabilidad, Eficiencia y Aplicaciones</b></span></li>
<li class="chapter" data-level="11" data-path="algoritmos-de-optimización.html"><a href="algoritmos-de-optimización.html"><i class="fa fa-check"></i><b>11</b> Algoritmos de Optimización</a></li>
<li class="divider"></li>
<li><a href="./"><img src="img/aif-logo.png" width="280"></a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Deep Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="perceptrón-multicapa" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">Capítulo 4</span> Perceptrón Multicapa<a href="perceptrón-multicapa.html#perceptr%C3%B3n-multicapa" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="perceptrones-multicapa" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Perceptrones multicapa<a href="perceptrón-multicapa.html#perceptrones-multicapa" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En la Sección anterior, se presentó la regresión softmax, implementando el algoritmo desde cero. Esto permitió entrenar clasificadores capaces de reconocer 10 categorías de prendas de vestir a partir de imágenes de baja resolución. Durante el proceso, aprendimos a manipular los datos, a convertir las salidas en una distribución de probabilidad válida, a aplicar una función de pérdida adecuada y a minimizarla con respecto a los parámetros del modelo. Ahora que se conocen estos aspectos en el contexto de modelos lineales simples, podemos comenzar la exploración de las redes neuronales profundas, la clase de modelos relativamente rica que constituye el tema principal de este curso.</p>
<div id="capas-ocultas" class="section level3 hasAnchor" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> Capas ocultas<a href="perceptrón-multicapa.html#capas-ocultas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En la sección 3.1., se describen las transformaciones afines como transformaciones lineales con un sesgo añadido. Para empezar, recordemos la arquitectura del modelo correspondiente a nuestro ejemplo de regresión softmax, ilustrado en la figura 4.1.1. Este modelo asigna directamente las entradas a las salidas mediante una única transformación afín, seguida de una operación softmax. Si nuestras etiquetas estuvieran realmente relacionadas con los datos de entrada mediante una simple transformación afín, este enfoque sería suficiente. Sin embargo, la linealidad (en las transformaciones afines) es una suposición muy restrictiva.</p>
<p><img src="img/04_Linear_Neural_Networks_for_Classification/fig15.png" width="650pt" height="300pt" style="display: block; margin: auto;" /></p>
<div id="limitaciones-de-los-modelos-lineales" class="section level4 hasAnchor" number="4.1.1.1">
<h4><span class="header-section-number">4.1.1.1</span> Limitaciones de los modelos lineales<a href="perceptrón-multicapa.html#limitaciones-de-los-modelos-lineales" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>La linealidad supone una relación monotónica: si una variable aumenta, la salida del modelo siempre sube o baja según el signo del peso. Esto a veces es razonable, como al predecir el pago de un préstamo según ingresos, aunque la relación no sea estrictamente lineal. En estos casos, funciones como la logística pueden hacer más plausible la linealidad.</p>
<p>Sin embargo, muchas relaciones reales no son monotónicas. Por ejemplo, la temperatura corporal: valores por encima o por debajo de 37 °C aumentan el riesgo, por lo que conviene transformar la variable (p. ej., usar la distancia a 37 °C).</p>
<p><img src="img/05_Multilayer_Perceptron/lineal_vs_no_lineal.png" width="650pt" height="300pt" style="display: block; margin: auto;" /></p>
<p>En problemas como la clasificación de imágenes, la linealidad es claramente insuficiente: cambiar el brillo de un solo píxel no determina si hay un gato o un perro. Aquí el significado de cada píxel depende de su contexto, y no existe un preprocesamiento simple que lo capture. Las redes neuronales profundas resuelven esto aprendiendo simultáneamente una representación adecuada y un predictor lineal sobre esa representación.</p>
<p>La necesidad de modelar no linealidades se conoce desde hace un siglo y ha dado lugar a enfoques como árboles de decisión, métodos kernel, splines y, más recientemente, redes neuronales, inspiradas en las conexiones jerárquicas entre neuronas del cerebro.</p>
</div>
<div id="incorporación-de-capas-ocultas" class="section level4 hasAnchor" number="4.1.1.2">
<h4><span class="header-section-number">4.1.1.2</span> Incorporación de Capas Ocultas<a href="perceptrón-multicapa.html#incorporaci%C3%B3n-de-capas-ocultas" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Para superar las limitaciones de los modelos lineales, podemos agregar capas ocultas. La idea más básica es apilar varias capas totalmente conectadas: cada capa envía su salida a la siguiente. Las primeras capas aprenden una representación de los datos y la última capa actúa como un modelo lineal sobre esa representación.</p>
<p>A esta arquitectura se le llama perceptrón multicapa o MLP.</p>
<p>Observa la siguiente imagen que contempla un MLP con 4 entradas, 1 capa oculta con 5 neuronas y 3 salidas. Como la capa de entrada no calcula nada, realmente el modelo tiene 2 capas de cálculo: la oculta y la de salida.</p>
<p><img src="img/05_Multilayer_Perceptron/MLP01_example.png" width="650pt" height="300pt" style="display: block; margin: auto;" /></p>
<p>En un MLP, cada neurona de una capa está conectada con todas las neuronas de la siguiente. Es decir, cada entrada afecta a todas las neuronas ocultas, y cada una de estas afecta a todas las neuronas de salida.</p>
</div>
<div id="de-lo-lineal-a-lo-no-lineal" class="section level4 hasAnchor" number="4.1.1.3">
<h4><span class="header-section-number">4.1.1.3</span> De lo Lineal a lo No Lineal<a href="perceptrón-multicapa.html#de-lo-lineal-a-lo-no-lineal" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Como antes, denotamos con la matriz <span class="math inline">\(X \in \mathbb{R}^{n \times d}\)</span> un minibatch de <span class="math inline">\(n\)</span> ejemplos, donde cada ejemplo tiene <span class="math inline">\(d\)</span> entradas (características). Para un MLP de una capa oculta cuya capa oculta tiene <span class="math inline">\(h\)</span> unidades ocultas, denotamos por <span class="math inline">\(H \in \mathbb{R}^{n \times h}\)</span> las salidas de la capa oculta, que son representaciones ocultas. Dado que las capas oculta y de salida están completamente conectadas, tenemos pesos de capas ocultas <span class="math inline">\(W^{(1)} \in \mathbb{R}^{d \times h}\)</span> y sesgos <span class="math inline">\(b^{(1)} \in \mathbb{R}^{1 \times h}\)</span> y pesos <span class="math inline">\(W^{(2)} \in \mathbb{R}^{h \times q}\)</span> y sesgos <span class="math inline">\(b^{(2)} \in \mathbb{R}^{1 \times q}\)</span> de la capa de salida. Esto nos permite calcular las salidas <span class="math inline">\(O \in \mathbb{R}^{n \times q}\)</span> del MLP de una capa oculta de la siguiente manera:</p>
<p><span class="math display">\[
H=XW^{(1)}+b^{(1)},
\]</span>
<span class="math display">\[
O=HW^{(2)}+b^{(2)}.
\]</span></p>
<div class="infobox important">
<p><strong>¡¡ RECORDATORIO !!</strong></p>
<p>Una función “Afín” está dada por: <span class="math inline">\(f(x)=Ax+b\)</span>,</p>
<p>Mientras que una función lineal está dado por: <span class="math inline">\(f(x)=Ax\)</span></p>
</div>
<p>Hay que tener en cuenta que, tras añadir la capa oculta, el modelo requiere que se rastree y actualicen conjuntos adicionales de parámetros. ¿Qué se ha ganado a cambio? Sorprendentemente, el modelo definido anteriormente, ¡NO GANA NADA! y la razón es sencilla. Las unidades ocultas anteriores se dan mediante una función afín de las entradas, y las salidas (pre-softmax) son simplemente una función afín de las unidades ocultas. La composición de funciones afines es todavía una función afín. Además, el modelo lineal ya era capaz de representar cualquier función afín.</p>
<p>Para verlo formalmente, se puede simplemente colapsar la capa oculta en la definición anterior, lo que genera un modelo equivalente de una sola capa con parámetros.</p>
<p><span class="math display">\[
W=W^{(1)}W^{(2)} \text{ and } b=b^{1}W^{(2)}+b^{(2)}:
\]</span>
<span class="math display">\[
O=(XW^{(1)}+b^{(1)})W^{(2)}+b^{(2)}=XW^{(1)}W^{(2)}+b^{(1)}W^{(2)}+b^{(2)}=XW+b
\]</span></p>
<p>Para aprovechar el potencial de las arquitecturas multicapa, se necesita un ingrediente clave adicional: <strong>una función de activación no lineal</strong> que se aplique a cada unidad oculta tras la transformación afín. na opción popular es la función de activación ReLU (unidad lineal rectificada) (Nair y Hinton, 2010) <span class="math inline">\(\sigma(x)=max(0, x)\)</span>, que opera sobre sus argumentos elemento por elemento. Las salidas de las funciones de activación <span class="math inline">\(\sigma(\cdot)\)</span> se denominan <strong>activaciones</strong>. En general, con las funciones de activación establecidas, ya no es posible convertir el MLP en un modelo lineal:</p>
<p><span class="math display">\[
H=\sigma(XW^{(1)}+b^{(1)}),
\]</span>
<span class="math display">\[
O=HW^{(2)}+b^{(2)}.
\]</span></p>
<p>Dado que cada fila en <span class="math inline">\(X\)</span> corresponde a un ejemplo en el minibatch, con cierto abuso de notación, definimos la no linealidad <span class="math inline">\(\sigma\)</span> para aplicarla a sus entradas por filas, es decir, un ejemplo a la vez. Con frecuencia, las funciones de activación se aplican no solo por filas, sino también por elementos. Esto significa que, tras calcular la parte lineal de la capa, se calcula cada activación sin tener en cuenta los valores tomados por las demás unidades ocultas.</p>
</div>
<div id="aproximadores-universales" class="section level4 hasAnchor" number="4.1.1.4">
<h4><span class="header-section-number">4.1.1.4</span> Aproximadores Universales<a href="perceptrón-multicapa.html#aproximadores-universales" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="infobox quicktip">
<p><strong>¿Qué es un aproximador universal?</strong></p>
<p>Es un resultado teórico que dice que <strong>una red neuronal con una sola capa oculta puede representar prácticamente cualquier función</strong>, si tiene suficientes neuronas y parámetros.</p>
</div>
<p><strong>Pero ojo:</strong></p>
<p>Que pueda representar cualquier función no significa que sea fácil aprenderla. Tener una sola capa oculta puede requerir muchísimas neuronas (algo poco práctico). A veces es mejor usar: métodos de kernels, cuando aplican, porque resuelven el problema de forma exacta; redes más profundas, que permiten representar las mismas funciones de manera más compacta y eficiente.</p>
<p><strong>Idea didáctica clave</strong></p>
<p>La profundidad importa. Con suficiente profundidad, una red puede aprender funciones complejas de forma más eficiente que una red muy ancha con una sola capa.</p>
</div>
</div>
<div id="funciones-de-activación" class="section level3 hasAnchor" number="4.1.2">
<h3><span class="header-section-number">4.1.2</span> Funciones de activación<a href="perceptrón-multicapa.html#funciones-de-activaci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Las funciones de activación determinan si una neurona debe activarse o no calculando la suma ponderada y agregándole un sesgo. Son operadores diferenciables que transforman señales de entrada en salidas, y la mayoría añade no linealidad. Dado que las funciones de activación son fundamentales para el aprendizaje profundo, se revisarán algunas de las más comunes.</p>
<div id="función-relu" class="section level4 hasAnchor" number="4.1.2.1">
<h4><span class="header-section-number">4.1.2.1</span> Función ReLU<a href="perceptrón-multicapa.html#funci%C3%B3n-relu" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>La opción más popular, debido tanto a su simplicidad de implementación como a su buen rendimiento en diversas tareas predictivas, es la unidad lineal rectificada (ReLU) (Nair y Hinton, 2010). ReLU proporciona una transformación no lineal muy simple. Dado un elemento , la función se define como el máximo de ese elemento y 0:</p>
<p><span class="math display">\[
ReLU(x)=max(x, 0).
\]</span></p>
<p>De manera informal, <strong>la función ReLU conserva solo los elementos positivos y descarta todos los negativos</strong> estableciendo las activaciones correspondientes a 0. Para una mayor comprensión, podemos representar gráficamente la función. Como se puede observar, la función de activación es lineal por partes.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="perceptrón-multicapa.html#cb1-1" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a href="perceptrón-multicapa.html#cb1-2" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="perceptrón-multicapa.html#cb1-3" tabindex="-1"></a></span>
<span id="cb1-4"><a href="perceptrón-multicapa.html#cb1-4" tabindex="-1"></a><span class="co"># Datos</span></span>
<span id="cb1-5"><a href="perceptrón-multicapa.html#cb1-5" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="op">-</span><span class="fl">8.0</span>, <span class="fl">8.0</span>, <span class="fl">0.1</span>)</span>
<span id="cb1-6"><a href="perceptrón-multicapa.html#cb1-6" tabindex="-1"></a>y <span class="op">=</span> torch.relu(x)</span>
<span id="cb1-7"><a href="perceptrón-multicapa.html#cb1-7" tabindex="-1"></a></span>
<span id="cb1-8"><a href="perceptrón-multicapa.html#cb1-8" tabindex="-1"></a><span class="co"># Gráfica</span></span>
<span id="cb1-9"><a href="perceptrón-multicapa.html#cb1-9" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="fl">2.5</span>))</span>
<span id="cb1-10"><a href="perceptrón-multicapa.html#cb1-10" tabindex="-1"></a>plt.plot(x, y)</span>
<span id="cb1-11"><a href="perceptrón-multicapa.html#cb1-11" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;x&quot;</span>)</span>
<span id="cb1-12"><a href="perceptrón-multicapa.html#cb1-12" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;ReLU(x)&quot;</span>)</span>
<span id="cb1-13"><a href="perceptrón-multicapa.html#cb1-13" tabindex="-1"></a>plt.title(<span class="st">&quot;Función de activación ReLU&quot;</span>)</span>
<span id="cb1-14"><a href="perceptrón-multicapa.html#cb1-14" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb1-15"><a href="perceptrón-multicapa.html#cb1-15" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p><img src="deep_learning_course_python_files/figure-html/unnamed-chunk-4-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Cuando la entrada es negativa, la derivada de la función ReLU es 0, y cuando la entrada es positiva, la derivada de la función ReLU es 1. Nótese que la función ReLU no es diferenciable cuando la entrada toma valor exactamente igual a 0. En estos casos, se usa por defecto la derivada del lado izquierdo y decimos que la derivada es 0 cuando la entrada es 0. Podemos evitar esto porque la entrada puede que nunca sea realmente cero (los matemáticos dirían que no es diferenciable en un conjunto de medida cero). Hay un viejo adagio que dice que si las condiciones de contorno sutiles importan, probablemente estemos haciendo matemáticas (reales), no ingeniería. Esa sabiduría convencional puede aplicarse aquí, o al menos, el hecho de que no estamos realizando optimización restringida (Mangasarian, 1965, Rockafellar, 1970). se traza la derivada de la función ReLU a continuación.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="perceptrón-multicapa.html#cb2-1" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="op">-</span><span class="fl">8.0</span>, <span class="fl">8.0</span>, <span class="fl">0.1</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-2"><a href="perceptrón-multicapa.html#cb2-2" tabindex="-1"></a>y <span class="op">=</span> torch.relu(x)</span>
<span id="cb2-3"><a href="perceptrón-multicapa.html#cb2-3" tabindex="-1"></a></span>
<span id="cb2-4"><a href="perceptrón-multicapa.html#cb2-4" tabindex="-1"></a>y.backward(torch.ones_like(x))</span>
<span id="cb2-5"><a href="perceptrón-multicapa.html#cb2-5" tabindex="-1"></a></span>
<span id="cb2-6"><a href="perceptrón-multicapa.html#cb2-6" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="fl">2.5</span>))</span>
<span id="cb2-7"><a href="perceptrón-multicapa.html#cb2-7" tabindex="-1"></a>plt.plot(x.detach(), x.grad)</span>
<span id="cb2-8"><a href="perceptrón-multicapa.html#cb2-8" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;x&#39;</span>)</span>
<span id="cb2-9"><a href="perceptrón-multicapa.html#cb2-9" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;grad ReLU(x)&#39;</span>)</span>
<span id="cb2-10"><a href="perceptrón-multicapa.html#cb2-10" tabindex="-1"></a>plt.title(<span class="st">&#39;Derivada de ReLU&#39;</span>)</span>
<span id="cb2-11"><a href="perceptrón-multicapa.html#cb2-11" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb2-12"><a href="perceptrón-multicapa.html#cb2-12" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p><img src="deep_learning_course_python_files/figure-html/unnamed-chunk-5-3.png" width="480" style="display: block; margin: auto;" /></p>
<p>La razón para usar ReLU es que sus derivadas se comportan particularmente bien: o se anulan o simplemente dejan pasar el argumento. Esto mejora el comportamiento de la optimización y mitiga el problema bien documentado de los gradientes evanescentes que afectaba a versiones anteriores de redes neuronales (más sobre esto más adelante).</p>
<p>Cabe destacar que existen muchas variantes de la función ReLU, incluyendo la función ReLU parametrizada (pReLU) (He et al., 2015). Esta variación añade un término lineal a ReLU, por lo que parte de la información se transmite, incluso cuando el argumento es negativo:</p>
<p><span class="math display">\[
pReLU(x)=max(0,x)+\alpha \cdot min(0,x).
\]</span></p>
</div>
<div id="función-sigmoide" class="section level4 hasAnchor" number="4.1.2.2">
<h4><span class="header-section-number">4.1.2.2</span> Función Sigmoide<a href="perceptrón-multicapa.html#funci%C3%B3n-sigmoide" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>La función sigmoidea transforma las entradas cuyos valores se encuentran en el dominio <span class="math inline">\(\mathbb{R}\)</span>, en salidas que se encuentran en el intervalo (0, 1). Por esta razón, la función sigmoidea suele denominarse función de aplastamiento (<em>squashing function</em>): aplasta cualquier entrada en el rango (-inf, inf) a un valor en el rango (0, 1):</p>
<p><span class="math display">\[
\text{sigmoid}(x)=\frac{1}{1+\text{exp}(-x)}
\]</span></p>
<p>A continuación, se grafica la función sigmoidea. Nótese que cuando la entrada se acerca a 0, la función sigmoidea se aproxima a una transformación lineal.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="perceptrón-multicapa.html#cb3-1" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="op">-</span><span class="fl">8.0</span>, <span class="fl">8.0</span>, <span class="fl">0.1</span>)</span>
<span id="cb3-2"><a href="perceptrón-multicapa.html#cb3-2" tabindex="-1"></a>y <span class="op">=</span> torch.sigmoid(x)</span>
<span id="cb3-3"><a href="perceptrón-multicapa.html#cb3-3" tabindex="-1"></a></span>
<span id="cb3-4"><a href="perceptrón-multicapa.html#cb3-4" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="fl">2.5</span>))</span>
<span id="cb3-5"><a href="perceptrón-multicapa.html#cb3-5" tabindex="-1"></a>plt.plot(x.detach(), y.detach())</span>
<span id="cb3-6"><a href="perceptrón-multicapa.html#cb3-6" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;x&quot;</span>)</span>
<span id="cb3-7"><a href="perceptrón-multicapa.html#cb3-7" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;sigmoid(x)&quot;</span>)</span>
<span id="cb3-8"><a href="perceptrón-multicapa.html#cb3-8" tabindex="-1"></a>plt.title(<span class="st">&quot;Función Sigmoid&quot;</span>)</span>
<span id="cb3-9"><a href="perceptrón-multicapa.html#cb3-9" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb3-10"><a href="perceptrón-multicapa.html#cb3-10" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p><img src="deep_learning_course_python_files/figure-html/unnamed-chunk-6-5.png" width="480" style="display: block; margin: auto;" /></p>
<p>La derivada de la función sigmoide está dada por la siguiente ecuación:</p>
<p><span class="math display">\[
\frac{d}{dx}\text{sigmoid}(x)=\frac{\text{exp(-x)}}{(1+\text{exp}(-x))^2}=\text{sigmoid}(x)(1-\text{sigmoid}(x))
\]</span></p>
<p>La derivada de la función sigmoidea se grafica a continuación. Nótese que cuando la entrada es 0, la derivada de la función sigmoidea alcanza un máximo de 0,25. A medida que la entrada diverge de 0 en cualquier dirección, la derivada tiende a 0.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="perceptrón-multicapa.html#cb4-1" tabindex="-1"></a><span class="co"># Definir x con gradientes</span></span>
<span id="cb4-2"><a href="perceptrón-multicapa.html#cb4-2" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="op">-</span><span class="fl">8.0</span>, <span class="fl">8.0</span>, <span class="fl">0.1</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-3"><a href="perceptrón-multicapa.html#cb4-3" tabindex="-1"></a>y <span class="op">=</span> torch.sigmoid(x)</span>
<span id="cb4-4"><a href="perceptrón-multicapa.html#cb4-4" tabindex="-1"></a></span>
<span id="cb4-5"><a href="perceptrón-multicapa.html#cb4-5" tabindex="-1"></a><span class="co"># Borrar gradientes previos (si los hubiera)</span></span>
<span id="cb4-6"><a href="perceptrón-multicapa.html#cb4-6" tabindex="-1"></a><span class="cf">if</span> x.grad <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb4-7"><a href="perceptrón-multicapa.html#cb4-7" tabindex="-1"></a>    x.grad.zero_()</span>
<span id="cb4-8"><a href="perceptrón-multicapa.html#cb4-8" tabindex="-1"></a></span>
<span id="cb4-9"><a href="perceptrón-multicapa.html#cb4-9" tabindex="-1"></a><span class="co"># Backprop para obtener la derivada</span></span>
<span id="cb4-10"><a href="perceptrón-multicapa.html#cb4-10" tabindex="-1"></a>y.backward(torch.ones_like(x), retain_graph<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-11"><a href="perceptrón-multicapa.html#cb4-11" tabindex="-1"></a></span>
<span id="cb4-12"><a href="perceptrón-multicapa.html#cb4-12" tabindex="-1"></a><span class="co"># Graficar</span></span>
<span id="cb4-13"><a href="perceptrón-multicapa.html#cb4-13" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="fl">2.5</span>))</span>
<span id="cb4-14"><a href="perceptrón-multicapa.html#cb4-14" tabindex="-1"></a>plt.plot(x.detach(), x.grad.detach())</span>
<span id="cb4-15"><a href="perceptrón-multicapa.html#cb4-15" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;x&quot;</span>)</span>
<span id="cb4-16"><a href="perceptrón-multicapa.html#cb4-16" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;grad sigmoid(x)&quot;</span>)</span>
<span id="cb4-17"><a href="perceptrón-multicapa.html#cb4-17" tabindex="-1"></a>plt.title(<span class="st">&quot;Derivada de la función Sigmoid&quot;</span>)</span>
<span id="cb4-18"><a href="perceptrón-multicapa.html#cb4-18" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb4-19"><a href="perceptrón-multicapa.html#cb4-19" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p><img src="deep_learning_course_python_files/figure-html/unnamed-chunk-7-7.png" width="480" style="display: block; margin: auto;" /></p>
</div>
<div id="función-tanh" class="section level4 hasAnchor" number="4.1.2.3">
<h4><span class="header-section-number">4.1.2.3</span> Función Tanh<a href="perceptrón-multicapa.html#funci%C3%B3n-tanh" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Al igual que la función sigmoidea, la función tangente hiperbólica también reduce sus valores de entrada, transformándolos en elementos del intervalo entre -1 y 1.</p>
<p><span class="math display">\[
\text{tanh}(x)=\frac{1-\text{exp}(-2x)}{1+\text{exp}(-2x)}
\]</span></p>
<p>Nótese que, a medida que la entrada se acerca a 0, la función tanh se aproxima a una transformación lineal. Aunque la forma de la función es similar a la de la función sigmoidea, la función tanh presenta <strong>simetría puntual respecto al origen</strong> del sistema de coordenadas (Kalman y Kwasny, 1992).</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="perceptrón-multicapa.html#cb5-1" tabindex="-1"></a><span class="co"># Datos</span></span>
<span id="cb5-2"><a href="perceptrón-multicapa.html#cb5-2" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="op">-</span><span class="fl">8.0</span>, <span class="fl">8.0</span>, <span class="fl">0.1</span>)</span>
<span id="cb5-3"><a href="perceptrón-multicapa.html#cb5-3" tabindex="-1"></a>y <span class="op">=</span> torch.tanh(x)</span>
<span id="cb5-4"><a href="perceptrón-multicapa.html#cb5-4" tabindex="-1"></a></span>
<span id="cb5-5"><a href="perceptrón-multicapa.html#cb5-5" tabindex="-1"></a><span class="co"># Gráfica</span></span>
<span id="cb5-6"><a href="perceptrón-multicapa.html#cb5-6" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="fl">2.5</span>))</span>
<span id="cb5-7"><a href="perceptrón-multicapa.html#cb5-7" tabindex="-1"></a>plt.plot(x.detach(), y.detach())</span>
<span id="cb5-8"><a href="perceptrón-multicapa.html#cb5-8" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;x&quot;</span>)</span>
<span id="cb5-9"><a href="perceptrón-multicapa.html#cb5-9" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;tanh(x)&quot;</span>)</span>
<span id="cb5-10"><a href="perceptrón-multicapa.html#cb5-10" tabindex="-1"></a>plt.title(<span class="st">&quot;Función tanh&quot;</span>)</span>
<span id="cb5-11"><a href="perceptrón-multicapa.html#cb5-11" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb5-12"><a href="perceptrón-multicapa.html#cb5-12" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p><img src="deep_learning_course_python_files/figure-html/unnamed-chunk-8-9.png" width="480" style="display: block; margin: auto;" /></p>
<p>La derivada de la función <em>tanh</em> es:</p>
<p><span class="math display">\[
\frac{d}{dx}\text{tanh}(x)=1-\text{tanh}^{2}(x)
\]</span></p>
<p>A medida que la entrada se acerca a 0, la derivada de la función <em>tanh</em> se acerca a un máximo de 1. Y, como se vio con la función sigmoidea, a medida que la entrada se aleja de 0 en cualquier dirección, la derivada de la función <em>tanh</em> se acerca a 0.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="perceptrón-multicapa.html#cb6-1" tabindex="-1"></a><span class="co"># Definir x con gradientes activados</span></span>
<span id="cb6-2"><a href="perceptrón-multicapa.html#cb6-2" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="op">-</span><span class="fl">8.0</span>, <span class="fl">8.0</span>, <span class="fl">0.1</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-3"><a href="perceptrón-multicapa.html#cb6-3" tabindex="-1"></a>y <span class="op">=</span> torch.tanh(x)</span>
<span id="cb6-4"><a href="perceptrón-multicapa.html#cb6-4" tabindex="-1"></a></span>
<span id="cb6-5"><a href="perceptrón-multicapa.html#cb6-5" tabindex="-1"></a><span class="co"># Borrar gradientes anteriores</span></span>
<span id="cb6-6"><a href="perceptrón-multicapa.html#cb6-6" tabindex="-1"></a><span class="cf">if</span> x.grad <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb6-7"><a href="perceptrón-multicapa.html#cb6-7" tabindex="-1"></a>    x.grad.zero_()</span>
<span id="cb6-8"><a href="perceptrón-multicapa.html#cb6-8" tabindex="-1"></a></span>
<span id="cb6-9"><a href="perceptrón-multicapa.html#cb6-9" tabindex="-1"></a><span class="co"># Backprop para obtener la derivada</span></span>
<span id="cb6-10"><a href="perceptrón-multicapa.html#cb6-10" tabindex="-1"></a>y.backward(torch.ones_like(x), retain_graph<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-11"><a href="perceptrón-multicapa.html#cb6-11" tabindex="-1"></a></span>
<span id="cb6-12"><a href="perceptrón-multicapa.html#cb6-12" tabindex="-1"></a><span class="co"># Graficar la derivada</span></span>
<span id="cb6-13"><a href="perceptrón-multicapa.html#cb6-13" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="fl">2.5</span>))</span>
<span id="cb6-14"><a href="perceptrón-multicapa.html#cb6-14" tabindex="-1"></a>plt.plot(x.detach(), x.grad.detach())</span>
<span id="cb6-15"><a href="perceptrón-multicapa.html#cb6-15" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;x&quot;</span>)</span>
<span id="cb6-16"><a href="perceptrón-multicapa.html#cb6-16" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;grad tanh(x)&quot;</span>)</span>
<span id="cb6-17"><a href="perceptrón-multicapa.html#cb6-17" tabindex="-1"></a>plt.title(<span class="st">&quot;Derivada de la función tanh&quot;</span>)</span>
<span id="cb6-18"><a href="perceptrón-multicapa.html#cb6-18" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb6-19"><a href="perceptrón-multicapa.html#cb6-19" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p><img src="deep_learning_course_python_files/figure-html/unnamed-chunk-9-11.png" width="480" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="discusión" class="section level3 hasAnchor" number="4.1.3">
<h3><span class="header-section-number">4.1.3</span> Discusión<a href="perceptrón-multicapa.html#discusi%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Ahora sabemos cómo incorporar <strong>no linealidades</strong> para construir arquitecturas expresivas de redes neuronales multicapa. Una ventaja de la función ReLU es que es significativamente más fácil de optimizar que la función sigmoidea o la función tanh. Se podría argumentar que esta fue una de las innovaciones clave que impulsaron el resurgimiento del aprendizaje profundo en la última década.</p>
<p>Cabe destacar, sin embargo, que la investigación en funciones de activación no se ha detenido. Por ejemplo, la función de activación GELU (unidad lineal de error gaussiano) <span class="math inline">\(x\phi(x)\)</span> de Hendrycks y Gimpel (2016) <span class="math inline">\(\phi(x)\)</span> (es la función de distribución acumulativa gaussiana estándar) y la función de activación <em>Swish</em> <span class="math inline">\(\sigma(x)=x\cdot\text{sigmoid}(\beta x)\)</span>, propuesta por Ramachandran et al. (2017), pueden ofrecer una mayor precisión en muchos casos.</p>
</div>
<div id="ejercicios" class="section level3 hasAnchor" number="4.1.4">
<h3><span class="header-section-number">4.1.4</span> Ejercicios<a href="perceptrón-multicapa.html#ejercicios" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><p>Demuestre que añadir capas a una red lineal profunda, es decir, una red sin no linealidad <span class="math inline">\(\sigma\)</span>, nunca puede aumentar su potencia expresiva. Dé un ejemplo donde la reduzca activamente.</p></li>
<li><p>Calcule la derivada de la función de activación pReLU.</p></li>
<li><p>Calcule la derivada de la función de activación Swish <span class="math inline">\(x\cdot \text{sigmoid}(\beta x)\)</span>.</p></li>
<li><p>Demuestre que una MLP que utiliza solo ReLU (o pReLU) construye una función lineal continua por partes.</p></li>
<li><p>Sigmoid y tanh son muy similares.</p></li>
</ol>
<ul>
<li><p>Demuestre que <span class="math inline">\(\text{tanh}(x)+1 = 2\text{sigmoid}(2x)\)</span>.</p></li>
<li><p>Demuestre que las clases de función parametrizadas por ambas no linealidades son idénticas. Pista: las capas afines también tienen términos de sesgo.</p></li>
</ul>
<ol start="6" style="list-style-type: decimal">
<li><p>Suponga que tenemos una no linealidad que se aplica a un minibatch a la vez, como la normalización por lotes (Ioffe y Szegedy, 2015). ¿Qué tipo de problemas espera que esto cause?</p></li>
<li><p>Dé un ejemplo donde los gradientes se anulen para la función de activación sigmoide.</p></li>
</ol>
</div>
</div>
<div id="implementación-de-perceptrones-multicapa" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Implementación de Perceptrones Multicapa<a href="perceptrón-multicapa.html#implementaci%C3%B3n-de-perceptrones-multicapa" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Los perceptrones multicapa (MLP) no son mucho más complejos de implementar que los modelos lineales simples. La diferencia conceptual clave radica en que ahora se concatenan múltiples capas.</p>
<div id="implementación-desde-cero" class="section level3 hasAnchor" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Implementación desde Cero<a href="perceptrón-multicapa.html#implementaci%C3%B3n-desde-cero" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Comencemos de nuevo implementando dicha red desde cero.</p>
<div id="inicialización-de-parámetros-del-modelo" class="section level4 hasAnchor" number="4.2.1.1">
<h4><span class="header-section-number">4.2.1.1</span> Inicialización de parámetros del modelo<a href="perceptrón-multicapa.html#inicializaci%C3%B3n-de-par%C3%A1metros-del-modelo" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>El conjunto de datos <strong>Fashion-MNIST</strong> contiene 10 clases de imágenes y cada imagen consiste en una cuadrícula de valores de píxeles en escala de grises. Como antes, por ahora ignoraremos la estructura espacial entre los píxeles, por lo que podemos considerarlo como un conjunto de datos de clasificación con 784 características de entrada y 10 clases. Para comenzar, implementaremos un MLP con una capa oculta y 256 unidades ocultas. Tanto el número de capas como su ancho son ajustables (se consideran hiperparámetros).</p>
<div class="infobox quicktip">
<p><strong>Tip:</strong></p>
<p>Normalmente, se busca que <strong>el ancho de las capas (número de neuronas) sea divisible por potencias mayores de 2</strong>, es decir: 4, 8, 16, 32, 64, 128, 256, 512, etc. Esto es computacionalmente eficiente debido a que las GPUs trabajan internamente con bloques de tamaño 32 y potencias de 2, haciendo que esos anchos sean:</p>
<ul>
<li>Más rápidos</li>
<li>Más fáciles de paralelizar</li>
<li>Más eficientes en memoria</li>
</ul>
</div>
<p>De nuevo, representaremos nuestros parámetros con varios tensores. Tenga en cuenta que, para cada capa, debemos registrar una matriz de ponderación y un vector de sesgo. Es importante tomar en cuenta la asignación de memoria para los gradientes de pérdida con respecto a estos parámetros.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="perceptrón-multicapa.html#cb7-1" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb7-2"><a href="perceptrón-multicapa.html#cb7-2" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb7-3"><a href="perceptrón-multicapa.html#cb7-3" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-4"><a href="perceptrón-multicapa.html#cb7-4" tabindex="-1"></a><span class="im">import</span> inspect</span>
<span id="cb7-5"><a href="perceptrón-multicapa.html#cb7-5" tabindex="-1"></a></span>
<span id="cb7-6"><a href="perceptrón-multicapa.html#cb7-6" tabindex="-1"></a><span class="kw">class</span> Module(nn.Module):</span>
<span id="cb7-7"><a href="perceptrón-multicapa.html#cb7-7" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb7-8"><a href="perceptrón-multicapa.html#cb7-8" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb7-9"><a href="perceptrón-multicapa.html#cb7-9" tabindex="-1"></a>        <span class="va">self</span>.metrics <span class="op">=</span> {}</span>
<span id="cb7-10"><a href="perceptrón-multicapa.html#cb7-10" tabindex="-1"></a></span>
<span id="cb7-11"><a href="perceptrón-multicapa.html#cb7-11" tabindex="-1"></a>    <span class="kw">def</span> save_hyperparameters(<span class="va">self</span>, ignore<span class="op">=</span>[]):</span>
<span id="cb7-12"><a href="perceptrón-multicapa.html#cb7-12" tabindex="-1"></a>        frame <span class="op">=</span> inspect.currentframe().f_back</span>
<span id="cb7-13"><a href="perceptrón-multicapa.html#cb7-13" tabindex="-1"></a>        _, _, _, local_vars <span class="op">=</span> inspect.getargvalues(frame)</span>
<span id="cb7-14"><a href="perceptrón-multicapa.html#cb7-14" tabindex="-1"></a>        <span class="cf">for</span> k, v <span class="kw">in</span> local_vars.items():</span>
<span id="cb7-15"><a href="perceptrón-multicapa.html#cb7-15" tabindex="-1"></a>            <span class="cf">if</span> k <span class="kw">not</span> <span class="kw">in</span> ignore <span class="kw">and</span> k <span class="op">!=</span> <span class="st">&quot;self&quot;</span>:</span>
<span id="cb7-16"><a href="perceptrón-multicapa.html#cb7-16" tabindex="-1"></a>                <span class="bu">setattr</span>(<span class="va">self</span>, k, v)</span>
<span id="cb7-17"><a href="perceptrón-multicapa.html#cb7-17" tabindex="-1"></a></span>
<span id="cb7-18"><a href="perceptrón-multicapa.html#cb7-18" tabindex="-1"></a>    <span class="kw">def</span> plot(<span class="va">self</span>, name, value, train<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb7-19"><a href="perceptrón-multicapa.html#cb7-19" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;Guarda valores para graficarlos al final.&quot;&quot;&quot;</span></span>
<span id="cb7-20"><a href="perceptrón-multicapa.html#cb7-20" tabindex="-1"></a>        key <span class="op">=</span> <span class="ss">f&quot;</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span><span class="st">&#39;train&#39;</span> <span class="cf">if</span> train <span class="cf">else</span> <span class="st">&#39;val&#39;</span><span class="sc">}</span><span class="ss">&quot;</span></span>
<span id="cb7-21"><a href="perceptrón-multicapa.html#cb7-21" tabindex="-1"></a>        <span class="cf">if</span> key <span class="kw">not</span> <span class="kw">in</span> <span class="va">self</span>.metrics:</span>
<span id="cb7-22"><a href="perceptrón-multicapa.html#cb7-22" tabindex="-1"></a>            <span class="va">self</span>.metrics[key] <span class="op">=</span> []</span>
<span id="cb7-23"><a href="perceptrón-multicapa.html#cb7-23" tabindex="-1"></a>        <span class="va">self</span>.metrics[key].append(value)</span>
<span id="cb7-24"><a href="perceptrón-multicapa.html#cb7-24" tabindex="-1"></a></span>
<span id="cb7-25"><a href="perceptrón-multicapa.html#cb7-25" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, X):</span>
<span id="cb7-26"><a href="perceptrón-multicapa.html#cb7-26" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">NotImplementedError</span>(<span class="st">&quot;Define forward() in subclass&quot;</span>)</span>
<span id="cb7-27"><a href="perceptrón-multicapa.html#cb7-27" tabindex="-1"></a></span>
<span id="cb7-28"><a href="perceptrón-multicapa.html#cb7-28" tabindex="-1"></a></span>
<span id="cb7-29"><a href="perceptrón-multicapa.html#cb7-29" tabindex="-1"></a><span class="kw">class</span> Classifier(Module):</span>
<span id="cb7-30"><a href="perceptrón-multicapa.html#cb7-30" tabindex="-1"></a>    <span class="kw">def</span> loss(<span class="va">self</span>, y_hat, y):</span>
<span id="cb7-31"><a href="perceptrón-multicapa.html#cb7-31" tabindex="-1"></a>        <span class="cf">return</span> nn.CrossEntropyLoss()(y_hat, y)</span>
<span id="cb7-32"><a href="perceptrón-multicapa.html#cb7-32" tabindex="-1"></a></span>
<span id="cb7-33"><a href="perceptrón-multicapa.html#cb7-33" tabindex="-1"></a>    <span class="kw">def</span> accuracy(<span class="va">self</span>, y_hat, y):</span>
<span id="cb7-34"><a href="perceptrón-multicapa.html#cb7-34" tabindex="-1"></a>        preds <span class="op">=</span> y_hat.argmax(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-35"><a href="perceptrón-multicapa.html#cb7-35" tabindex="-1"></a>        <span class="cf">return</span> (preds <span class="op">==</span> y).<span class="bu">float</span>().mean()</span>
<span id="cb7-36"><a href="perceptrón-multicapa.html#cb7-36" tabindex="-1"></a></span>
<span id="cb7-37"><a href="perceptrón-multicapa.html#cb7-37" tabindex="-1"></a>    <span class="co"># def train_step(self, batch):</span></span>
<span id="cb7-38"><a href="perceptrón-multicapa.html#cb7-38" tabindex="-1"></a>    <span class="co">#     X, y = batch</span></span>
<span id="cb7-39"><a href="perceptrón-multicapa.html#cb7-39" tabindex="-1"></a>    <span class="co">#     y_hat = self.forward(X)</span></span>
<span id="cb7-40"><a href="perceptrón-multicapa.html#cb7-40" tabindex="-1"></a>    <span class="co">#     loss = self.loss(y_hat, y)</span></span>
<span id="cb7-41"><a href="perceptrón-multicapa.html#cb7-41" tabindex="-1"></a>    <span class="co"># </span></span>
<span id="cb7-42"><a href="perceptrón-multicapa.html#cb7-42" tabindex="-1"></a>    <span class="co">#     # backprop</span></span>
<span id="cb7-43"><a href="perceptrón-multicapa.html#cb7-43" tabindex="-1"></a>    <span class="co">#     self.optimizer.zero_grad()</span></span>
<span id="cb7-44"><a href="perceptrón-multicapa.html#cb7-44" tabindex="-1"></a>    <span class="co">#     loss.backward()</span></span>
<span id="cb7-45"><a href="perceptrón-multicapa.html#cb7-45" tabindex="-1"></a>    <span class="co">#     self.optimizer.step()</span></span>
<span id="cb7-46"><a href="perceptrón-multicapa.html#cb7-46" tabindex="-1"></a>    <span class="co"># </span></span>
<span id="cb7-47"><a href="perceptrón-multicapa.html#cb7-47" tabindex="-1"></a>    <span class="co">#     return loss.item(), self.accuracy(y_hat, y).item()</span></span>
<span id="cb7-48"><a href="perceptrón-multicapa.html#cb7-48" tabindex="-1"></a>       </span>
<span id="cb7-49"><a href="perceptrón-multicapa.html#cb7-49" tabindex="-1"></a>    <span class="kw">def</span> evaluation_step(<span class="va">self</span>, X, y):</span>
<span id="cb7-50"><a href="perceptrón-multicapa.html#cb7-50" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb7-51"><a href="perceptrón-multicapa.html#cb7-51" tabindex="-1"></a>            y_hat <span class="op">=</span> <span class="va">self</span>(X)</span>
<span id="cb7-52"><a href="perceptrón-multicapa.html#cb7-52" tabindex="-1"></a>            <span class="cf">return</span> (</span>
<span id="cb7-53"><a href="perceptrón-multicapa.html#cb7-53" tabindex="-1"></a>                <span class="va">self</span>.loss(y_hat, y).item(),</span>
<span id="cb7-54"><a href="perceptrón-multicapa.html#cb7-54" tabindex="-1"></a>                <span class="va">self</span>.accuracy(y_hat, y).item(),</span>
<span id="cb7-55"><a href="perceptrón-multicapa.html#cb7-55" tabindex="-1"></a>            )</span>
<span id="cb7-56"><a href="perceptrón-multicapa.html#cb7-56" tabindex="-1"></a></span>
<span id="cb7-57"><a href="perceptrón-multicapa.html#cb7-57" tabindex="-1"></a></span>
<span id="cb7-58"><a href="perceptrón-multicapa.html#cb7-58" tabindex="-1"></a></span>
<span id="cb7-59"><a href="perceptrón-multicapa.html#cb7-59" tabindex="-1"></a><span class="co"># ------ Decorador para agregar métodos ------</span></span>
<span id="cb7-60"><a href="perceptrón-multicapa.html#cb7-60" tabindex="-1"></a><span class="kw">def</span> add_to_class(cls):</span>
<span id="cb7-61"><a href="perceptrón-multicapa.html#cb7-61" tabindex="-1"></a>    <span class="kw">def</span> decorator(fn):</span>
<span id="cb7-62"><a href="perceptrón-multicapa.html#cb7-62" tabindex="-1"></a>        <span class="bu">setattr</span>(cls, fn.<span class="va">__name__</span>, fn)</span>
<span id="cb7-63"><a href="perceptrón-multicapa.html#cb7-63" tabindex="-1"></a>        <span class="cf">return</span> fn</span>
<span id="cb7-64"><a href="perceptrón-multicapa.html#cb7-64" tabindex="-1"></a>    <span class="cf">return</span> decorator</span></code></pre></div>
<p>En el código siguiente usamos nn.Parameter para registrar automáticamente un atributo de clase como un parámetro que será rastreado por autograd.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="perceptrón-multicapa.html#cb8-1" tabindex="-1"></a><span class="kw">class</span> MLPScratch(Classifier):</span>
<span id="cb8-2"><a href="perceptrón-multicapa.html#cb8-2" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_inputs, num_outputs, num_hiddens, lr, sigma<span class="op">=</span><span class="fl">0.01</span>):</span>
<span id="cb8-3"><a href="perceptrón-multicapa.html#cb8-3" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb8-4"><a href="perceptrón-multicapa.html#cb8-4" tabindex="-1"></a>        <span class="va">self</span>.save_hyperparameters()</span>
<span id="cb8-5"><a href="perceptrón-multicapa.html#cb8-5" tabindex="-1"></a>        <span class="va">self</span>.lr <span class="op">=</span> lr</span>
<span id="cb8-6"><a href="perceptrón-multicapa.html#cb8-6" tabindex="-1"></a></span>
<span id="cb8-7"><a href="perceptrón-multicapa.html#cb8-7" tabindex="-1"></a>        <span class="va">self</span>.W1 <span class="op">=</span> nn.Parameter(torch.randn(num_inputs, num_hiddens) <span class="op">*</span> sigma)</span>
<span id="cb8-8"><a href="perceptrón-multicapa.html#cb8-8" tabindex="-1"></a>        <span class="va">self</span>.b1 <span class="op">=</span> nn.Parameter(torch.zeros(num_hiddens))</span>
<span id="cb8-9"><a href="perceptrón-multicapa.html#cb8-9" tabindex="-1"></a>        </span>
<span id="cb8-10"><a href="perceptrón-multicapa.html#cb8-10" tabindex="-1"></a>        <span class="va">self</span>.W2 <span class="op">=</span> nn.Parameter(torch.randn(num_hiddens, num_outputs) <span class="op">*</span> sigma)</span>
<span id="cb8-11"><a href="perceptrón-multicapa.html#cb8-11" tabindex="-1"></a>        <span class="va">self</span>.b2 <span class="op">=</span> nn.Parameter(torch.zeros(num_outputs))</span></code></pre></div>
</div>
<div id="modelo" class="section level4 hasAnchor" number="4.2.1.2">
<h4><span class="header-section-number">4.2.1.2</span> Modelo<a href="perceptrón-multicapa.html#modelo" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Para asegurarnos de que sabemos cómo funciona todo, implementaremos la activación de ReLU nosotros mismos en lugar de invocar directamente la función relu incorporada.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="perceptrón-multicapa.html#cb9-1" tabindex="-1"></a><span class="kw">def</span> relu(X):</span>
<span id="cb9-2"><a href="perceptrón-multicapa.html#cb9-2" tabindex="-1"></a>    a <span class="op">=</span> torch.zeros_like(X)</span>
<span id="cb9-3"><a href="perceptrón-multicapa.html#cb9-3" tabindex="-1"></a>    <span class="cf">return</span> torch.<span class="bu">max</span>(X, a)</span></code></pre></div>
<p>Como ignoramos la estructura espacial, transformamos cada imagen bidimensional en un vector plano de longitud num_inputs. Finalmente, implementamos nuestro modelo con solo unas pocas líneas de código. Como usamos el framework autograd integrado, esto es todo lo que necesitamos.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="perceptrón-multicapa.html#cb10-1" tabindex="-1"></a><span class="co"># Añadir método usando el decorador</span></span>
<span id="cb10-2"><a href="perceptrón-multicapa.html#cb10-2" tabindex="-1"></a><span class="at">@add_to_class</span>(MLPScratch)</span>
<span id="cb10-3"><a href="perceptrón-multicapa.html#cb10-3" tabindex="-1"></a><span class="kw">def</span> forward(<span class="va">self</span>, X):</span>
<span id="cb10-4"><a href="perceptrón-multicapa.html#cb10-4" tabindex="-1"></a>    X <span class="op">=</span> X.reshape((<span class="op">-</span><span class="dv">1</span>, <span class="va">self</span>.num_inputs))</span>
<span id="cb10-5"><a href="perceptrón-multicapa.html#cb10-5" tabindex="-1"></a>    H <span class="op">=</span> relu(torch.matmul(X, <span class="va">self</span>.W1) <span class="op">+</span> <span class="va">self</span>.b1)</span>
<span id="cb10-6"><a href="perceptrón-multicapa.html#cb10-6" tabindex="-1"></a>    O <span class="op">=</span> torch.matmul(H, <span class="va">self</span>.W2) <span class="op">+</span> <span class="va">self</span>.b2</span>
<span id="cb10-7"><a href="perceptrón-multicapa.html#cb10-7" tabindex="-1"></a>    <span class="cf">return</span> O</span></code></pre></div>
</div>
<div id="entrenamiento" class="section level4 hasAnchor" number="4.2.1.3">
<h4><span class="header-section-number">4.2.1.3</span> Entrenamiento<a href="perceptrón-multicapa.html#entrenamiento" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Afortunadamente, el ciclo de entrenamiento para las MLP es exactamente el mismo que para la regresión softmax. Definimos el modelo, los datos y el entrenador, y finalmente invocamos el método de ajuste en el modelo y los datos.</p>
<p>Primero, unas clases auxiliares:</p>
<div id="dataloader" class="section level5 unnumbered hasAnchor">
<h5>DataLoader:<a href="perceptrón-multicapa.html#dataloader" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="perceptrón-multicapa.html#cb11-1" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb11-2"><a href="perceptrón-multicapa.html#cb11-2" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, transforms</span>
<span id="cb11-3"><a href="perceptrón-multicapa.html#cb11-3" tabindex="-1"></a></span>
<span id="cb11-4"><a href="perceptrón-multicapa.html#cb11-4" tabindex="-1"></a><span class="kw">class</span> FashionMNISTData:</span>
<span id="cb11-5"><a href="perceptrón-multicapa.html#cb11-5" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, batch_size<span class="op">=</span><span class="dv">256</span>):</span>
<span id="cb11-6"><a href="perceptrón-multicapa.html#cb11-6" tabindex="-1"></a>        <span class="va">self</span>.batch_size <span class="op">=</span> batch_size</span>
<span id="cb11-7"><a href="perceptrón-multicapa.html#cb11-7" tabindex="-1"></a>        <span class="va">self</span>.transform <span class="op">=</span> transforms.ToTensor()</span>
<span id="cb11-8"><a href="perceptrón-multicapa.html#cb11-8" tabindex="-1"></a></span>
<span id="cb11-9"><a href="perceptrón-multicapa.html#cb11-9" tabindex="-1"></a>        <span class="va">self</span>.train <span class="op">=</span> datasets.FashionMNIST(</span>
<span id="cb11-10"><a href="perceptrón-multicapa.html#cb11-10" tabindex="-1"></a>            root<span class="op">=</span><span class="st">&quot;./data&quot;</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span><span class="va">self</span>.transform</span>
<span id="cb11-11"><a href="perceptrón-multicapa.html#cb11-11" tabindex="-1"></a>        )</span>
<span id="cb11-12"><a href="perceptrón-multicapa.html#cb11-12" tabindex="-1"></a>        <span class="va">self</span>.test <span class="op">=</span> datasets.FashionMNIST(</span>
<span id="cb11-13"><a href="perceptrón-multicapa.html#cb11-13" tabindex="-1"></a>            root<span class="op">=</span><span class="st">&quot;./data&quot;</span>, train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span><span class="va">self</span>.transform</span>
<span id="cb11-14"><a href="perceptrón-multicapa.html#cb11-14" tabindex="-1"></a>        )</span>
<span id="cb11-15"><a href="perceptrón-multicapa.html#cb11-15" tabindex="-1"></a></span>
<span id="cb11-16"><a href="perceptrón-multicapa.html#cb11-16" tabindex="-1"></a>        <span class="va">self</span>.train_loader <span class="op">=</span> DataLoader(<span class="va">self</span>.train, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb11-17"><a href="perceptrón-multicapa.html#cb11-17" tabindex="-1"></a>        <span class="va">self</span>.test_loader <span class="op">=</span> DataLoader(<span class="va">self</span>.test, batch_size<span class="op">=</span>batch_size)</span>
<span id="cb11-18"><a href="perceptrón-multicapa.html#cb11-18" tabindex="-1"></a></span>
<span id="cb11-19"><a href="perceptrón-multicapa.html#cb11-19" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__iter__</span>(<span class="va">self</span>):</span>
<span id="cb11-20"><a href="perceptrón-multicapa.html#cb11-20" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">iter</span>(<span class="va">self</span>.train_loader)</span>
<span id="cb11-21"><a href="perceptrón-multicapa.html#cb11-21" tabindex="-1"></a></span>
<span id="cb11-22"><a href="perceptrón-multicapa.html#cb11-22" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb11-23"><a href="perceptrón-multicapa.html#cb11-23" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.train_loader)</span></code></pre></div>
</div>
<div id="trainer-minimalista" class="section level5 unnumbered hasAnchor">
<h5>Trainer minimalista<a href="perceptrón-multicapa.html#trainer-minimalista" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="perceptrón-multicapa.html#cb12-1" tabindex="-1"></a><span class="kw">class</span> Trainer:</span>
<span id="cb12-2"><a href="perceptrón-multicapa.html#cb12-2" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, max_epochs<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb12-3"><a href="perceptrón-multicapa.html#cb12-3" tabindex="-1"></a>        <span class="va">self</span>.max_epochs <span class="op">=</span> max_epochs</span>
<span id="cb12-4"><a href="perceptrón-multicapa.html#cb12-4" tabindex="-1"></a></span>
<span id="cb12-5"><a href="perceptrón-multicapa.html#cb12-5" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, model, data):</span>
<span id="cb12-6"><a href="perceptrón-multicapa.html#cb12-6" tabindex="-1"></a>        model.metrics <span class="op">=</span> {}</span>
<span id="cb12-7"><a href="perceptrón-multicapa.html#cb12-7" tabindex="-1"></a>        optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span>model.lr)</span>
<span id="cb12-8"><a href="perceptrón-multicapa.html#cb12-8" tabindex="-1"></a></span>
<span id="cb12-9"><a href="perceptrón-multicapa.html#cb12-9" tabindex="-1"></a>        <span class="co"># Asegura que exista test_loader</span></span>
<span id="cb12-10"><a href="perceptrón-multicapa.html#cb12-10" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> <span class="bu">hasattr</span>(data, <span class="st">&quot;test_loader&quot;</span>):</span>
<span id="cb12-11"><a href="perceptrón-multicapa.html#cb12-11" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">&quot;El dataset debe tener data.test_loader para validación&quot;</span>)</span>
<span id="cb12-12"><a href="perceptrón-multicapa.html#cb12-12" tabindex="-1"></a>        </span>
<span id="cb12-13"><a href="perceptrón-multicapa.html#cb12-13" tabindex="-1"></a>        <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.max_epochs):</span>
<span id="cb12-14"><a href="perceptrón-multicapa.html#cb12-14" tabindex="-1"></a>            total_loss, total_acc, count <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb12-15"><a href="perceptrón-multicapa.html#cb12-15" tabindex="-1"></a>            </span>
<span id="cb12-16"><a href="perceptrón-multicapa.html#cb12-16" tabindex="-1"></a>            <span class="cf">for</span> X, y <span class="kw">in</span> data:</span>
<span id="cb12-17"><a href="perceptrón-multicapa.html#cb12-17" tabindex="-1"></a>                optimizer.zero_grad()</span>
<span id="cb12-18"><a href="perceptrón-multicapa.html#cb12-18" tabindex="-1"></a>                y_hat <span class="op">=</span> model(X)</span>
<span id="cb12-19"><a href="perceptrón-multicapa.html#cb12-19" tabindex="-1"></a>                loss <span class="op">=</span> model.loss(y_hat, y)</span>
<span id="cb12-20"><a href="perceptrón-multicapa.html#cb12-20" tabindex="-1"></a>                loss.backward()</span>
<span id="cb12-21"><a href="perceptrón-multicapa.html#cb12-21" tabindex="-1"></a>                optimizer.step()</span>
<span id="cb12-22"><a href="perceptrón-multicapa.html#cb12-22" tabindex="-1"></a></span>
<span id="cb12-23"><a href="perceptrón-multicapa.html#cb12-23" tabindex="-1"></a>                total_loss <span class="op">+=</span> loss.item() <span class="op">*</span> X.size(<span class="dv">0</span>)</span>
<span id="cb12-24"><a href="perceptrón-multicapa.html#cb12-24" tabindex="-1"></a>                total_acc <span class="op">+=</span> model.accuracy(y_hat, y).item() <span class="op">*</span> X.size(<span class="dv">0</span>)</span>
<span id="cb12-25"><a href="perceptrón-multicapa.html#cb12-25" tabindex="-1"></a>                count <span class="op">+=</span> X.size(<span class="dv">0</span>)</span>
<span id="cb12-26"><a href="perceptrón-multicapa.html#cb12-26" tabindex="-1"></a>                </span>
<span id="cb12-27"><a href="perceptrón-multicapa.html#cb12-27" tabindex="-1"></a>            <span class="co"># Al final de cada epoch: guardar promedios de entrenamiento</span></span>
<span id="cb12-28"><a href="perceptrón-multicapa.html#cb12-28" tabindex="-1"></a>            model.plot(<span class="st">&quot;loss&quot;</span>, total_loss <span class="op">/</span> count, train<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb12-29"><a href="perceptrón-multicapa.html#cb12-29" tabindex="-1"></a>            model.plot(<span class="st">&quot;acc&quot;</span>, total_acc <span class="op">/</span> count, train<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb12-30"><a href="perceptrón-multicapa.html#cb12-30" tabindex="-1"></a></span>
<span id="cb12-31"><a href="perceptrón-multicapa.html#cb12-31" tabindex="-1"></a>            <span class="co"># ---------- VALIDACIÓN ----------</span></span>
<span id="cb12-32"><a href="perceptrón-multicapa.html#cb12-32" tabindex="-1"></a>            val_loss, val_acc, val_count <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb12-33"><a href="perceptrón-multicapa.html#cb12-33" tabindex="-1"></a>            <span class="cf">for</span> X, y <span class="kw">in</span> data.test_loader:</span>
<span id="cb12-34"><a href="perceptrón-multicapa.html#cb12-34" tabindex="-1"></a>                l, a <span class="op">=</span> model.evaluation_step(X, y)</span>
<span id="cb12-35"><a href="perceptrón-multicapa.html#cb12-35" tabindex="-1"></a>                val_loss <span class="op">+=</span> l <span class="op">*</span> X.size(<span class="dv">0</span>)</span>
<span id="cb12-36"><a href="perceptrón-multicapa.html#cb12-36" tabindex="-1"></a>                val_acc <span class="op">+=</span> a <span class="op">*</span> X.size(<span class="dv">0</span>)</span>
<span id="cb12-37"><a href="perceptrón-multicapa.html#cb12-37" tabindex="-1"></a>                val_count <span class="op">+=</span> X.size(<span class="dv">0</span>)</span>
<span id="cb12-38"><a href="perceptrón-multicapa.html#cb12-38" tabindex="-1"></a>            </span>
<span id="cb12-39"><a href="perceptrón-multicapa.html#cb12-39" tabindex="-1"></a>            <span class="co"># guardar métricas de validación por epoch</span></span>
<span id="cb12-40"><a href="perceptrón-multicapa.html#cb12-40" tabindex="-1"></a>            model.plot(<span class="st">&quot;loss&quot;</span>, val_loss <span class="op">/</span> val_count, train<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb12-41"><a href="perceptrón-multicapa.html#cb12-41" tabindex="-1"></a>            model.plot(<span class="st">&quot;acc&quot;</span>, val_acc <span class="op">/</span> val_count, train<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb12-42"><a href="perceptrón-multicapa.html#cb12-42" tabindex="-1"></a>            </span>
<span id="cb12-43"><a href="perceptrón-multicapa.html#cb12-43" tabindex="-1"></a>            <span class="co"># -------- PRINT FULL METRICS --------</span></span>
<span id="cb12-44"><a href="perceptrón-multicapa.html#cb12-44" tabindex="-1"></a>            <span class="bu">print</span>(</span>
<span id="cb12-45"><a href="perceptrón-multicapa.html#cb12-45" tabindex="-1"></a>                <span class="ss">f&quot;Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">: &quot;</span></span>
<span id="cb12-46"><a href="perceptrón-multicapa.html#cb12-46" tabindex="-1"></a>                <span class="ss">f&quot;train_loss=</span><span class="sc">{</span>total_loss<span class="op">/</span>count<span class="sc">:.3f}</span><span class="ss">, &quot;</span></span>
<span id="cb12-47"><a href="perceptrón-multicapa.html#cb12-47" tabindex="-1"></a>                <span class="ss">f&quot;val_loss=</span><span class="sc">{</span>val_loss<span class="op">/</span>val_count<span class="sc">:.3f}</span><span class="ss">, &quot;</span></span>
<span id="cb12-48"><a href="perceptrón-multicapa.html#cb12-48" tabindex="-1"></a>                <span class="ss">f&quot;train_acc=</span><span class="sc">{</span>total_acc<span class="op">/</span>count<span class="sc">:.3f}</span><span class="ss">, &quot;</span></span>
<span id="cb12-49"><a href="perceptrón-multicapa.html#cb12-49" tabindex="-1"></a>                <span class="ss">f&quot;val_acc=</span><span class="sc">{</span>val_acc<span class="op">/</span>val_count<span class="sc">:.3f}</span><span class="ss">&quot;</span></span>
<span id="cb12-50"><a href="perceptrón-multicapa.html#cb12-50" tabindex="-1"></a>            )</span>
<span id="cb12-51"><a href="perceptrón-multicapa.html#cb12-51" tabindex="-1"></a>            </span>
<span id="cb12-52"><a href="perceptrón-multicapa.html#cb12-52" tabindex="-1"></a>        <span class="co"># Al final → graficar exactamente como el libro</span></span>
<span id="cb12-53"><a href="perceptrón-multicapa.html#cb12-53" tabindex="-1"></a>        <span class="va">self</span>._plot_metrics(model)</span>
<span id="cb12-54"><a href="perceptrón-multicapa.html#cb12-54" tabindex="-1"></a></span>
<span id="cb12-55"><a href="perceptrón-multicapa.html#cb12-55" tabindex="-1"></a>    <span class="kw">def</span> _plot_metrics(<span class="va">self</span>, model):</span>
<span id="cb12-56"><a href="perceptrón-multicapa.html#cb12-56" tabindex="-1"></a>        metrics <span class="op">=</span> model.metrics</span>
<span id="cb12-57"><a href="perceptrón-multicapa.html#cb12-57" tabindex="-1"></a>        </span>
<span id="cb12-58"><a href="perceptrón-multicapa.html#cb12-58" tabindex="-1"></a>        n <span class="op">=</span> <span class="bu">len</span>(metrics[<span class="st">&quot;loss_train&quot;</span>])</span>
<span id="cb12-59"><a href="perceptrón-multicapa.html#cb12-59" tabindex="-1"></a>        epochs <span class="op">=</span> <span class="bu">range</span>(n)</span>
<span id="cb12-60"><a href="perceptrón-multicapa.html#cb12-60" tabindex="-1"></a>    </span>
<span id="cb12-61"><a href="perceptrón-multicapa.html#cb12-61" tabindex="-1"></a>        plt.plot(epochs, metrics[<span class="st">&quot;loss_train&quot;</span>], label<span class="op">=</span><span class="st">&quot;train_loss&quot;</span>)</span>
<span id="cb12-62"><a href="perceptrón-multicapa.html#cb12-62" tabindex="-1"></a>        <span class="co">#plt.plot(epochs, metrics[&quot;loss_val&quot;], label=&quot;val_loss&quot;)</span></span>
<span id="cb12-63"><a href="perceptrón-multicapa.html#cb12-63" tabindex="-1"></a>        plt.plot(epochs, metrics[<span class="st">&quot;acc_train&quot;</span>], label<span class="op">=</span><span class="st">&quot;train_acc&quot;</span>)</span>
<span id="cb12-64"><a href="perceptrón-multicapa.html#cb12-64" tabindex="-1"></a>        plt.plot(epochs, metrics[<span class="st">&quot;acc_val&quot;</span>], label<span class="op">=</span><span class="st">&quot;val_acc&quot;</span>)</span>
<span id="cb12-65"><a href="perceptrón-multicapa.html#cb12-65" tabindex="-1"></a>    </span>
<span id="cb12-66"><a href="perceptrón-multicapa.html#cb12-66" tabindex="-1"></a>        plt.xlabel(<span class="st">&quot;epoch&quot;</span>)</span>
<span id="cb12-67"><a href="perceptrón-multicapa.html#cb12-67" tabindex="-1"></a>        plt.legend()</span>
<span id="cb12-68"><a href="perceptrón-multicapa.html#cb12-68" tabindex="-1"></a>        plt.title(<span class="st">&quot;Training and Validation Metrics&quot;</span>)</span>
<span id="cb12-69"><a href="perceptrón-multicapa.html#cb12-69" tabindex="-1"></a>        plt.show()</span>
<span id="cb12-70"><a href="perceptrón-multicapa.html#cb12-70" tabindex="-1"></a>        </span>
<span id="cb12-71"><a href="perceptrón-multicapa.html#cb12-71" tabindex="-1"></a>        plt.clf()       <span class="co"># Limpia la figura actual</span></span>
<span id="cb12-72"><a href="perceptrón-multicapa.html#cb12-72" tabindex="-1"></a>        plt.close()</span></code></pre></div>
<div class="sourceCode" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="perceptrón-multicapa.html#cb13-1" tabindex="-1"></a><span class="co"># Crear modelo</span></span>
<span id="cb13-2"><a href="perceptrón-multicapa.html#cb13-2" tabindex="-1"></a>model <span class="op">=</span> MLPScratch(</span>
<span id="cb13-3"><a href="perceptrón-multicapa.html#cb13-3" tabindex="-1"></a>    num_inputs<span class="op">=</span><span class="dv">784</span>,</span>
<span id="cb13-4"><a href="perceptrón-multicapa.html#cb13-4" tabindex="-1"></a>    num_outputs<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb13-5"><a href="perceptrón-multicapa.html#cb13-5" tabindex="-1"></a>    num_hiddens<span class="op">=</span><span class="dv">256</span>,</span>
<span id="cb13-6"><a href="perceptrón-multicapa.html#cb13-6" tabindex="-1"></a>    lr<span class="op">=</span><span class="fl">0.1</span></span>
<span id="cb13-7"><a href="perceptrón-multicapa.html#cb13-7" tabindex="-1"></a>)</span>
<span id="cb13-8"><a href="perceptrón-multicapa.html#cb13-8" tabindex="-1"></a></span>
<span id="cb13-9"><a href="perceptrón-multicapa.html#cb13-9" tabindex="-1"></a><span class="co"># Cargar datos (reemplaza d2l.FashionMNIST)</span></span>
<span id="cb13-10"><a href="perceptrón-multicapa.html#cb13-10" tabindex="-1"></a>data <span class="op">=</span> FashionMNISTData(batch_size<span class="op">=</span><span class="dv">256</span>)</span></code></pre></div>
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="perceptrón-multicapa.html#cb14-1" tabindex="-1"></a>trainer <span class="op">=</span> Trainer(max_epochs<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb14-2"><a href="perceptrón-multicapa.html#cb14-2" tabindex="-1"></a><span class="co">#trainer.fit(model, data)</span></span></code></pre></div>
</div>
</div>
</div>
<div id="implementación" class="section level3 hasAnchor" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> Implementación<a href="perceptrón-multicapa.html#implementaci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La implementación pasada es bastante útil para entender cómo funciona el modelo, no obstante, al implementar las API de alto nivel, podemos crear MLP de forma aún más concisa.</p>
<div id="modelo-1" class="section level4 hasAnchor" number="4.2.2.1">
<h4><span class="header-section-number">4.2.2.1</span> Modelo<a href="perceptrón-multicapa.html#modelo-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>En comparación con la implementación concisa de la regresión softmax, la única diferencia radica en que se añaden dos capas completamente conectadas donde antes solo se añadía una. La primera es la capa oculta y la segunda, la capa de salida.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="perceptrón-multicapa.html#cb15-1" tabindex="-1"></a><span class="kw">class</span> MLP(Classifier):</span>
<span id="cb15-2"><a href="perceptrón-multicapa.html#cb15-2" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_outputs, num_hiddens, lr):</span>
<span id="cb15-3"><a href="perceptrón-multicapa.html#cb15-3" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb15-4"><a href="perceptrón-multicapa.html#cb15-4" tabindex="-1"></a>        <span class="va">self</span>.save_hyperparameters()</span>
<span id="cb15-5"><a href="perceptrón-multicapa.html#cb15-5" tabindex="-1"></a>        <span class="va">self</span>.net <span class="op">=</span> nn.Sequential(</span>
<span id="cb15-6"><a href="perceptrón-multicapa.html#cb15-6" tabindex="-1"></a>            nn.Flatten(), </span>
<span id="cb15-7"><a href="perceptrón-multicapa.html#cb15-7" tabindex="-1"></a>            nn.LazyLinear(num_hiddens),</span>
<span id="cb15-8"><a href="perceptrón-multicapa.html#cb15-8" tabindex="-1"></a>            nn.ReLU(), </span>
<span id="cb15-9"><a href="perceptrón-multicapa.html#cb15-9" tabindex="-1"></a>            nn.LazyLinear(num_outputs)</span>
<span id="cb15-10"><a href="perceptrón-multicapa.html#cb15-10" tabindex="-1"></a>        )</span>
<span id="cb15-11"><a href="perceptrón-multicapa.html#cb15-11" tabindex="-1"></a></span>
<span id="cb15-12"><a href="perceptrón-multicapa.html#cb15-12" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, X):</span>
<span id="cb15-13"><a href="perceptrón-multicapa.html#cb15-13" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.net(X)</span></code></pre></div>
<p>Anteriormente, definimos métodos <strong>forward</strong> para que los modelos transformen la entrada utilizando los parámetros del modelo. Estas operaciones son esencialmente una secuencia: se toma una entrada y se aplica una transformación (por ejemplo, multiplicación de matrices con pesos seguida de la adición de sesgos), y luego se utiliza repetidamente la salida de la transformación actual como entrada para la siguiente transformación. Sin embargo, es posible notar que aquí no se define ningún método <strong>forward</strong>.</p>
<p>De hecho, MLP hereda el método de <em>forward</em> de la clase Module para simplemente invocar self.net(X) (X es la entrada), que ahora se define como una secuencia de transformaciones mediante la clase <em>Sequential</em>. La clase <em>Sequential</em> abstrae el proceso de avance (forward), lo que nos permite centrarnos en las transformaciones. Analizaremos con más detalle el funcionamiento de la clase <em>Sequential</em> en secciones posteriores.</p>
</div>
<div id="entrenamiento-1" class="section level4 hasAnchor" number="4.2.2.2">
<h4><span class="header-section-number">4.2.2.2</span> Entrenamiento<a href="perceptrón-multicapa.html#entrenamiento-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>El ciclo de entrenamiento es exactamente el mismo que cuando implementamos la regresión softmax. Esta modularidad permite separar los aspectos relacionados con la arquitectura del modelo de las consideraciones ortogonales.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="perceptrón-multicapa.html#cb16-1" tabindex="-1"></a>model <span class="op">=</span> MLP(num_outputs<span class="op">=</span><span class="dv">10</span>, num_hiddens<span class="op">=</span><span class="dv">256</span>, lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb16-2"><a href="perceptrón-multicapa.html#cb16-2" tabindex="-1"></a><span class="co">#trainer.fit(model, data)</span></span></code></pre></div>
</div>
</div>
<div id="ejercicios-1" class="section level3 hasAnchor" number="4.2.3">
<h3><span class="header-section-number">4.2.3</span> Ejercicios<a href="perceptrón-multicapa.html#ejercicios-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><p>Cambie el número de unidades ocultas num_hiddens y grafique cómo su número afecta la precisión del modelo. ¿Cuál es el mejor valor para este hiperparámetro?</p></li>
<li><p>Intente añadir una capa oculta para ver cómo afecta a los resultados.</p></li>
<li><p>¿Por qué es una mala idea insertar una capa oculta con una sola neurona? ¿Qué podría salir mal?</p></li>
<li><p>¿Cómo altera los resultados el cambio de la tasa de aprendizaje? Con todos los demás parámetros fijos, ¿qué tasa de aprendizaje ofrece los mejores resultados? ¿Cómo se relaciona esto con el número de épocas?</p></li>
<li><p>Optimicemos todos los hiperparámetros conjuntamente: tasa de aprendizaje, número de épocas, número de capas ocultas y número de unidades ocultas por capa.</p></li>
</ol>
<ul>
<li>¿Cuál es el mejor resultado que se puede obtener optimizando todos ellos?</li>
<li>¿Por qué es mucho más difícil gestionar varios hiperparámetros?</li>
<li>Describa una estrategia eficiente para optimizar varios parámetros conjuntamente.</li>
</ul>
<ol start="6" style="list-style-type: decimal">
<li><p>Compare la velocidad del framework y la implementación desde cero para un problema complejo. ¿Cómo cambia con la complejidad de la red?</p></li>
<li><p>Mide la velocidad de las multiplicaciones tensor-matriz para matrices bien alineadas y desalineadas. Por ejemplo, prueba matrices con dimensiones 1024, 1025, 1026, 1028 y 1032.</p></li>
</ol>
<ul>
<li>¿Cómo cambia esto entre GPU y CPU?</li>
<li>Determina el ancho del bus de memoria de tu CPU y GPU.</li>
</ul>
<ol start="8" style="list-style-type: decimal">
<li><p>Prueba diferentes funciones de activación. ¿Cuál funciona mejor?</p></li>
<li><p>¿Existe alguna diferencia entre las inicializaciones de peso de la red? ¿Tiene importancia?</p></li>
</ol>
</div>
</div>
<div id="forward-propagation-backward-propagation" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Forward Propagation, Backward Propagation<a href="perceptrón-multicapa.html#forward-propagation-backward-propagation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Hasta ahora hemos entrenado redes con descenso de gradiente usando minibatches, pero siempre confiando en que el framework calcule los gradientes por nosotros. Gracias a la diferenciación automática, no necesitamos derivar a mano expresiones complicadas, como se hacía antes en los artículos académicos.</p>
<p>Pero para entender realmente cómo aprenden las redes, es importante saber qué ocurre detrás de escena. Por eso, en esta sección vamos a estudiar backpropagation, el mecanismo que calcula cómo cambia cada parámetro según el error cometido. Usaremos matemáticas básicas y grafos computacionales, trabajando con un ejemplo sencillo: un MLP de una capa oculta con regularización (weight decay <span class="math inline">\(l_2\)</span>). Esto nos permitirá entender no sólo el qué, sino el cómo del aprendizaje profundo.</p>
<div id="forward-propagation" class="section level3 hasAnchor" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Forward Propagation<a href="perceptrón-multicapa.html#forward-propagation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La propagación hacia adelante (forward propagation o pase hacia adelante) se refiere al cálculo y almacenamiento de variables intermedias (incluidas las salidas) para una red neuronal, desde la capa de entrada hasta la capa de salida. A continuación, se explica paso a paso la mecánica de una red neuronal con una capa oculta.</p>
<p>Para simplificar, supongamos que el ejemplo de entrada es <span class="math inline">\(x\in \mathbb{R}^{d}\)</span> y que nuestra capa oculta no incluye un término de sesgo. En este caso, la variable intermedia es:</p>
<p><span class="math display">\[\mathbb{z}=W^{(1)}x,\]</span></p>
<p>donde <span class="math inline">\(W^{(1)} \in \mathbb{R}^{h\times d}\)</span> es el peso del parámetro de las capas ocultas. Luego de ejecutar la variable intermedia <span class="math inline">\(z\in \mathbb{R}^{h}\)</span> a través de la función de activación <span class="math inline">\(\phi\)</span>, se obtiene el vector de activación oculto de longitud <span class="math inline">\(h\)</span>:</p>
<p><span class="math display">\[h=\phi(z).\]</span></p>
<p>La salida de la capa oculta <span class="math inline">\(h\)</span> también es una variable intermedia. Suponiendo que los parámetros de la capa de salida solo tienen un peso de <span class="math inline">\(W^{(2)}\in \mathbb{R}^{q\times h}\)</span>, se puede obtener una variable de capa de salida con un vector de longitud <span class="math inline">\(q\)</span>:</p>
<p><span class="math display">\[\mathbb{o}=W^{(2)}h\]</span></p>
<p>Asumiendo que la función de pérdida es <span class="math inline">\(l\)</span> y la etiqueta de ejemplo es <span class="math inline">\(y\)</span>, se puede calcular el término de pérdida para un solo ejemplo de datos,</p>
<p><span class="math display">\[L=l(o,y)\]</span></p>
<p>Como veremos en la definición de regularización (<span class="math inline">\(l_2\)</span>) que se presentará más adelante, dado el hiperparámetro <span class="math inline">\(\lambda\)</span>, el término de regularización es:</p>
<p><span class="math display">\[s=\frac{\lambda}{2} \left(||W^{(1)}||^{2}_{F}+||W^{(2)}||^{2}_{F} \right),\]</span></p>
<p>Donde la <em>norma de Frobenius</em> de la matriz es simplemente la norma <span class="math inline">\(l_2\)</span> aplicada tras aplanar la matriz a un vector. Finalmente, la pérdida regularizada del modelo en un ejemplo de datos dado es:</p>
<p><span class="math display">\[J=L+s.\]</span></p>
<p>Refiriéndose a <span class="math inline">\(J\)</span> como la <em>función objetivo</em> en la siguiente discusión. A continuación se muestra el flujo computacional del proceso <strong>Forward</strong>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-20"></span>
<img src="img/05_Multilayer_Perceptron/computational_grapg_forward_propagation.png" alt="Computational graph of forward propagation of Dive into Deep Learning Book" width="650pt" height="300pt" />
<p class="caption">
Figure 4.1: Computational graph of forward propagation of Dive into Deep Learning Book
</p>
</div>
</div>
<div id="backpropagation" class="section level3 hasAnchor" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Backpropagation<a href="perceptrón-multicapa.html#backpropagation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La retropropagación se refiere al método para calcular el gradiente de los parámetros de una red neuronal. En resumen, el método recorre <strong>la red en orden inverso</strong>, desde la capa de salida hasta la de entrada, según la <strong>regla de la cadena</strong> del cálculo. El algoritmo almacena las variables intermedias (derivadas parciales) necesarias para calcular el gradiente con respecto a algunos parámetros. Supongamos que tenemos funciones <span class="math inline">\(Y=f(X)\)</span> y <span class="math inline">\(Z=g(Y)\)</span>, donde la entrada y la salida <span class="math inline">\(X, Y, Z\)</span> son tensores de formas arbitrarias. Utilizando la regla de la cadena, podemos calcular la derivada de <span class="math inline">\(Z\)</span> con respecto a <span class="math inline">\(X\)</span> mediante:</p>
<p><span class="math display">\[\frac{\partial Z}{\partial X} = \text{prod} \left( \frac{\partial Z}{\partial Y}, \frac{\partial Y}{\partial X} \right)\]</span></p>
<p>Aquí usamos el operador <span class="math inline">\(prod\)</span> para multiplicar sus argumentos después de realizar las operaciones necesarias, como la transposición y el intercambio de posiciones de entrada. Para vectores, esto es sencillo: se trata simplemente de una multiplicación matriz-matriz. Para tensores de mayor dimensión, usamos el operador correspondiente. El operador <span class="math inline">\(prod\)</span> elimina toda la sobrecarga de notación.</p>
<p><img src="img/05_Multilayer_Perceptron/Gradient_descent.gif" width="650pt" height="300pt" style="display: block; margin: auto;" /></p>
<p>El objetivo de la retropropagación es calcular los gradientes <span class="math inline">\(\frac{\partial J}{\partial W^{(1)}}\)</span> y <span class="math inline">\(\frac{\partial J}{\partial W^{(2)}}\)</span>. Para ello, aplicamos la regla de la cadena y calculamos, a su vez, el gradiente de cada variable y parámetro intermedio. El orden de los cálculos se invierte con respecto a los realizados en la propagación hacia adelante, ya que debemos comenzar con el resultado del grafo computacional y avanzar hacia los parámetros. El primer paso es calcular los gradientes de la función objetivo <span class="math inline">\(J=L+s\)</span> con respecto al término de pérdida <span class="math inline">\(L\)</span> y al término de regularización <span class="math inline">\(s\)</span>:</p>
<p><span class="math display">\[
\frac{\partial J}{\partial L} = 1 \quad \text{and} \quad\frac{\partial J}{\partial s}=1
\]</span>
A continuación, calculamos el gradiente de la función objetivo con respecto a la variable de la capa de salida <span class="math inline">\(o\)</span> según la regla de la cadena:</p>
<p><span class="math display">\[
\frac{\partial J}{\partial o}=\text{prod}\left( \frac{\partial J}{\partial L}, \frac{\partial L}{\partial o} \right) = \frac{\partial J}{\partial o}\in \mathbb{R}^{q}.
\]</span>
A continuación, calculamos los gradientes del término de regularización con respecto a ambos parámetros:</p>
<p><span class="math display">\[
\frac{\partial s}{\partial W^{(1)}}=\lambda W^{(1)} \quad and \quad \frac{\partial s}{\partial W^{(2)}}=\lambda W^{(2)}
\]</span>
Ahora podemos calcular el gradiente <span class="math inline">\(\frac{\partial J}{\partial W^{(2)}}\)</span> de los parámetros del modelo más cercanos a la capa de salida. Usando la regla de la cadena obtenemos:</p>
<p><span class="math display">\[
\frac{\partial J}{\partial W^{(2)}}=prod\left(\frac{\partial J}{\partial o}, \frac{\partial o}{\partial W^{(2)}}\right)+prod\left(\frac{\partial J}{\partial s}, \frac{\partial s}{\partial W^{(2)}}\right)=\frac{\partial J}{\partial o}h^{T}+\lambda W^{(2)}
\]</span></p>
<p>Para obtener el gradiente con respecto a <span class="math inline">\(W^{(1)}\)</span>, necesitamos continuar la retropropagación a lo largo de la capa de salida hasta la capa oculta. El gradiente con respecto a la salida de la capa oculta <span class="math inline">\(\frac{\partial J}{\partial h}\in \mathbb{R}^{h}\)</span> está dado por:</p>
<p><span class="math display">\[
\frac{\partial J}{\partial h}=prod\left(\frac{\partial J}{\partial o}, \frac{\partial o}{\partial h}\right)=W^{(2)^{T}}\frac{\partial J}{\partial o}
\]</span>
Dado que la función de activación <span class="math inline">\(\phi\)</span> se aplica elemento por elemento, para calcular el gradiente <span class="math inline">\(\frac{\partial J}{\partial z} \in \mathbb{R}^{h}\)</span> de la variable intermedia <span class="math inline">\(z\)</span> es necesario utilizar el operador de multiplicación elemento por elemento, que denotamos como <span class="math inline">\(\odot\)</span>:</p>
<p><span class="math display">\[
\frac{\partial J}{\partial z}=prod\left(\frac{\partial J}{\partial h}, \frac{\partial h}{\partial z}\right)=\frac{\partial J}{\partial h}\odot\phi^{\prime}(z).
\]</span>
Finalmente, podemos obtener el gradiente <span class="math inline">\(\frac{\partial J}{\partial W^{(1)}}\in \mathbb{R}^{h\times d}\)</span> de los parámetros del modelo más cercanos a la capa de entrada. Según la regla de la cadena, obtenemos:</p>
<p><span class="math display">\[
\frac{\partial J}{\partial W^{(1)}}=prod\left(\frac{\partial J}{\partial z}, \frac{\partial z}{\partial W^{(1)}}\right)+prod\left(\frac{\partial J}{\partial s}, \frac{\partial s}{\partial W^{(1)}}\right)=\frac{\partial J}{\partial z}x^{T}+\lambda W^{(1)}
\]</span></p>
<p>Al entrenar redes neuronales, la propagación hacia adelante y la retropropagación se necesitan mutuamente. En la fase hacia adelante se recorre el grafo computacional según sus dependencias y se calculan variables intermedias que luego serán reutilizadas en la retropropagación.</p>
<p>En una red simple, por ejemplo, el término de regularización depende de los parámetros actuales <span class="math inline">\(W^{(1)}\)</span> y <span class="math inline">\(W^{(2)}\)</span>, actualizados previamente mediante retropropagación. A su vez, el cálculo de gradientes en la retropropagación depende de valores generados hacia adelante, como la salida oculta $h&amp;.</p>
<p>En resumen, el entrenamiento alterna continuamente entre ambas fases: la propagación hacia adelante produce valores intermedios, la retropropagación usa esos valores para obtener gradientes y actualizar parámetros, y esos parámetros actualizados se usan en la siguiente pasada hacia adelante. Esto requiere almacenar los valores intermedios hasta que termine la retropropagación.</p>
</div>
<div id="resumen-6" class="section level3 hasAnchor" number="4.3.3">
<h3><span class="header-section-number">4.3.3</span> Resumen<a href="perceptrón-multicapa.html#resumen-6" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La propagación hacia adelante calcula, paso a paso, las variables intermedias del grafo computacional de la red, avanzando desde la entrada hasta la salida. La retropropagación hace lo mismo pero en sentido inverso: calcula y almacena los gradientes de esas variables y de los parámetros.</p>
<p>Durante el entrenamiento, ambas fases dependen una de la otra, por lo que se necesita mucha más memoria que en la simple fase de predicción.</p>
</div>
<div id="ejercicios-2" class="section level3 hasAnchor" number="4.3.4">
<h3><span class="header-section-number">4.3.4</span> Ejercicios<a href="perceptrón-multicapa.html#ejercicios-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><p>Suponga que las entradas <span class="math inline">\(X\)</span> de una función escalar <span class="math inline">\(f\)</span> son matrices <span class="math inline">\(n \times m\)</span>. ¿Cuál es la dimensionalidad del gradiente <span class="math inline">\(f\)</span> de con respecto a <span class="math inline">\(X\)</span>?</p></li>
<li><p>Agregue un sesgo a la capa oculta del modelo descrito en esta sección (no es necesario incluirlo en el término de regularización).</p>
<ul>
<li>Dibuje el grafo computacional correspondiente.</li>
<li>Obtenga las ecuaciones de propagación hacia adelante y hacia atrás.</li>
</ul></li>
<li><p>Calcule la huella de memoria para el entrenamiento y la predicción en el modelo descrito en esta sección.</p></li>
<li><p>Suponga que desea calcular las derivadas secundarias. ¿Qué ocurre con el grafo computacional? ¿Cuánto tiempo espera que tarde el cálculo?</p></li>
<li><p>Suponga que el grafo computacional es demasiado grande para su GPU.</p>
<ul>
<li>¿Puede particionarlo en más de una GPU?</li>
<li>¿Cuáles son las ventajas y desventajas del entrenamiento en un minibatch más pequeño?</li>
</ul></li>
</ol>
</div>
</div>
<div id="estabilidad-numérica-e-inicialización" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> Estabilidad Numérica e Inicialización<a href="perceptrón-multicapa.html#estabilidad-num%C3%A9rica-e-inicializaci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Hasta ahora, todos los modelos que hemos visto necesitaban <strong>inicializar sus parámetros usando alguna distribución predefinida</strong>. Hemos pasado por alto cómo se eligen realmente estos valores, lo que podría dar la impresión de que no importa demasiado. Pero en realidad, la forma de inicializar los parámetros es clave para que una red neuronal aprenda bien y mantenga la estabilidad numérica.</p>
<div class="infobox note">
<p><strong>¡¡ RECORDAR !!</strong></p>
<p>la forma de inicializar los parámetros es clave para que una red neuronal aprenda bien y mantenga la estabilidad numérica.</p>
</div>
<p>Además, la inicialización está estrechamente relacionada con la función de activación elegida. <strong>Ambas decisiones influyen en qué tan rápido converge el algoritmo de optimización</strong>. Una mala combinación puede provocar problemas típicos como gradientes que explotan o desaparecen (exploding or vanishing).</p>
<p>En esta sección exploraremos estos temas con más detalle y veremos reglas prácticas que resultan muy útiles al trabajar con deep learning.</p>
<div id="explotación-y-desvanecimiento-de-gradientes" class="section level3 hasAnchor" number="4.4.1">
<h3><span class="header-section-number">4.4.1</span> Explotación y Desvanecimiento de Gradientes<a href="perceptrón-multicapa.html#explotaci%C3%B3n-y-desvanecimiento-de-gradientes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Considera una red neuronal con <span class="math inline">\(L\)</span> capas, entrada <span class="math inline">\(x\)</span> y salida <span class="math inline">\(o\)</span>. Con cada capa <span class="math inline">\(l\)</span> definida por la transformación <span class="math inline">\(f_l\)</span> parametrizada por los pesos <span class="math inline">\(W^{(l)}\)</span>, cuya capa oculta de salida es <span class="math inline">\(h^{(l)}\)</span> (siendo <span class="math inline">\(h^{(0)}=x\)</span>), la red puede ser expresada como:</p>
<p><span class="math display">\[
h^{(l)}=f_l(h^{(l-1)}) \quad \text{y entonces} \quad o=f_L \circ \cdot \cdot \cdot \circ f_{1}(x)
\]</span>
Si la salida y la entrada de la capa oculta son vectores, podemos escribir el gradiente de <span class="math inline">\(o\)</span> con respecto a cualquier conjunto de parámetros <span class="math inline">\(W^{(l)}\)</span> de la siguiente manera:</p>
<p><span class="math display">\[
\partial_{W^{(l)}}o=\underbrace{\partial_{h^{(l-1)}}h^{L}}_{M^{(L)}} \cdot \cdot \cdot  \underbrace{\partial_{h^{(l)}}h^{l+1}}_{M^{(l+1)}}\underbrace{\partial_{W^{(l)}}h^{l}}_{v^{(l)}}
\]</span></p>
<p>Resumiendo, este gradiente es el producto de <span class="math inline">\(L-l\)</span> matrices <span class="math inline">\(M^{(L)}\cdot\cdot\cdot M^{(l+1)}\)</span> y el vector gradiente <span class="math inline">\(v^{(l)}.\)</span> Esto puede causar problemas numéricos similares a cuando multiplicamos muchas probabilidades y obtenemos valores extremadamente pequeños. En probabilidades solemos pasar a “log-espacio” para evitarlo, pero aquí el problema es más serio: las matrices involucradas <span class="math inline">\(M^{(l)}\)</span> pueden tener <em>eigenvalores</em> muy grandes o muy pequeños, y su producto puede descontrolarse.</p>
<p>Cuando los gradientes se vuelven inestables, no solo fallan las representaciones numéricas, sino que también se afecta el proceso de optimización. Podemos terminar con actualizaciones demasiado grandes, que destrozan el modelo (gradientes que explotan), o demasiado pequeñas, donde los parámetros casi no cambian y la red deja de aprender (gradientes que desaparecen).</p>
<p><img src="img/05_Multilayer_Perceptron/vanishing_and_exploding_gradient.webp" width="650pt" height="300pt" style="display: block; margin: auto;" /></p>
<div id="desvanecimiento-de-gradientes" class="section level4 hasAnchor" number="4.4.1.1">
<h4><span class="header-section-number">4.4.1.1</span> Desvanecimiento de Gradientes<a href="perceptrón-multicapa.html#desvanecimiento-de-gradientes" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Un culpable frecuente del problema de gradientes que desaparecen es la función de activación <span class="math inline">\(\sigma\)</span> que se aplica después de cada operación lineal. Históricamente, la función sigmoide <span class="math inline">\(\frac{1}{1+exp(-x)}\)</span> fue muy usada porque se parece a una función de umbral, evocando la idea de neuronas biológicas que “disparan” o no. Sin embargo, si se observa más de cerca la sigmoide, vemos por qué puede provocar que los gradientes se vuelvan muy pequeños y, por lo tanto, que el aprendizaje se frene.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="perceptrón-multicapa.html#cb17-1" tabindex="-1"></a><span class="co"># Datos y cómputo de la sigmoide y su gradiente</span></span>
<span id="cb17-2"><a href="perceptrón-multicapa.html#cb17-2" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="op">-</span><span class="fl">8.0</span>, <span class="fl">8.0</span>, <span class="fl">0.1</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb17-3"><a href="perceptrón-multicapa.html#cb17-3" tabindex="-1"></a>y <span class="op">=</span> torch.sigmoid(x)</span>
<span id="cb17-4"><a href="perceptrón-multicapa.html#cb17-4" tabindex="-1"></a>y.backward(torch.ones_like(x))</span>
<span id="cb17-5"><a href="perceptrón-multicapa.html#cb17-5" tabindex="-1"></a></span>
<span id="cb17-6"><a href="perceptrón-multicapa.html#cb17-6" tabindex="-1"></a><span class="co"># Convertimos a numpy para graficar</span></span>
<span id="cb17-7"><a href="perceptrón-multicapa.html#cb17-7" tabindex="-1"></a>x_np <span class="op">=</span> x.detach().numpy()</span>
<span id="cb17-8"><a href="perceptrón-multicapa.html#cb17-8" tabindex="-1"></a>y_np <span class="op">=</span> y.detach().numpy()</span>
<span id="cb17-9"><a href="perceptrón-multicapa.html#cb17-9" tabindex="-1"></a>grad_np <span class="op">=</span> x.grad.detach().numpy()</span>
<span id="cb17-10"><a href="perceptrón-multicapa.html#cb17-10" tabindex="-1"></a></span>
<span id="cb17-11"><a href="perceptrón-multicapa.html#cb17-11" tabindex="-1"></a><span class="co"># Graficar</span></span>
<span id="cb17-12"><a href="perceptrón-multicapa.html#cb17-12" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="fl">4.5</span>, <span class="fl">2.5</span>))</span>
<span id="cb17-13"><a href="perceptrón-multicapa.html#cb17-13" tabindex="-1"></a>plt.plot(x_np, y_np, label<span class="op">=</span><span class="st">&#39;sigmoid&#39;</span>)</span>
<span id="cb17-14"><a href="perceptrón-multicapa.html#cb17-14" tabindex="-1"></a>plt.plot(x_np, grad_np, label<span class="op">=</span><span class="st">&#39;gradient&#39;</span>)</span>
<span id="cb17-15"><a href="perceptrón-multicapa.html#cb17-15" tabindex="-1"></a>plt.legend()</span>
<span id="cb17-16"><a href="perceptrón-multicapa.html#cb17-16" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;x&#39;</span>)</span>
<span id="cb17-17"><a href="perceptrón-multicapa.html#cb17-17" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb17-18"><a href="perceptrón-multicapa.html#cb17-18" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb17-19"><a href="perceptrón-multicapa.html#cb17-19" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p><img src="deep_learning_course_python_files/figure-html/unnamed-chunk-23-1.png" width="432" /></p>
<p>La sigmoide tiene un inconveniente importante: <strong>su gradiente se hace casi cero cuando la entrada es muy grande o muy pequeña</strong>. Esto significa que, al retropropagar a través de muchas capas, el gradiente total tiende a desaparecer a menos que todas las sigmoides trabajen en una zona muy específica cerca de cero. En redes profundas esto era un problema común: en algún punto el gradiente simplemente se “cortaba”.</p>
<div class="infobox quicktip">
<p><strong>¡¡ RECORDAR !!</strong></p>
<p>Funciones como ReLU se volvieron la opción estándar. Aunque son menos parecidas a las neuronas biológicas, resultan mucho más estables y facilitan entrenar redes más profundas.</p>
</div>
</div>
<div id="gradientes-explosivos" class="section level4 hasAnchor" number="4.4.1.2">
<h4><span class="header-section-number">4.4.1.2</span> Gradientes Explosivos<a href="perceptrón-multicapa.html#gradientes-explosivos" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>El problema opuesto, cuando los gradientes explotan, puede ser igualmente complejo. Para ilustrarlo mejor, dibujamos 100 matrices aleatorias gaussianas y las multiplicamos por una matriz inicial. Para la escala elegida (la elección de la varianza <span class="math inline">\(\sigma^{2}=1\)</span>), el producto de la matriz explota. Cuando esto ocurre debido a la inicialización de una red profunda, no tenemos posibilidad de lograr la convergencia de un optimizador de descenso de gradiente.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="perceptrón-multicapa.html#cb18-1" tabindex="-1"></a>M <span class="op">=</span> torch.normal(<span class="dv">0</span>, <span class="dv">1</span>, size<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb18-2"><a href="perceptrón-multicapa.html#cb18-2" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;a single matrix </span><span class="ch">\n</span><span class="st">&#39;</span>,M)</span></code></pre></div>
<pre><code>## a single matrix 
##  tensor([[-0.5402,  0.0320, -1.9324,  0.7777],
##         [-0.1177, -1.3671,  1.1809, -0.6876],
##         [-0.0848,  0.6232, -0.4370,  1.2215],
##         [-1.4847, -1.6700,  0.3961,  0.0623]])</code></pre>
<div class="sourceCode" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="perceptrón-multicapa.html#cb20-1" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb20-2"><a href="perceptrón-multicapa.html#cb20-2" tabindex="-1"></a>    M <span class="op">=</span> M <span class="op">@</span> torch.normal(<span class="dv">0</span>, <span class="dv">1</span>, size<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb20-3"><a href="perceptrón-multicapa.html#cb20-3" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;after multiplying 100 matrices</span><span class="ch">\n</span><span class="st">&#39;</span>, M)</span></code></pre></div>
<pre><code>## after multiplying 100 matrices
##  tensor([[-9.8701e+25,  1.2372e+26,  7.2798e+25,  8.5048e+25],
##         [ 7.7112e+25, -9.6658e+25, -5.6875e+25, -6.6445e+25],
##         [-7.8869e+24,  9.8859e+24,  5.8170e+24,  6.7959e+24],
##         [ 7.6766e+25, -9.6224e+25, -5.6620e+25, -6.6147e+25]])</code></pre>
</div>
<div id="rompiendo-la-simetría" class="section level4 hasAnchor" number="4.4.1.3">
<h4><span class="header-section-number">4.4.1.3</span> Rompiendo la Simetría<a href="perceptrón-multicapa.html#rompiendo-la-simetr%C3%ADa" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Otro problema en el diseño de redes neuronales es la simetría inherente a su parametrización. Supongamos que tenemos un MLP simple con una capa oculta y dos unidades. En este caso, podríamos permutar los pesos <span class="math inline">\(W^{(1)}\)</span> de la primera capa y, de igual manera, los de la capa de salida para obtener la misma función. No hay ninguna diferencia especial entre la primera y la segunda unidad oculta. En otras palabras, tenemos simetría de permutación entre las unidades ocultas de cada capa.</p>
<p><img src="img/05_Multilayer_Perceptron/simetry.jpg" width="300pt" height="300pt" style="display: block; margin: auto;" /></p>
<p>Esto es más que una simple molestia teórica. Consideremos el MLP de una capa oculta mencionado anteriormente con dos unidades ocultas. A modo de ilustración, supongamos que la capa de salida transforma las dos unidades ocultas en una sola unidad de salida. Imaginemos qué sucedería si inicializáramos todos los parámetros de la capa oculta como <span class="math inline">\(W^{(1)}=c\)</span> para una constante <span class="math inline">\(c\)</span>. En este caso, durante la propagación hacia adelante, cualquiera de las unidades ocultas toma las mismas entradas y parámetros, lo que produce la misma activación que se aplica a la unidad de salida. Durante la retropropagación, la diferenciación de la unidad de salida con respecto a los parámetros <span class="math inline">\(W^{(1)}\)</span> da como resultado un gradiente cuyos elementos toman el mismo valor. Por lo tanto, tras una iteración basada en gradientes (p. ej., el descenso de gradiente estocástico en minibatch), todos los elementos de <span class="math inline">\(W^{(1)}\)</span> siguen teniendo el mismo valor. Dichas iteraciones nunca romperían la simetría por sí solas y es posible que nunca seamos capaces de apreciar el potencial expresivo de la red. La capa oculta se comportaría como si solo tuviera una unidad. Cabe destacar que, si bien el descenso de gradiente estocástico en minibatch no rompería esta simetría, la regularización por abandono (que se presentará más adelante) sí lo haría.</p>
</div>
</div>
<div id="inicialización-paramétrica" class="section level3 hasAnchor" number="4.4.2">
<h3><span class="header-section-number">4.4.2</span> Inicialización paramétrica<a href="perceptrón-multicapa.html#inicializaci%C3%B3n-param%C3%A9trica" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Una forma de abordar, o al menos mitigar, los problemas planteados anteriormente es mediante una inicialización cuidadosa. Como veremos más adelante, un cuidado adicional durante la optimización y una regularización adecuada pueden mejorar aún más la estabilidad.</p>
<div id="inicialización-default" class="section level4 hasAnchor" number="4.4.2.1">
<h4><span class="header-section-number">4.4.2.1</span> Inicialización Default<a href="perceptrón-multicapa.html#inicializaci%C3%B3n-default" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>En las secciones anteriores, utilizamos una <strong>distribución normal</strong> para inicializar los valores de nuestros pesos. Si no especificamos el método de inicialización, <strong>el framework utilizará un método de inicialización aleatorio predeterminado</strong>, que suele funcionar bien en la práctica para problemas de tamaño moderado.</p>
</div>
<div id="inicialización-xavier" class="section level4 hasAnchor" number="4.4.2.2">
<h4><span class="header-section-number">4.4.2.2</span> Inicialización Xavier<a href="perceptrón-multicapa.html#inicializaci%C3%B3n-xavier" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Veamos la distribución de escala de una salida <span class="math inline">\(o_i\)</span> para una capa completamente conectada sin no linealidades. Con <span class="math inline">\(n_{in}\)</span> entradas <span class="math inline">\(x_{ij}\)</span> y sus pesos asociados <span class="math inline">\(w_{ij}\)</span> para esta capa, la salida viene dada por</p>
<p><span class="math display">\[
o_i=\sum_{j=1}^{n_{in}}{w_{ij}x_{j}}
\]</span>
Los pesos <span class="math inline">\(w_{ij}\)</span> se extraen independientemente de la misma distribución. Además, supongamos que esta distribución tiene media y varianza <span class="math inline">\(\sigma^{2}\)</span> cero. Tenga en cuenta que esto no significa que la distribución deba ser gaussiana, solo que la media y la varianza deben existir. Por ahora, supongamos que las entradas de la capa <span class="math inline">\(x_{j}\)</span> también tienen media y varianza <span class="math inline">\(\gamma^{2}\)</span> cero y que son independientes de <span class="math inline">\(w_{ij}\)</span> e independientes entre sí. En este caso, podemos calcular la media de <span class="math inline">\(o_i\)</span>:</p>
<p><span class="math display">\[\begin{align}
E[o_i] &amp;= \sum_{j=1}^{n_{in}}{E[w_{ij}x_{j}]} \\
&amp;= \sum_{j=1}^{n_{in}}{E[w_{ij}]E[x_{j}]} \\
&amp;= 0
\end{align}\]</span></p>
<p>y la varianza:</p>
<p><span class="math display">\[\begin{align}
Var[o_i] &amp;= E[o_{i}^{2}] - \left(E[o_i] \right)^{2} \\
&amp;= \sum_{j=1}^{n_{in}}{E[w^{2}_{ij}x^{2}_{j}]} - 0 \\
&amp;= \sum_{j=1}^{n_{in}}{E[w^{2}_{ij}]E[x^{2}_{j}]} \\
&amp;= n_{in}\sigma^{2}\gamma^{2}.
\end{align}\]</span></p>
<p>Una forma de mantener la varianza fija es establecer <span class="math inline">\(n_{in}\sigma^{2}=1\)</span>. Consideremos ahora la retropropagación. En este caso, nos enfrentamos a un problema similar, aunque con gradientes que se propagan desde las capas más cercanas a la salida. Utilizando el mismo razonamiento que para la propagación hacia adelante, vemos que la varianza de los gradientes puede dispararse a menos que <span class="math inline">\(n_{out}\sigma^{2}=1\)</span>, donde <span class="math inline">\(n_{out}\)</span> es el número de salidas de esta capa. Esto nos plantea un dilema: no podemos satisfacer ambas condiciones simultáneamente. En su lugar, simplemente intentamos satisfacer:</p>
<p><span class="math display">\[
\frac{1}{2}(n_{in}+n_{out})\sigma^{2}=1 \quad \text{o equivalentemente } \quad \sigma=\sqrt{\frac{2}{n_{in}+n_{out}}}
\]</span>
Este es el razonamiento subyacente a la inicialización de Xavier, ahora estándar y prácticamente beneficiosa, llamada así por el primer autor de sus creadores (Glorot y Bengio, 2010). Normalmente, la inicialización de Xavier muestrea ponderaciones de una distribución gaussiana con media y varianza cero <span class="math inline">\(\sigma^{2}=\frac{2}{n_{in}+n_{out}}\)</span>. También podemos adaptar esto para elegir la varianza al muestrear ponderaciones de una distribución uniforme. Nótese que la distribución uniforme <span class="math inline">\(U(-a, a)\)</span> tiene varianza <span class="math inline">\(\frac{a^{2}}{3}\)</span>. Al sustituir <span class="math inline">\(\frac{a^{2}}{3}\)</span> en nuestra condición <span class="math inline">\(\sigma^{2}\)</span>, nos lleva a inicializar según:</p>
<p><span class="math display">\[U\left(-\sqrt{\frac{6}{n_{in}+n_{out}}}, \sqrt{\frac{6}{n_{in}+n_{out}}} \right)\]</span></p>
<p>Aunque el supuesto de inexistencia de no linealidades en el razonamiento matemático anterior puede violarse fácilmente en redes neuronales, el método de inicialización de Xavier resulta funcionar bien en la práctica.</p>
</div>
</div>
<div id="ejercicios-3" class="section level3 hasAnchor" number="4.4.3">
<h3><span class="header-section-number">4.4.3</span> Ejercicios<a href="perceptrón-multicapa.html#ejercicios-3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><p>¿Puedes diseñar otros casos donde una red neuronal pueda presentar simetría que deba romperse, además de la simetría de permutación en las capas de una MLP?</p></li>
<li><p>¿Podemos inicializar todos los parámetros de peso en la regresión lineal o en la regresión softmax con el mismo valor?</p></li>
<li><p>Consulta los límites analíticos de los autovalores del producto de dos matrices. ¿Qué te indica esto sobre cómo asegurar que los gradientes estén bien condicionados?</p></li>
<li><p>Si sabemos que algunos términos divergen, ¿podemos corregirlo posteriormente? Consulta el artículo sobre escalamiento de tasa adaptativo por capas para inspirarte (You et al., 2017).</p></li>
</ol>
</div>
</div>
<div id="generalización-en-deep-learning" class="section level2 hasAnchor" number="4.5">
<h2><span class="header-section-number">4.5</span> Generalización en Deep Learning<a href="perceptrón-multicapa.html#generalizaci%C3%B3n-en-deep-learning" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El teorema “no free lunch” nos recuerda que ningún algoritmo aprende bien en todas las situaciones: para generalizar necesitamos asumir algo sobre cómo es el mundo. Estas suposiciones se llaman sesgos inductivos. Por ejemplo, una red profunda tiene el sesgo de construir funciones complejas combinando funciones simples capa a capa.</p>
<p>En machine learning solemos seguir dos pasos:</p>
<ol style="list-style-type: decimal">
<li>Ajustar el modelo a los datos de entrenamiento.</li>
<li>Medir la generalización evaluando en datos separados.</li>
</ol>
<p>La diferencia entre ambos resultados es la brecha de generalización, y si es grande hablamos de overfitting: el modelo “memoriza” el entrenamiento pero falla con ejemplos nuevos.</p>
<p>En el enfoque clásico, el overfitting se relaciona con tener modelos demasiado complejos. La solución típica es regularizar, reduciendo parámetros o limitando su tamaño para evitar que el modelo se vuelva excesivamente flexible.</p>
<p>Sin embargo, en deep learning esta idea se vuelve contraintuitiva. Las redes profundas son tan expresivas que pueden ajustar perfectamente incluso enormes conjuntos de datos. Lo sorprendente es que, aun alcanzando cero error de entrenamiento, a veces mejoramos la generalización haciendo el modelo más grande, añadiendo capas, neuronas o entrenando más tiempo. Esto da lugar al fenómeno de double descent, donde aumentar la complejidad primero empeora y luego mejora la generalización.</p>
<p>En resumen, aunque las redes puedan memorizarlo todo, en la práctica generalizan, y muchas de las herramientas del deep learning —algunas que restringen el modelo y otras que lo hacen más flexible— se usan precisamente para controlar el overfitting. Lo curioso es que la teoría clásica no explica bien este éxito: medidas como VC dimension o Rademacher complexity no predicen por qué las redes profundas generalizan tan bien.</p>
<div id="sobreajuste-y-regularización" class="section level3 hasAnchor" number="4.5.1">
<h3><span class="header-section-number">4.5.1</span> Sobreajuste y Regularización<a href="perceptrón-multicapa.html#sobreajuste-y-regularizaci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El teorema no free lunch dice que para generalizar necesitamos sesgos inductivos, es decir, suposiciones sobre cómo es el mundo. Las redes profundas tienen el sesgo de construir funciones complejas a partir de funciones simples.</p>
<p>En ML primero ajustamos los datos de entrenamiento y luego medimos la generalización. Si la diferencia es grande, aparece el overfitting. En el enfoque clásico, esto se controla reduciendo la complejidad del modelo mediante regularización.</p>
<p>Pero en deep learning el panorama es distinto: las redes pueden memorizar perfectamente el entrenamiento, y aun así generalizar mejor al hacerlas más grandes. Esto lleva al fenómeno de double descent, donde más complejidad primero perjudica y luego ayuda.</p>
<p>Lo más curioso es que la teoría clásica no explica por qué las redes profundas generalizan tan bien. Aun así, en la práctica usamos una combinación de trucos y regularizaciones para reducir el overfitting y mejorar la generalización.</p>
</div>
<div id="inspiración-de-los-no-paramétricos" class="section level3 hasAnchor" number="4.5.2">
<h3><span class="header-section-number">4.5.2</span> Inspiración de los no paramétricos<a href="perceptrón-multicapa.html#inspiraci%C3%B3n-de-los-no-param%C3%A9tricos" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Aunque las redes neuronales tienen millones de parámetros, a veces es más útil pensar en ellas como modelos no paramétricos. En estos modelos, la complejidad crece con la cantidad de datos, en lugar de estar fija desde el inicio.</p>
<p>Un ejemplo clásico de modelo no paramétrico es k-nearest neighbors (k-NN): el algoritmo básicamente memoriza el conjunto de entrenamiento y, al predecir, busca los puntos más cercanos según alguna métrica de distancia. Con <span class="math inline">\(k=1\)</span>, siempre logra cero error de entrenamiento, y aun así puede generalizar bien bajo ciertas condiciones. Eso sí, distintas métricas de distancia implican diferentes sesgos inductivos y pueden producir predictores distintos.</p>
<p>Las redes neuronales profundas, al estar sobrerrepresentadas (tienen muchos más parámetros de los necesarios para ajustar los datos), también tienden a interpolar o memorizar completamente el entrenamiento, comportándose en varios aspectos como modelos no paramétricos.</p>
<p>De hecho, investigaciones recientes muestran una conexión profunda entre redes muy anchas y métodos de kernels. En particular, cuando un MLP se hace infinitamente ancho, su comportamiento converge a un método de kernel no paramétrico llamado neural tangent kernel (NTK). Aunque el NTK no explica todo lo que ocurre en redes modernas, sirve como herramienta teórica para entender por qué los modelos sobredimensionados pueden generalizar tan bien.</p>
</div>
<div id="early-stopping" class="section level3 hasAnchor" number="4.5.3">
<h3><span class="header-section-number">4.5.3</span> Early Stopping<a href="perceptrón-multicapa.html#early-stopping" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Las redes neuronales profundas pueden memorizar etiquetas arbitrarias o aleatorias, pero lo hacen tarde en el entrenamiento. Estudios recientes muestran que primero aprenden los ejemplos correctamente etiquetados y solo después empiezan a ajustar las etiquetas incorrectas o ruidosas. Esto tiene una implicación importante: si el modelo ya ajustó los datos limpios pero aún no ha memorizado las etiquetas aleatorias, entonces ya está generalizando.</p>
<p>Este comportamiento motiva el uso de early stopping como técnica de regularización. En lugar de limitar los pesos, limitamos el número de épocas entrenadas. Lo usual es vigilar el error de validación y detener el entrenamiento cuando deja de mejorar después de cierta “paciencia”. Esto no solo mejora la generalización en presencia de ruido, sino que ahorra mucho tiempo y costo computacional, especialmente en modelos grandes.</p>
<p>Cuando las etiquetas no contienen ruido (problemas bien separables como gatos vs. perros), el early stopping aporta poco. Pero cuando hay ruido, ambigüedad o variabilidad natural en las etiquetas (como en medicina), el early stopping se vuelve crucial, porque entrenar hasta que el modelo memorice el ruido suele ser perjudicial.</p>
</div>
<div id="métodos-clásicos-de-regularización-para-redes-profundas" class="section level3 hasAnchor" number="4.5.4">
<h3><span class="header-section-number">4.5.4</span> Métodos clásicos de regularización para redes profundas<a href="perceptrón-multicapa.html#m%C3%A9todos-cl%C3%A1sicos-de-regularizaci%C3%B3n-para-redes-profundas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Anteriormente vimos técnicas clásicas de regularización, como <em>weight decay</em>, que añade un término a la función de pérdida para penalizar pesos grandes. Según la norma usada, se conoce como ridge (<span class="math inline">\(l_2\)</span>) o lasso (<span class="math inline">\(l_1\)</span>). En el enfoque clásico, estas penalizaciones limitan la complejidad del modelo y evitan que ajuste etiquetas arbitrarias.</p>
<p>En deep learning, el <em>weight decay</em> sigue siendo muy usado, pero se ha observado que, por sí solo, no impide que las redes profundas interpolen completamente los datos. Por eso, sus beneficios suelen entenderse mejor cuando se combina con <em>early stopping</em>. Sin esta combinación, el efecto de técnicas como <em>weight decay</em> puede deberse menos a “restringir” la capacidad del modelo y más a introducir sesgos inductivos compatibles con los patrones reales de los datos.</p>
<p>Aun así, los regularizadores clásicos siguen siendo populares en práctica. Además, el deep learning ha desarrollado variantes inspiradas en estas ideas, como agregar ruido durante el entrenamiento. En la siguiente sección aparecerá dropout, una técnica muy usada cuyo funcionamiento efectivo también tiene una base teórica parcial, pero funciona muy bien en la práctica.</p>
</div>
<div id="ejercicios-4" class="section level3 hasAnchor" number="4.5.5">
<h3><span class="header-section-number">4.5.5</span> Ejercicios<a href="perceptrón-multicapa.html#ejercicios-4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><p>¿En qué sentido las medidas tradicionales basadas en la complejidad no tienen en cuenta la generalización de las redes neuronales profundas?</p></li>
<li><p>¿Por qué la interrupción anticipada podría considerarse una técnica de regularización?</p></li>
<li><p>¿Cómo suelen determinar los investigadores el criterio de parada?</p></li>
<li><p>¿Qué factor importante parece diferenciar los casos en los que la interrupción temprana conduce a grandes mejoras en la generalización?</p></li>
<li><p>Más allá de la generalización, describa otro beneficio de dejar de fumar temprano.</p></li>
</ol>
</div>
</div>
<div id="dropout" class="section level2 hasAnchor" number="4.6">
<h2><span class="header-section-number">4.6</span> Dropout<a href="perceptrón-multicapa.html#dropout" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Pensemos brevemente en lo que esperamos de un buen modelo predictivo. Queremos que tenga un buen desempeño sobre datos no vistos. La teoría clásica de generalización sugiere que, para cerrar la brecha entre el rendimiento en entrenamiento y en prueba, deberíamos aspirar a un modelo simple. La simplicidad puede presentarse en forma de un número pequeño de dimensiones. Otra noción útil de simplicidad es la suavidad, es decir, que la función no sea sensible a pequeños cambios en sus entradas. Por ejemplo, al clasificar imágenes, esperaríamos que añadir algo de ruido aleatorio a los píxeles sea en su mayoría inofensivo.</p>
<p>Bishop (1995) formalizó esta idea cuando demostró que el entrenamiento con ruido en la entrada es equivalente a la regularización de Tikhonov. Este trabajo estableció una conexión matemática clara entre el requisito de que una función sea suave (y por tanto simple) y el requisito de que sea resistente a perturbaciones en la entrada.</p>
<p>Posteriormente, Srivastava et al. (2014) desarrollaron una idea ingeniosa para aplicar también la idea de Bishop a las capas internas de una red. Su propuesta, llamada dropout, consiste en inyectar ruido durante el cálculo de cada capa interna en la propagación hacia adelante, y se ha convertido en una técnica estándar para entrenar redes neuronales. El método se llama dropout porque literalmente se “eliminan” algunas neuronas durante el entrenamiento. A lo largo del entrenamiento, en cada iteración, el dropout estándar consiste en poner a cero una fracción de los nodos en cada capa antes de calcular la capa siguiente, la técnica de dropout en sí ha demostrado ser duradera, y diversas variantes de dropout están implementadas en la mayoría de las bibliotecas de aprendizaje profundo.</p>
<p>En la regularización dropout estándar, se ponen a cero una fracción de los nodos en cada capa y luego se corrige el sesgo de cada capa normalizando por la fracción de nodos que se conservaron (no eliminados). En otras palabras, con una probabilidad de dropout <span class="math inline">\(p\)</span>, cada activación intermedia <span class="math inline">\(h\)</span> se sustituye por una variable aleatoria <span class="math inline">\(h&#39;\)</span> de la siguiente manera:<span class="math display">\[h&#39; = \begin{cases}
0 &amp; \text{con probabilidad } p \\
\frac{h}{1-p} &amp; \text{en otro caso}
\end{cases}\]</span>Por diseño, la esperanza se mantiene inalterada, es decir, <span class="math inline">\(E[h&#39;] = h\)</span>.</p>
<div id="dropout-en-la-práctica" class="section level3 hasAnchor" number="4.6.1">
<h3><span class="header-section-number">4.6.1</span> Dropout en la práctica<a href="perceptrón-multicapa.html#dropout-en-la-pr%C3%A1ctica" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recuerda el MLP con una capa oculta y cinco unidades ocultas de la Sección 4.1.1. Cuando aplicamos dropout a una capa oculta, poniendo a cero cada unidad oculta con probabilidad <span class="math inline">\(p\)</span>, el resultado puede verse como una red que contiene solo un subconjunto de las neuronas originales. En la Fig. 4.6.1, <span class="math inline">\(h_2\)</span> y <span class="math inline">\(h_5\)</span> han sido eliminadas. En consecuencia, el cálculo de las salidas ya no depende de <span class="math inline">\(h_2\)</span> o <span class="math inline">\(h_5\)</span> y sus respectivos gradientes también desaparecen al realizar la retropropagación (backpropagation). De esta manera, el cálculo de la capa de salida no puede ser excesivamente dependiente de ningún elemento individual de <span class="math inline">\(h_1, \dots, h_5\)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-26"></span>
<img src="img/05_Multilayer_Perceptron/MLP%20before%20and%20after%20dropout.png" alt="Fig. 4.6.1 MLP antes y después del dropout" width="650pt" height="300pt" />
<p class="caption">
Figure 4.2: Fig. 4.6.1 MLP antes y después del dropout
</p>
</div>
<p>Típicamente, desactivamos el dropout en el momento de la prueba (test time). Dado un modelo entrenado y un nuevo ejemplo, no eliminamos ningún nodo y, por lo tanto, no necesitamos normalizar. Sin embargo, existen algunas excepciones: algunos investigadores utilizan el dropout en el momento de la prueba como una heurística para estimar la incertidumbre de las predicciones de la red neuronal: si las predicciones coinciden a través de muchas salidas diferentes de dropout, entonces podríamos decir que la red tiene mayor confianza.</p>
</div>
</div>
<div id="ejemplo" class="section level2 hasAnchor" number="4.7">
<h2><span class="header-section-number">4.7</span> Ejemplo<a href="perceptrón-multicapa.html#ejemplo" class="anchor-section" aria-label="Anchor link to header"></a></h2>

<!-- ::: watermark -->
<!-- <img src="img/aif-logo.png" width="400"/> -->
<!-- ::: -->
</div>
</div>



<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script>

$('.pipehover_incremental tr').hover(function() {
  $(this).removeClass()
  $(this).prevAll().removeClass()
  $(this).nextAll().removeClass()
  $(this).addClass('hover');
  $(this).prevAll().addClass('hover');
  $(this).closest('div').next().find('img').attr("src", $(this).attr("link"));
});


$('.pipehover_select_one_row tr').hover(function() {
  $(this).removeClass()
  $(this).prevAll().removeClass()
  $(this).nextAll().removeClass()
  $(this).addClass('hover');
  $(this).closest('div').next().find('img').attr("src", $(this).attr("link"));
});

</script>
            </section>

          </div>
        </div>
      </div>
<a href="redes-neuronales-lineales-para-clasificación.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="guía-del-constructor.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["deep_learning_course_python.pdf"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
