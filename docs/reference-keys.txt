introducción-a-deep-learning
introducción-al-aprendizaje-automático
motivación-los-paradigmas-del-conocimiento
machine-learning-supervisado
aprendizaje-supervisado
componentes-del-aprendizaje-supervisado
tipos-de-datos-en-el-aprendizaje-supervisado
númericos
categóricos
series-de-tiempo
los-problemas-de-machine-learning
el-problema-inverso
generación-del-modelo-que-aproxime-al-sistema
por-qué-deep-learning
dimensión-vc
el-truco-del-kernel-svm
ingeniería-de-caracteristicas
beneficios-del-deep-learning
teorema-de-aproximación-universal
extracción-automática-de-características-feature-extraction
escalabilidad-con-datos-y-cómputo
preliminares
algebra-lineal
introducción
motivación
vectores
matrices
transformaciones-lineales
escalares
campos-algebraicos
dato-curioso
vectores-1
matrices-1
alternativas-conceptuales-para-entenderlas
propiedades-matemáticas
en-el-aprendizaje-profundo
resumen
tensores
intuición-geométrica
su-rol-en-el-aprendizaje-profundo
propiedades-básicas-de-la-aritmética-de-tensores
reducciones-sobre-tensores
ejemplos
intuición-geométrica-1
en-aprendizaje-profundo
tipos-comunes-de-reducciones
resumen-1
producto-punto
interpretación-geométrica
en-el-aprendizaje-profundo-1
resumen-2
producto-entre-matrices-y-vectores
interpretación-geométrica-1
teorema-del-rango-y-nulidad
en-aprendizaje-profundo-1
resumen-3
multiplicación-matricial
interpretación-geométrica-2
propiedades-importantes
en-el-aprendizaje-profundo-2
producto-matricial-como-cambio-de-base-del-espacio-vectorial
resumen-4
normas
ejemplos-de-normas
norma-euclidiana-o-l2
norma-manhattan-o-l1
norma-máxima-linfty
norma-frobenius
interpretación-geométrica-3
en-aprendizaje-profundo-2
resumen-5
cálculo-diferencial
introducción-1
motivación-1
derivadas-y-diferenciación
funciones
derivada
derivada-vectorial
algunas-formulas-y-reglas
reglas-útiles-para-derivar-funciones-multivariable
regla-de-la-cadena
interpretación-geométrica-de-la-derivada
teorema-fundamental-del-cálculo
autodiferenciación
historia
qué-es
fundamento-matemático
dos-modos-principales
modo-directo
el-jacobiano-j_fx-y
el-gradiente-nabla-gx-y
el-hessiano-h_gx-y
uso-de-estos-resultados
modo-inverso
redes-neuronales-lineales-para-regresión
redes-neuronales-lineales-para-clasificación
perceptrón-multicapa
guía-del-constructor
redes-neuronales-convolucionales
redes-neuronales-convolucionales-modernas
redes-neuronales-recurrentes
redes-neuronales-recurrentes-modernas
mecanismos-de-atención-y-transformers
algoritmos-de-optimización
